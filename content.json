{"pages":[{"title":"关于作者","text":"记录学习的点滴","link":"/about/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"","text":"JavaScript 3D library for NexT Installation If you want to use the CDN instead of clone this repo, please jump to the Step 3. Step 1 &rarr; Go to NexT dir Change dir to NexT directory. There must be layout, source, languages and other directories: 123$ cd themes/next$ ls_config.yml crowdin.yml docs gulpfile.js languages layout LICENSE.md package.json README.md scripts source Step 2 &rarr; Get module Install module to source/lib directory: 1$ git clone https://github.com/theme-next/theme-next-three source/lib/three Step 3 &rarr; Set it up Enable module in NexT _config.yml file: 12345three_waves: trueORcanvas_lines: trueORcanvas_sphere: true And, if you wants to use the CDN, then need to set: 123456vendors: ... three: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js three_waves: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/three-waves.min.js canvas_lines: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/canvas_lines.min.js canvas_sphere: //cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/canvas_sphere.min.js Update 12$ cd themes/next/source/lib/three$ git pull","link":"/lib/three/README.html"},{"title":"","text":"/** * Copyright (c) 2016 hustcc * License: MIT * Version: v1.0.1 * GitHub: https://github.com/hustcc/ribbon.js **/ /*jshint -W030 */ ! function() { function attr(node, attr, default_value) { return Number(node.getAttribute(attr)) || default_value; } // get user config var scripts = document.getElementsByTagName('script'), script = scripts[scripts.length - 1]; // 当前加载的script config = { z: attr(script, \"zIndex\", -1), // z-index a: attr(script, \"alpha\", 0.6), // alpha s: attr(script, \"size\", 90), // size }; var canvas = document.createElement('canvas'), g2d = canvas.getContext('2d'), pr = window.devicePixelRatio || 1, width = window.innerWidth, height = window.innerHeight, f = config.s, q, t, m = Math, r = 0, pi = m.PI*2, cos = m.cos, random = m.random; canvas.width = width * pr; canvas.height = height * pr; g2d.scale(pr, pr); g2d.globalAlpha = config.a; canvas.style.cssText = 'opacity: ' + config.a + ';position:fixed;top:0;left:0;z-index: ' + config.z + ';width:100%;height:100%;pointer-events:none;'; // create canvas document.getElementsByTagName('body')[0].appendChild(canvas); function redraw() { g2d.clearRect(0, 0, width, height); q = [{x: 0, y: height * 0.7 + f}, {x: 0, y: height * 0.7 - f}]; while(q[1].x < width + f) draw(q[0], q[1]); } function draw(i, j) { g2d.beginPath(); g2d.moveTo(i.x, i.y); g2d.lineTo(j.x, j.y); var k = j.x + (random()*2-0.25)*f, n = line(j.y); g2d.lineTo(k, n); g2d.closePath(); r -= pi / -50; g2d.fillStyle = '#'+(cos(r)*127+128","link":"/lib/canvas-ribbon/canvas-ribbon.js"},{"title":"","text":"const fs = require('fs') const del = require('del') const gulp = require('gulp') const concat = require('gulp-concat') const uglify = require('gulp-uglify') gulp.task('clean', async () => { del(['*.min.js', '!three.min.js']) }) gulp.task('scripts', async () => { const sourceFiles = fs.readdirSync('src') sourceFiles.forEach(file => { const fileName = file.split('.')[0] return gulp.src([`src/${fileName}.js`, 'lib/*.js']) .pipe(concat(`${fileName}.min.js`)) .pipe(uglify()) .pipe(gulp.dest('./')) }) }) gulp.task('default', gulp.series('clean', 'scripts'))","link":"/lib/three/gulpfile.js"},{"title":"","text":"THREE.SpriteCanvasMaterial=function(e){THREE.Material.call(this),this.type=\"SpriteCanvasMaterial\",this.color=new THREE.Color(16777215),this.program=function(e,t){},this.setValues(e)},THREE.SpriteCanvasMaterial.prototype=Object.create(THREE.Material.prototype),THREE.SpriteCanvasMaterial.prototype.constructor=THREE.SpriteCanvasMaterial,THREE.SpriteCanvasMaterial.prototype.clone=function(){var e=new THREE.SpriteCanvasMaterial;return e.copy(this),e.color.copy(this.color),e.program=this.program,e},THREE.CanvasRenderer=function(e){console.log(\"THREE.CanvasRenderer\",THREE.REVISION),e=e||{};var s,l,c,p,E,d,h,f,u,m,v,x,R,y,T,w,H,g,S,M=this,b=new THREE.Projector,r=void 0!==e.canvas?e.canvas:document.createElement(\"canvas\"),C=r.width,z=r.height,V=Math.floor(C/2),j=Math.floor(z/2),L=0,O=0,B=C,W=z,n=1,P=r.getContext(\"2d\",{alpha:!0===e.alpha}),i=new THREE.Color(0),o=!0===e.alpha?0:1,a=1,k=0,N=null,F=null,A=null,I=null,D=null,t=[],G=(new THREE.RenderableVertex,new THREE.RenderableVertex,new THREE.Color),U=(new THREE.Color,new THREE.Color,new THREE.Color,new THREE.Color,new THREE.Color),q=new THREE.Color,X=new THREE.Color,J={},Y=new THREE.Box2,$=new THREE.Box2,K=new THREE.Box2,Q=new THREE.Color,Z=new THREE.Color,_=new THREE.Color,ee=new THREE.Vector3,te=new THREE.Vector3,ie=new THREE.Vector3,re=new THREE.Matrix3;function ne(e,t,i){de(i.opacity),he(i.blending);var r=t.scale.x*V,n=t.scale.y*j,o=.5*Math.sqrt(r*r+n*n);if(K.min.set(e.x-o,e.y-o),K.max.set(e.x+o,e.y+o),i instanceof THREE.SpriteMaterial){var a=i.map;if(null!==a){var s=J[a.id];if(void 0!==s&&s.version===a.version||(s=ce(a),J[a.id]=s),void 0!==s.canvas){xe(s.canvas);var l=a.image,c=l.width*a.offset.x,p=l.height*a.offset.y,E=l.width*a.repeat.x,d=l.height*a.repeat.y,h=r/E,f=n/d;P.save(),P.translate(e.x,e.y),0!==i.rotation&&P.rotate(i.rotation),P.translate(-r/2,-n/2),P.scale(h,f),P.translate(-c,-p),P.fillRect(c,p,E,d),P.restore()}}else xe(i.color.getStyle()),P.save(),P.translate(e.x,e.y),0!==i.rotation&&P.rotate(i.rotation),P.scale(r,-n),P.fillRect(-.5,-.5,1,1),P.restore()}else i instanceof THREE.SpriteCanvasMaterial&&(ve(i.color.getStyle()),xe(i.color.getStyle()),P.save(),P.translate(e.x,e.y),0!==i.rotation&&P.rotate(i.rotation),P.scale(r,n),i.program(P),P.restore())}function oe(e,t,i,r){if(de(r.opacity),he(r.blending),P.beginPath(),P.moveTo(e.positionScreen.x,e.positionScreen.y),P.lineTo(t.positionScreen.x,t.positionScreen.y),r instanceof THREE.LineBasicMaterial){if(fe(r.linewidth),ue(r.linecap),me(r.linejoin),r.vertexColors!==THREE.VertexColors)ve(r.color.getStyle());else{var n=i.vertexColors[0].getStyle(),o=i.vertexColors[1].getStyle();if(n===o)ve(n);else{try{var a=P.createLinearGradient(e.positionScreen.x,e.positionScreen.y,t.positionScreen.x,t.positionScreen.y);a.addColorStop(0,n),a.addColorStop(1,o)}catch(e){a=n}ve(a)}}P.stroke(),K.expandByScalar(2*r.linewidth)}else r instanceof THREE.LineDashedMaterial&&(fe(r.linewidth),ue(r.linecap),me(r.linejoin),ve(r.color.getStyle()),Re([r.dashSize,r.gapSize]),P.stroke(),K.expandByScalar(2*r.linewidth),Re([]))}function ae(e,t,i,r,n,o,a,s){if(M.info.render.vertices+=3,M.info.render.faces++,de(s.opacity),he(s.blending),h=e.positionScreen.x,f=e.positionScreen.y,u=t.positionScreen.x,m=t.positionScreen.y,v=i.positionScreen.x,x=i.positionScreen.y,function(e,t,i,r,n,o){P.beginPath(),P.moveTo(e,t),P.lineTo(i,r),P.lineTo(n,o),P.closePath()}(h,f,u,m,v,x),(s instanceof THREE.MeshLambertMaterial||s instanceof THREE.MeshPhongMaterial)&&null===s.map)U.copy(s.color),q.copy(s.emissive),s.vertexColors===THREE.FaceColors&&U.multiply(a.color),G.copy(Q),te.copy(e.positionWorld).add(t.positionWorld).add(i.positionWorld).divideScalar(3),function(e,t,i){for(var r=0,n=c.length;r","link":"/lib/three/canvas_lines.min.js"},{"title":"","text":"{\"extends\":[\"config:base\"]}","link":"/lib/three/renovate.json"},{"title":"","text":"{\"name\":\"theme-next-three\",\"version\":\"1.0.0\",\"main\":\"index.js\",\"repository\":\"git@github.com:theme-next/theme-next-three.git\",\"author\":\"Raincal \",\"license\":\"MIT\",\"scripts\":{\"build\":\"gulp\"},\"dependencies\":{\"del\":\"^5.1.0\",\"gulp\":\"^4.0.2\",\"gulp-concat\":\"^2.6.1\",\"gulp-uglify\":\"^3.0.2\"}}","link":"/lib/three/package.json"},{"title":"","text":"THREE.SpriteCanvasMaterial=function(e){THREE.Material.call(this),this.type=\"SpriteCanvasMaterial\",this.color=new THREE.Color(16777215),this.program=function(e,t){},this.setValues(e)},THREE.SpriteCanvasMaterial.prototype=Object.create(THREE.Material.prototype),THREE.SpriteCanvasMaterial.prototype.constructor=THREE.SpriteCanvasMaterial,THREE.SpriteCanvasMaterial.prototype.clone=function(){var e=new THREE.SpriteCanvasMaterial;return e.copy(this),e.color.copy(this.color),e.program=this.program,e},THREE.CanvasRenderer=function(e){console.log(\"THREE.CanvasRenderer\",THREE.REVISION),e=e||{};var s,l,c,p,E,d,h,f,u,m,v,R,x,y,T,w,H,g,S,M=this,b=new THREE.Projector,i=void 0!==e.canvas?e.canvas:document.createElement(\"canvas\"),C=i.width,z=i.height,V=Math.floor(C/2),j=Math.floor(z/2),L=0,O=0,B=C,W=z,n=1,P=i.getContext(\"2d\",{alpha:!0===e.alpha}),r=new THREE.Color(0),o=!0===e.alpha?0:1,a=1,k=0,N=null,F=null,A=null,I=null,D=null,t=[],G=(new THREE.RenderableVertex,new THREE.RenderableVertex,new THREE.Color),U=(new THREE.Color,new THREE.Color,new THREE.Color,new THREE.Color,new THREE.Color),q=new THREE.Color,X=new THREE.Color,J={},Y=new THREE.Box2,$=new THREE.Box2,K=new THREE.Box2,Q=new THREE.Color,Z=new THREE.Color,_=new THREE.Color,ee=new THREE.Vector3,te=new THREE.Vector3,re=new THREE.Vector3,ie=new THREE.Matrix3;function ne(e,t,r){de(r.opacity),he(r.blending);var i=t.scale.x*V,n=t.scale.y*j,o=.5*Math.sqrt(i*i+n*n);if(K.min.set(e.x-o,e.y-o),K.max.set(e.x+o,e.y+o),r instanceof THREE.SpriteMaterial){var a=r.map;if(null!==a){var s=J[a.id];if(void 0!==s&&s.version===a.version||(s=ce(a),J[a.id]=s),void 0!==s.canvas){Re(s.canvas);var l=a.image,c=l.width*a.offset.x,p=l.height*a.offset.y,E=l.width*a.repeat.x,d=l.height*a.repeat.y,h=i/E,f=n/d;P.save(),P.translate(e.x,e.y),0!==r.rotation&&P.rotate(r.rotation),P.translate(-i/2,-n/2),P.scale(h,f),P.translate(-c,-p),P.fillRect(c,p,E,d),P.restore()}}else Re(r.color.getStyle()),P.save(),P.translate(e.x,e.y),0!==r.rotation&&P.rotate(r.rotation),P.scale(i,-n),P.fillRect(-.5,-.5,1,1),P.restore()}else r instanceof THREE.SpriteCanvasMaterial&&(ve(r.color.getStyle()),Re(r.color.getStyle()),P.save(),P.translate(e.x,e.y),0!==r.rotation&&P.rotate(r.rotation),P.scale(i,n),r.program(P),P.restore())}function oe(e,t,r,i){if(de(i.opacity),he(i.blending),P.beginPath(),P.moveTo(e.positionScreen.x,e.positionScreen.y),P.lineTo(t.positionScreen.x,t.positionScreen.y),i instanceof THREE.LineBasicMaterial){if(fe(i.linewidth),ue(i.linecap),me(i.linejoin),i.vertexColors!==THREE.VertexColors)ve(i.color.getStyle());else{var n=r.vertexColors[0].getStyle(),o=r.vertexColors[1].getStyle();if(n===o)ve(n);else{try{var a=P.createLinearGradient(e.positionScreen.x,e.positionScreen.y,t.positionScreen.x,t.positionScreen.y);a.addColorStop(0,n),a.addColorStop(1,o)}catch(e){a=n}ve(a)}}P.stroke(),K.expandByScalar(2*i.linewidth)}else i instanceof THREE.LineDashedMaterial&&(fe(i.linewidth),ue(i.linecap),me(i.linejoin),ve(i.color.getStyle()),xe([i.dashSize,i.gapSize]),P.stroke(),K.expandByScalar(2*i.linewidth),xe([]))}function ae(e,t,r,i,n,o,a,s){if(M.info.render.vertices+=3,M.info.render.faces++,de(s.opacity),he(s.blending),h=e.positionScreen.x,f=e.positionScreen.y,u=t.positionScreen.x,m=t.positionScreen.y,v=r.positionScreen.x,R=r.positionScreen.y,function(e,t,r,i,n,o){P.beginPath(),P.moveTo(e,t),P.lineTo(r,i),P.lineTo(n,o),P.closePath()}(h,f,u,m,v,R),(s instanceof THREE.MeshLambertMaterial||s instanceof THREE.MeshPhongMaterial)&&null===s.map)U.copy(s.color),q.copy(s.emissive),s.vertexColors===THREE.FaceColors&&U.multiply(a.color),G.copy(Q),te.copy(e.positionWorld).add(t.positionWorld).add(r.positionWorld).divideScalar(3),function(e,t,r){for(var i=0,n=c.length;i","link":"/lib/three/canvas_sphere.min.js"},{"title":"","text":"THREE.SpriteCanvasMaterial=function(e){THREE.Material.call(this),this.type=\"SpriteCanvasMaterial\",this.color=new THREE.Color(16777215),this.program=function(e,t){},this.setValues(e)},THREE.SpriteCanvasMaterial.prototype=Object.create(THREE.Material.prototype),THREE.SpriteCanvasMaterial.prototype.constructor=THREE.SpriteCanvasMaterial,THREE.SpriteCanvasMaterial.prototype.clone=function(){var e=new THREE.SpriteCanvasMaterial;return e.copy(this),e.color.copy(this.color),e.program=this.program,e},THREE.CanvasRenderer=function(e){console.log(\"THREE.CanvasRenderer\",THREE.REVISION),e=e||{};var s,l,c,p,E,d,f,h,u,m,v,x,R,y,T,w,H,g,S,M=this,b=new THREE.Projector,i=void 0!==e.canvas?e.canvas:document.createElement(\"canvas\"),C=i.width,z=i.height,V=Math.floor(C/2),j=Math.floor(z/2),L=0,O=0,B=C,W=z,n=1,P=i.getContext(\"2d\",{alpha:!0===e.alpha}),r=new THREE.Color(0),o=!0===e.alpha?0:1,a=1,k=0,N=null,F=null,A=null,I=null,D=null,t=[],G=(new THREE.RenderableVertex,new THREE.RenderableVertex,new THREE.Color),U=(new THREE.Color,new THREE.Color,new THREE.Color,new THREE.Color,new THREE.Color),q=new THREE.Color,J=new THREE.Color,X={},$=new THREE.Box2,K=new THREE.Box2,Q=new THREE.Box2,Y=new THREE.Color,Z=new THREE.Color,_=new THREE.Color,ee=new THREE.Vector3,te=new THREE.Vector3,re=new THREE.Vector3,ie=new THREE.Matrix3;function ne(e,t,r){de(r.opacity),fe(r.blending);var i=t.scale.x*V,n=t.scale.y*j,o=.5*Math.sqrt(i*i+n*n);if(Q.min.set(e.x-o,e.y-o),Q.max.set(e.x+o,e.y+o),r instanceof THREE.SpriteMaterial){var a=r.map;if(null!==a){var s=X[a.id];if(void 0!==s&&s.version===a.version||(s=ce(a),X[a.id]=s),void 0!==s.canvas){xe(s.canvas);var l=a.image,c=l.width*a.offset.x,p=l.height*a.offset.y,E=l.width*a.repeat.x,d=l.height*a.repeat.y,f=i/E,h=n/d;P.save(),P.translate(e.x,e.y),0!==r.rotation&&P.rotate(r.rotation),P.translate(-i/2,-n/2),P.scale(f,h),P.translate(-c,-p),P.fillRect(c,p,E,d),P.restore()}}else xe(r.color.getStyle()),P.save(),P.translate(e.x,e.y),0!==r.rotation&&P.rotate(r.rotation),P.scale(i,-n),P.fillRect(-.5,-.5,1,1),P.restore()}else r instanceof THREE.SpriteCanvasMaterial&&(ve(r.color.getStyle()),xe(r.color.getStyle()),P.save(),P.translate(e.x,e.y),0!==r.rotation&&P.rotate(r.rotation),P.scale(i,n),r.program(P),P.restore())}function oe(e,t,r,i){if(de(i.opacity),fe(i.blending),P.beginPath(),P.moveTo(e.positionScreen.x,e.positionScreen.y),P.lineTo(t.positionScreen.x,t.positionScreen.y),i instanceof THREE.LineBasicMaterial){if(he(i.linewidth),ue(i.linecap),me(i.linejoin),i.vertexColors!==THREE.VertexColors)ve(i.color.getStyle());else{var n=r.vertexColors[0].getStyle(),o=r.vertexColors[1].getStyle();if(n===o)ve(n);else{try{var a=P.createLinearGradient(e.positionScreen.x,e.positionScreen.y,t.positionScreen.x,t.positionScreen.y);a.addColorStop(0,n),a.addColorStop(1,o)}catch(e){a=n}ve(a)}}P.stroke(),Q.expandByScalar(2*i.linewidth)}else i instanceof THREE.LineDashedMaterial&&(he(i.linewidth),ue(i.linecap),me(i.linejoin),ve(i.color.getStyle()),Re([i.dashSize,i.gapSize]),P.stroke(),Q.expandByScalar(2*i.linewidth),Re([]))}function ae(e,t,r,i,n,o,a,s){if(M.info.render.vertices+=3,M.info.render.faces++,de(s.opacity),fe(s.blending),f=e.positionScreen.x,h=e.positionScreen.y,u=t.positionScreen.x,m=t.positionScreen.y,v=r.positionScreen.x,x=r.positionScreen.y,function(e,t,r,i,n,o){P.beginPath(),P.moveTo(e,t),P.lineTo(r,i),P.lineTo(n,o),P.closePath()}(f,h,u,m,v,x),(s instanceof THREE.MeshLambertMaterial||s instanceof THREE.MeshPhongMaterial)&&null===s.map)U.copy(s.color),q.copy(s.emissive),s.vertexColors===THREE.FaceColors&&U.multiply(a.color),G.copy(Y),te.copy(e.positionWorld).add(t.positionWorld).add(r.positionWorld).divideScalar(3),function(e,t,r){for(var i=0,n=c.length;i","link":"/lib/three/three-waves.min.js"},{"title":"","text":"/** * @author mrdoob / http://mrdoob.com/ */ THREE.SpriteCanvasMaterial = function ( parameters ) { THREE.Material.call( this ); this.type = 'SpriteCanvasMaterial'; this.color = new THREE.Color( 0xffffff ); this.program = function ( context, color ) {}; this.setValues( parameters ); }; THREE.SpriteCanvasMaterial.prototype = Object.create( THREE.Material.prototype ); THREE.SpriteCanvasMaterial.prototype.constructor = THREE.SpriteCanvasMaterial; THREE.SpriteCanvasMaterial.prototype.clone = function () { var material = new THREE.SpriteCanvasMaterial(); material.copy( this ); material.color.copy( this.color ); material.program = this.program; return material; }; // THREE.CanvasRenderer = function ( parameters ) { console.log( 'THREE.CanvasRenderer', THREE.REVISION ); parameters = parameters || {}; var _this = this, _renderData, _elements, _lights, _projector = new THREE.Projector(), _canvas = parameters.canvas !== undefined ? parameters.canvas : document.createElement( 'canvas' ), _canvasWidth = _canvas.width, _canvasHeight = _canvas.height, _canvasWidthHalf = Math.floor( _canvasWidth / 2 ), _canvasHeightHalf = Math.floor( _canvasHeight / 2 ), _viewportX = 0, _viewportY = 0, _viewportWidth = _canvasWidth, _viewportHeight = _canvasHeight, _pixelRatio = 1, _context = _canvas.getContext( '2d', { alpha: parameters.alpha === true } ), _clearColor = new THREE.Color( 0x000000 ), _clearAlpha = parameters.alpha === true ? 0 : 1, _contextGlobalAlpha = 1, _contextGlobalCompositeOperation = 0, _contextStrokeStyle = null, _contextFillStyle = null, _contextLineWidth = null, _contextLineCap = null, _contextLineJoin = null, _contextLineDash = [], _camera, _v1, _v2, _v3, _v4, _v5 = new THREE.RenderableVertex(), _v6 = new THREE.RenderableVertex(), _v1x, _v1y, _v2x, _v2y, _v3x, _v3y, _v4x, _v4y, _v5x, _v5y, _v6x, _v6y, _color = new THREE.Color(), _color1 = new THREE.Color(), _color2 = new THREE.Color(), _color3 = new THREE.Color(), _color4 = new THREE.Color(), _diffuseColor = new THREE.Color(), _emissiveColor = new THREE.Color(), _lightColor = new THREE.Color(), _patterns = {}, _image, _uvs, _uv1x, _uv1y, _uv2x, _uv2y, _uv3x, _uv3y, _clipBox = new THREE.Box2(), _clearBox = new THREE.Box2(), _elemBox = new THREE.Box2(), _ambientLight = new THREE.Color(), _directionalLights = new THREE.Color(), _pointLights = new THREE.Color(), _vector3 = new THREE.Vector3(), // Needed for PointLight _centroid = new THREE.Vector3(), _normal = new THREE.Vector3(), _normalViewMatrix = new THREE.Matrix3(); /* TODO _canvas.mozImageSmoothingEnabled = false; _canvas.webkitImageSmoothingEnabled = false; _canvas.msImageSmoothingEnabled = false; _canvas.imageSmoothingEnabled = false; */ // dash+gap fallbacks for Firefox and everything else if ( _context.setLineDash === undefined ) { _context.setLineDash = function () {}; } this.domElement = _canvas; this.autoClear = true; this.sortObjects = true; this.sortElements = true; this.info = { render: { vertices: 0, faces: 0 } }; // WebGLRenderer compatibility this.supportsVertexTextures = function () {}; this.setFaceCulling = function () {}; // API this.getContext = function () { return _context; }; this.getContextAttributes = function () { return _context.getContextAttributes(); }; this.getPixelRatio = function () { return _pixelRatio; }; this.setPixelRatio = function ( value ) { if ( value !== undefined ) _pixelRatio = value; }; this.setSize = function ( width, height, updateStyle ) { _canvasWidth = width * _pixelRatio; _canvasHeight = height * _pixelRatio; _canvas.width = _canvasWidth; _canvas.height = _canvasHeight; _canvasWidthHalf = Math.floor( _canvasWidth / 2 ); _canvasHeightHalf = Math.floor( _canvasHeight / 2 ); if ( updateStyle !== false ) { _canvas.style.width = width + 'px'; _canvas.style.height = height + 'px'; } _clipBox.min.set( - _canvasWidthHalf, - _canvasHeightHalf ); _clipBox.max.set( _canvasWidthHalf, _canvasHeightHalf ); _clearBox.min.set( - _canvasWidthHalf, - _canvasHeightHalf ); _clearBox.max.set( _canvasWidthHalf, _canvasHeightHalf ); _contextGlobalAlpha = 1; _contextGlobalCompositeOperation = 0; _contextStrokeStyle = null; _contextFillStyle = null; _contextLineWidth = null; _contextLineCap = null; _contextLineJoin = null; this.setViewport( 0, 0, width, height ); }; this.setViewport = function ( x, y, width, height ) { _viewportX = x * _pixelRatio; _viewportY = y * _pixelRatio; _viewportWidth = width * _pixelRatio; _viewportHeight = height * _pixelRatio; }; this.setScissor = function () {}; this.setScissorTest = function () {}; this.setClearColor = function ( color, alpha ) { _clearColor.set( color ); _clearAlpha = alpha !== undefined ? alpha : 1; _clearBox.min.set( - _canvasWidthHalf, - _canvasHeightHalf ); _clearBox.max.set( _canvasWidthHalf, _canvasHeightHalf ); }; this.setClearColorHex = function ( hex, alpha ) { console.warn( 'THREE.CanvasRenderer: .setClearColorHex() is being removed. Use .setClearColor() instead.' ); this.setClearColor( hex, alpha ); }; this.getClearColor = function () { return _clearColor; }; this.getClearAlpha = function () { return _clearAlpha; }; this.getMaxAnisotropy = function () { return 0; }; this.clear = function () { if ( _clearBox.isEmpty() === false ) { _clearBox.intersect( _clipBox ); _clearBox.expandByScalar( 2 ); _clearBox.min.x = _clearBox.min.x + _canvasWidthHalf; _clearBox.min.y = - _clearBox.min.y + _canvasHeightHalf; // higher y value ! _clearBox.max.x = _clearBox.max.x + _canvasWidthHalf; _clearBox.max.y = - _clearBox.max.y + _canvasHeightHalf; // lower y value ! if ( _clearAlpha < 1 ) { _context.clearRect( _clearBox.min.x | 0, _clearBox.max.y | 0, ( _clearBox.max.x - _clearBox.min.x ) | 0, ( _clearBox.min.y - _clearBox.max.y ) | 0 ); } if ( _clearAlpha > 0 ) { setBlending( THREE.NormalBlending ); setOpacity( 1 ); setFillStyle( 'rgba(' + Math.floor( _clearColor.r * 255 ) + ',' + Math.floor( _clearColor.g * 255 ) + ',' + Math.floor( _clearColor.b * 255 ) + ',' + _clearAlpha + ')' ); _context.fillRect( _clearBox.min.x | 0, _clearBox.max.y | 0, ( _clearBox.max.x - _clearBox.min.x ) | 0, ( _clearBox.min.y - _clearBox.max.y ) | 0 ); } _clearBox.makeEmpty(); } }; // compatibility this.clearColor = function () {}; this.clearDepth = function () {}; this.clearStencil = function () {}; this.render = function ( scene, camera ) { if ( camera instanceof THREE.Camera === false ) { console.error( 'THREE.CanvasRenderer.render: camera is not an instance of THREE.Camera.' ); return; } var background = scene.background; if ( background && background.isColor ) { setFillStyle( 'rgb(' + Math.floor( background.r * 255 ) + ',' + Math.floor( background.g * 255 ) + ',' + Math.floor( background.b * 255 ) + ')' ); _context.fillRect( 0, 0, _canvasWidth, _canvasHeight ); } else if ( this.autoClear === true ) { this.clear(); } _this.info.render.vertices = 0; _this.info.render.faces = 0; _context.setTransform( _viewportWidth / _canvasWidth, 0, 0, - _viewportHeight / _canvasHeight, _viewportX, _canvasHeight - _viewportY ); _context.translate( _canvasWidthHalf, _canvasHeightHalf ); _renderData = _projector.projectScene( scene, camera, this.sortObjects, this.sortElements ); _elements = _renderData.elements; _lights = _renderData.lights; _camera = camera; _normalViewMatrix.getNormalMatrix( camera.matrixWorldInverse ); /* DEBUG setFillStyle( 'rgba( 0, 255, 255, 0.5 )' ); _context.fillRect( _clipBox.min.x, _clipBox.min.y, _clipBox.max.x - _clipBox.min.x, _clipBox.max.y - _clipBox.min.y ); */ calculateLights(); for ( var e = 0, el = _elements.length; e < el; e ++ ) { var element = _elements[ e ]; var material = element.material; if ( material === undefined || material.opacity === 0 ) continue; _elemBox.makeEmpty(); if ( element instanceof THREE.RenderableSprite ) { _v1 = element; _v1.x *= _canvasWidthHalf; _v1.y *= _canvasHeightHalf; renderSprite( _v1, element, material ); } else if ( element instanceof THREE.RenderableLine ) { _v1 = element.v1; _v2 = element.v2; _v1.positionScreen.x *= _canvasWidthHalf; _v1.positionScreen.y *= _canvasHeightHalf; _v2.positionScreen.x *= _canvasWidthHalf; _v2.positionScreen.y *= _canvasHeightHalf; _elemBox.setFromPoints( [ _v1.positionScreen, _v2.positionScreen ] ); if ( _clipBox.intersectsBox( _elemBox ) === true ) { renderLine( _v1, _v2, element, material ); } } else if ( element instanceof THREE.RenderableFace ) { _v1 = element.v1; _v2 = element.v2; _v3 = element.v3; if ( _v1.positionScreen.z < - 1 || _v1.positionScreen.z > 1 ) continue; if ( _v2.positionScreen.z < - 1 || _v2.positionScreen.z > 1 ) continue; if ( _v3.positionScreen.z < - 1 || _v3.positionScreen.z > 1 ) continue; _v1.positionScreen.x *= _canvasWidthHalf; _v1.positionScreen.y *= _canvasHeightHalf; _v2.positionScreen.x *= _canvasWidthHalf; _v2.positionScreen.y *= _canvasHeightHalf; _v3.positionScreen.x *= _canvasWidthHalf; _v3.positionScreen.y *= _canvasHeightHalf; if ( material.overdraw > 0 ) { expand( _v1.positionScreen, _v2.positionScreen, material.overdraw ); expand( _v2.positionScreen, _v3.positionScreen, material.overdraw ); expand( _v3.positionScreen, _v1.positionScreen, material.overdraw ); } _elemBox.setFromPoints( [ _v1.positionScreen, _v2.positionScreen, _v3.positionScreen ] ); if ( _clipBox.intersectsBox( _elemBox ) === true ) { renderFace3( _v1, _v2, _v3, 0, 1, 2, element, material ); } } /* DEBUG setLineWidth( 1 ); setStrokeStyle( 'rgba( 0, 255, 0, 0.5 )' ); _context.strokeRect( _elemBox.min.x, _elemBox.min.y, _elemBox.max.x - _elemBox.min.x, _elemBox.max.y - _elemBox.min.y ); */ _clearBox.union( _elemBox ); } /* DEBUG setLineWidth( 1 ); setStrokeStyle( 'rgba( 255, 0, 0, 0.5 )' ); _context.strokeRect( _clearBox.min.x, _clearBox.min.y, _clearBox.max.x - _clearBox.min.x, _clearBox.max.y - _clearBox.min.y ); */ _context.setTransform( 1, 0, 0, 1, 0, 0 ); }; // function calculateLights() { _ambientLight.setRGB( 0, 0, 0 ); _directionalLights.setRGB( 0, 0, 0 ); _pointLights.setRGB( 0, 0, 0 ); for ( var l = 0, ll = _lights.length; l < ll; l ++ ) { var light = _lights[ l ]; var lightColor = light.color; if ( light instanceof THREE.AmbientLight ) { _ambientLight.add( lightColor ); } else if ( light instanceof THREE.DirectionalLight ) { // for sprites _directionalLights.add( lightColor ); } else if ( light instanceof THREE.PointLight ) { // for sprites _pointLights.add( lightColor ); } } } function calculateLight( position, normal, color ) { for ( var l = 0, ll = _lights.length; l < ll; l ++ ) { var light = _lights[ l ]; _lightColor.copy( light.color ); if ( light instanceof THREE.DirectionalLight ) { var lightPosition = _vector3.setFromMatrixPosition( light.matrixWorld ).normalize(); var amount = normal.dot( lightPosition ); if ( amount","link":"/lib/three/lib/CanvasRenderer.js"},{"title":"","text":"/** * @author mrdoob / http://mrdoob.com/ * @author supereggbert / http://www.paulbrunt.co.uk/ * @author julianwa / https://github.com/julianwa */ THREE.RenderableObject = function () { this.id = 0; this.object = null; this.z = 0; this.renderOrder = 0; }; // THREE.RenderableFace = function () { this.id = 0; this.v1 = new THREE.RenderableVertex(); this.v2 = new THREE.RenderableVertex(); this.v3 = new THREE.RenderableVertex(); this.normalModel = new THREE.Vector3(); this.vertexNormalsModel = [ new THREE.Vector3(), new THREE.Vector3(), new THREE.Vector3() ]; this.vertexNormalsLength = 0; this.color = new THREE.Color(); this.material = null; this.uvs = [ new THREE.Vector2(), new THREE.Vector2(), new THREE.Vector2() ]; this.z = 0; this.renderOrder = 0; }; // THREE.RenderableVertex = function () { this.position = new THREE.Vector3(); this.positionWorld = new THREE.Vector3(); this.positionScreen = new THREE.Vector4(); this.visible = true; }; THREE.RenderableVertex.prototype.copy = function ( vertex ) { this.positionWorld.copy( vertex.positionWorld ); this.positionScreen.copy( vertex.positionScreen ); }; // THREE.RenderableLine = function () { this.id = 0; this.v1 = new THREE.RenderableVertex(); this.v2 = new THREE.RenderableVertex(); this.vertexColors = [ new THREE.Color(), new THREE.Color() ]; this.material = null; this.z = 0; this.renderOrder = 0; }; // THREE.RenderableSprite = function () { this.id = 0; this.object = null; this.x = 0; this.y = 0; this.z = 0; this.rotation = 0; this.scale = new THREE.Vector2(); this.material = null; this.renderOrder = 0; }; // THREE.Projector = function () { var _object, _objectCount, _objectPool = [], _objectPoolLength = 0, _vertex, _vertexCount, _vertexPool = [], _vertexPoolLength = 0, _face, _faceCount, _facePool = [], _facePoolLength = 0, _line, _lineCount, _linePool = [], _linePoolLength = 0, _sprite, _spriteCount, _spritePool = [], _spritePoolLength = 0, _renderData = { objects: [], lights: [], elements: [] }, _vector3 = new THREE.Vector3(), _vector4 = new THREE.Vector4(), _clipBox = new THREE.Box3( new THREE.Vector3( - 1, - 1, - 1 ), new THREE.Vector3( 1, 1, 1 ) ), _boundingBox = new THREE.Box3(), _points3 = new Array( 3 ), _points4 = new Array( 4 ), _viewMatrix = new THREE.Matrix4(), _viewProjectionMatrix = new THREE.Matrix4(), _modelMatrix, _modelViewProjectionMatrix = new THREE.Matrix4(), _normalMatrix = new THREE.Matrix3(), _frustum = new THREE.Frustum(), _clippedVertex1PositionScreen = new THREE.Vector4(), _clippedVertex2PositionScreen = new THREE.Vector4(); // this.projectVector = function ( vector, camera ) { console.warn( 'THREE.Projector: .projectVector() is now vector.project().' ); vector.project( camera ); }; this.unprojectVector = function ( vector, camera ) { console.warn( 'THREE.Projector: .unprojectVector() is now vector.unproject().' ); vector.unproject( camera ); }; this.pickingRay = function ( vector, camera ) { console.error( 'THREE.Projector: .pickingRay() is now raycaster.setFromCamera().' ); }; // var RenderList = function () { var normals = []; var uvs = []; var object = null; var material = null; var normalMatrix = new THREE.Matrix3(); function setObject( value ) { object = value; material = object.material; normalMatrix.getNormalMatrix( object.matrixWorld ); normals.length = 0; uvs.length = 0; } function projectVertex( vertex ) { var position = vertex.position; var positionWorld = vertex.positionWorld; var positionScreen = vertex.positionScreen; positionWorld.copy( position ).applyMatrix4( _modelMatrix ); positionScreen.copy( positionWorld ).applyMatrix4( _viewProjectionMatrix ); var invW = 1 / positionScreen.w; positionScreen.x *= invW; positionScreen.y *= invW; positionScreen.z *= invW; vertex.visible = positionScreen.x >= - 1 && positionScreen.x = - 1 && positionScreen.y = - 1 && positionScreen.z","link":"/lib/three/lib/Projector.js"},{"title":"","text":"$(function () { var SEPARATION = 100, AMOUNTX = 50, AMOUNTY = 50; var container; var camera, scene, renderer; var particles, particle, count = 0; var mouseX = 0, mouseY = 0; var windowHalfX = window.innerWidth / 2; var windowHalfY = window.innerHeight / 2; init(); animate(); function init() { container = document.createElement(\"div\"); container.style.position = \"fixed\"; container.style.top = \"0px\"; container.style.left = \"0px\"; container.style.zIndex = \"-1\"; container.style.opacity = \"0.5\"; document.body.appendChild(container); camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 1, 10000); camera.position.z = 1000; scene = new THREE.Scene(); particles = new Array(); var PI2 = Math.PI * 2; var material = new THREE.SpriteCanvasMaterial({ color: 10263708, program: function (context) { context.beginPath(); context.arc(0, 0, 0.5, 0, PI2, true); context.fill() } }); var i = 0; for (var ix = 0; ix < AMOUNTX; ix++) { for (var iy = 0; iy < AMOUNTY; iy++) { particle = particles[i++] = new THREE.Sprite(material); particle.position.x = ix * SEPARATION - ((AMOUNTX * SEPARATION) / 2); particle.position.z = iy * SEPARATION - ((AMOUNTY * SEPARATION) / 2); scene.add(particle) } } renderer = new THREE.CanvasRenderer({ alpha: true }); renderer.setPixelRatio(window.devicePixelRatio); renderer.setSize(window.innerWidth, window.innerHeight); container.appendChild(renderer.domElement); document.addEventListener(\"mousemove\", onDocumentMouseMove, false); window.addEventListener(\"resize\", onWindowResize, false) } function onWindowResize() { windowHalfX = window.innerWidth / 2; windowHalfY = window.innerHeight / 2; camera.aspect = window.innerWidth / window.innerHeight; camera.updateProjectionMatrix(); renderer.setSize(window.innerWidth, window.innerHeight) } function onDocumentMouseMove(event) { mouseX = event.clientX - windowHalfX } function animate() { requestAnimationFrame(animate); render() } function render() { camera.position.x += (mouseX - camera.position.x) * 0.05; camera.position.y = 362.05; camera.lookAt({ x: scene.position.x, y: window.innerHeight / 3, z: scene.position.z }); var i = 0; for (var ix = 0; ix < AMOUNTX; ix++) { for (var iy = 0; iy < AMOUNTY; iy++) { particle = particles[i++]; particle.position.y = (Math.sin((ix + count) * 0.3) * 50) + (Math.sin((iy + count) * 0.5) * 50); particle.scale.x = particle.scale.y = (Math.sin((ix + count) * 0.3) + 1) * 4 + (Math.sin((iy + count) * 0.5) + 1) * 4 } } renderer.render(scene, camera); count += 0.1 } });","link":"/lib/three/src/three-waves.js"},{"title":"","text":"/** * Created by Tang on 2017/4/15. */ $(function () { var SCREEN_WIDTH = window.innerWidth, SCREEN_HEIGHT = window.innerHeight, mouseX = 0, mouseY = 0, windowHalfX = window.innerWidth / 2, windowHalfY = window.innerHeight / 2, SEPARATION = 200, AMOUNTX = 10, AMOUNTY = 10, camera, scene, renderer; init(); animate(); function init() { var container, separation = 100, amountX = 50, amountY = 50, particles, particle; container = document.createElement('div'); // 设置css container.style.position = \"fixed\"; container.style.top = \"0px\"; container.style.left = \"0px\"; container.style.zIndex = \"-1\"; container.style.opacity = \"0.5\"; document.body.appendChild(container); camera = new THREE.PerspectiveCamera(75, SCREEN_WIDTH / SCREEN_HEIGHT, 1, 10000); camera.position.z = 1000; scene = new THREE.Scene(); renderer = new THREE.CanvasRenderer({ alpha: true }); renderer.setPixelRatio(window.devicePixelRatio); renderer.setSize(SCREEN_WIDTH, SCREEN_HEIGHT); container.appendChild(renderer.domElement); // particles var PI2 = Math.PI * 2; var material = new THREE.SpriteCanvasMaterial({ color: 10263708, program: function (context) { context.beginPath(); context.arc(0, 0, 0.5, 0, PI2, true); context.fill(); } }); for (var i = 0; i < 1000; i++) { particle = new THREE.Sprite(material); particle.position.x = Math.random() * 2 - 1; particle.position.y = Math.random() * 2 - 1; particle.position.z = Math.random() * 2 - 1; particle.position.normalize(); particle.position.multiplyScalar(Math.random() * 10 + 450); particle.scale.multiplyScalar(2); scene.add(particle); } // lines for (var i = 0; i < 300; i++) { var geometry = new THREE.Geometry(); var vertex = new THREE.Vector3(Math.random() * 2 - 1, Math.random() * 2 - 1, Math.random() * 2 - 1); vertex.normalize(); vertex.multiplyScalar(450); geometry.vertices.push(vertex); var vertex2 = vertex.clone(); vertex2.multiplyScalar(Math.random() * 0.3 + 1); geometry.vertices.push(vertex2); var line = new THREE.Line(geometry, new THREE.LineBasicMaterial({ color: 10263708, opacity: Math.random() })); scene.add(line); } document.addEventListener('mousemove', onDocumentMouseMove, false); document.addEventListener('touchstart', onDocumentTouchStart, false); document.addEventListener('touchmove', onDocumentTouchMove, false); // window.addEventListener('resize', onWindowResize, false); } function onWindowResize() { windowHalfX = window.innerWidth / 2; windowHalfY = window.innerHeight / 2; camera.aspect = window.innerWidth / window.innerHeight; camera.updateProjectionMatrix(); renderer.setSize(window.innerWidth, window.innerHeight); } // function onDocumentMouseMove(event) { mouseX = event.clientX - windowHalfX; mouseY = event.clientY - windowHalfY; } function onDocumentTouchStart(event) { if (event.touches.length > 1) { //event.preventDefault(); mouseX = event.touches[0].pageX - windowHalfX; //mouseY = event.touches[ 0 ].pageY - windowHalfY; } } function onDocumentTouchMove(event) { if (event.touches.length == 1) { //event.preventDefault(); mouseX = event.touches[0].pageX - windowHalfX; //mouseY = event.touches[ 0 ].pageY - windowHalfY; } } // function animate() { requestAnimationFrame(animate); render(); } function render() { camera.position.x += (mouseX - camera.position.x) * .05; camera.position.y += (-mouseY + 200 - camera.position.y) * .05; camera.lookAt(scene.position); renderer.render(scene, camera); } })","link":"/lib/three/src/canvas_sphere.js"},{"title":"","text":"/** * Created by Tang on 2017/4/15. */ $(function () { var mouseX = 0, mouseY = 0, windowHalfX = window.innerWidth / 2, windowHalfY = window.innerHeight / 2, SEPARATION = 200, AMOUNTX = 10, AMOUNTY = 10, camera, scene, renderer; init(); animate(); function init() { var container, separation = 100, amountX = 50, amountY = 50, particles, particle; container = document.createElement('div'); // 设置css container.style.position = \"fixed\"; container.style.top = \"0px\"; container.style.left = \"0px\"; container.style.zIndex = \"-1\"; container.style.opacity = \"0.5\"; document.body.appendChild(container); camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 1, 10000); camera.position.z = 100; scene = new THREE.Scene(); renderer = new THREE.CanvasRenderer({ alpha: true }); renderer.setPixelRatio(window.devicePixelRatio); renderer.setSize(window.innerWidth, window.innerHeight); container.appendChild(renderer.domElement); // particles var PI2 = Math.PI * 2; var material = new THREE.SpriteCanvasMaterial({ color: 10263708, program: function (context) { context.beginPath(); context.arc(0, 0, 0.5, 0, PI2, true); context.fill(); } }); var geometry = new THREE.Geometry(); for (var i = 0; i < 100; i++) { particle = new THREE.Sprite(material); particle.position.x = Math.random() * 2 - 1; particle.position.y = Math.random() * 2 - 1; particle.position.z = Math.random() * 2 - 1; particle.position.normalize(); particle.position.multiplyScalar(Math.random() * 10 + 450); particle.scale.x = particle.scale.y = 10; scene.add(particle); geometry.vertices.push(particle.position); } // lines var line = new THREE.Line(geometry, new THREE.LineBasicMaterial({ color: 10263708, opacity: 0.5 })); scene.add(line); document.addEventListener('mousemove', onDocumentMouseMove, false); document.addEventListener('touchstart', onDocumentTouchStart, false); document.addEventListener('touchmove', onDocumentTouchMove, false); // window.addEventListener('resize', onWindowResize, false); } function onWindowResize() { windowHalfX = window.innerWidth / 2; windowHalfY = window.innerHeight / 2; camera.aspect = window.innerWidth / window.innerHeight; camera.updateProjectionMatrix(); renderer.setSize(window.innerWidth, window.innerHeight); } // function onDocumentMouseMove(event) { mouseX = event.clientX - windowHalfX; mouseY = event.clientY - windowHalfY; } function onDocumentTouchStart(event) { if (event.touches.length > 1) { //event.preventDefault(); mouseX = event.touches[0].pageX - windowHalfX; //mouseY = event.touches[ 0 ].pageY - windowHalfY; } } function onDocumentTouchMove(event) { if (event.touches.length == 1) { //event.preventDefault(); mouseX = event.touches[0].pageX - windowHalfX; //mouseY = event.touches[ 0 ].pageY - windowHalfY; } } // function animate() { requestAnimationFrame(animate); render(); } function render() { camera.position.x += (mouseX - camera.position.x) * .05; camera.position.y += (-mouseY + 200 - camera.position.y) * .05; camera.lookAt(scene.position); renderer.render(scene, camera); } })","link":"/lib/three/src/canvas_lines.js"},{"title":"","text":"// threejs.org/license (function(l,pa){\"object\"===typeof exports&&\"undefined\"!==typeof module?pa(exports):\"function\"===typeof define&&define.amd?define([\"exports\"],pa):pa(l.THREE=l.THREE||{})})(this,function(l){function pa(){}function D(a,b){this.x=a||0;this.y=b||0}function ea(a,b,c,d,e,f,g,h,m,k){Object.defineProperty(this,\"id\",{value:Ze++});this.uuid=N.generateUUID();this.name=\"\";this.image=void 0!==a?a:ea.DEFAULT_IMAGE;this.mipmaps=[];this.mapping=void 0!==b?b:ea.DEFAULT_MAPPING;this.wrapS=void 0!==c?c:1001;this.wrapT= void 0!==d?d:1001;this.magFilter=void 0!==e?e:1006;this.minFilter=void 0!==f?f:1008;this.anisotropy=void 0!==m?m:1;this.format=void 0!==g?g:1023;this.type=void 0!==h?h:1009;this.offset=new D(0,0);this.repeat=new D(1,1);this.generateMipmaps=!0;this.premultiplyAlpha=!1;this.flipY=!0;this.unpackAlignment=4;this.encoding=void 0!==k?k:3E3;this.version=0;this.onUpdate=null}function fa(a,b,c,d){this.x=a||0;this.y=b||0;this.z=c||0;this.w=void 0!==d?d:1}function Ya(a,b,c){this.uuid=N.generateUUID();this.width= a;this.height=b;this.scissor=new fa(0,0,a,b);this.scissorTest=!1;this.viewport=new fa(0,0,a,b);c=c||{};void 0===c.minFilter&&(c.minFilter=1006);this.texture=new ea(void 0,void 0,c.wrapS,c.wrapT,c.magFilter,c.minFilter,c.format,c.type,c.anisotropy,c.encoding);this.depthBuffer=void 0!==c.depthBuffer?c.depthBuffer:!0;this.stencilBuffer=void 0!==c.stencilBuffer?c.stencilBuffer:!0;this.depthTexture=void 0!==c.depthTexture?c.depthTexture:null}function Gb(a,b,c){Ya.call(this,a,b,c);this.activeMipMapLevel= this.activeCubeFace=0}function ca(a,b,c,d){this._x=a||0;this._y=b||0;this._z=c||0;this._w=void 0!==d?d:1}function q(a,b,c){this.x=a||0;this.y=b||0;this.z=c||0}function S(){this.elements=new Float32Array([1,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1]);0= d||0","link":"/lib/three/three.min.js"}],"posts":[{"title":"HashMap和ConcurrentHashMap源码分析！","text":"HashMap和ConcurrentHashMap源码分析！ jdk8中的HashMapHashMap的构造方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable { //The default initial //默认值 private static final long serialVersionUID = 362498820763181265L; static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; static final float DEFAULT_LOAD_FACTOR = 0.75f; static final int TREEIFY_THRESHOLD = 8;//默认链表转换成红黑树的阈值 static final int UNTREEIFY_THRESHOLD = 6;//红黑树退化成链表的阈值，6能避免7&lt;-&gt;8之间的频繁转换 static final int MIN_TREEIFY_CAPACITY = 64;//最小的红黑树值，即使链表大于8但是size小于64，不会变成红黑树 transient Node&lt;K,V&gt;[] table;//Entry节点变为Node节点 transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; transient int size; transient int modCount; int threshold; final float loadFactor; transient int modCount; //单链表节点 static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; V value; Node&lt;K,V&gt; next; } //构造函数 public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; //tableSizeFor 会计算一个大于或等于 initialCapacity 的 2 的 N 次方的值作为初始化容量，hashMap使用threshold暂时保存容量值。 this.threshold = tableSizeFor(initialCapacity); } put()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156public V put(K key, V value) { //计算hash值并调用putVal()方法 return putVal(hash(key), key, value, false, true); }static final int hash(Object key) { int h; //右移16位后再异或，hash函数的扰动函数，让高位地位异或，分布更加平均 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); }final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //初始化桶数组table，table被延迟到插入新数据时再进行初始化 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //如果桶中不包含键值对节点引用，则将新键值对节点的引用存入桶中即可 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else { Node&lt;K,V&gt; e; K k; // 如果键的值以及节点hash等于链表中的第一个键值对节点时，则将e指向该键值对 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果桶中的引用类型为 TreeNode，则调用红黑树的插入方法 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else {//对链表进行遍历，并统计链表长度 for (int binCount = 0; ; ++binCount) { //链表中不包含要插入的键值对节点时，则将该节点接在链表的最后 if ((e = p.next) == null) { //尾插法插入新节点 p.next = newNode(hash, key, value, null); // 如果链表长度大于或等于树化阈值，则进行树化操作 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; } // 条件为 true，表示当前链表包含要插入的键值对，终止遍历 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; } } // 判断要插入的键值对是否存在 HashMap 中，若存在，则返回旧value并更新value if (e != null) { // existing mapping for key V oldValue = e.value; //onlyIfAbsent 表示是否仅在 oldValue 为 null 的情况下更新键值对的值 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; } } ++modCount;//fast-fail机制 // 键值对数量超过阈值时，则进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null; }//java8中的扩容机制final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; //如果容量不为空，则说明已经初始化。 if (oldCap &gt; 0) { if (oldCap &gt;= MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return oldTab; } //按旧容量和阀值的2倍计算新容量和阀值 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold } //如果容量为空，但threshold不为空，则开始初始化过程，将threshold赋给容量capacity。 else if (oldThr &gt; 0) // initial capacity was placed in threshold //初始化时，将 threshold 的值赋值给 newCap， //**// HashMap 使用 threshold 变量暂时保存 initialCapacity 参数的值 newCap = oldThr; else { // zero initial threshold signifies using defaults // 调用无参构造方法时，数组桶数组容量为默认容量 1 &lt;&lt; 4; aka 16 // 阀值；是默认容量与负载因子的乘积，0.75 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } //newThr为0，则使用阀值公式计算阈值 if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\"rawtypes\",\"unchecked\"}) //初始化数组桶table[] Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) { // 如果旧数组桶，oldCap有值，则遍历将键值映射到新数组桶中 for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; //如果oldTable[j]位置存在元素 if ((e = oldTab[j]) != null) { oldTab[j] = null;//清空oldTable[j]桶位置上的元素 if (e.next == null)//如果该桶只有一个元素，不是链表也不是红黑树 newTab[e.hash &amp; (newCap - 1)] = e;//重新计算索引并赋值 else if (e instanceof TreeNode) // 这里split，是红黑树拆分操作。在重新映射时操作的。 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order //对链表进行操作 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; //java8通过巧妙的方式避免了重新计算key.hash值,两组为：1.在原索引处不变。2.原索引+原容量。 Node&lt;K,V&gt; next; do { next = e.next; //如果e.hash &amp; oldCap == 0 则该元素在原索引处不动，在新数组中仍是该位置 if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } //否则该元素分到另一组，准备另一个索引 else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null);//遍历链表结束退出 //移动元素到新table[]指定索引。 if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } return newTab; } java8中的ConcurrentHashMapjdk1.8后，ConcurrentHashMap摒弃了segment的思想，转而使用cas+synchronized组合的方式来实现并发下的线程安全的 构造方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class ConcurrentHashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements ConcurrentMap&lt;K,V&gt;, Serializable { //用来控制数组的初始化和扩容的，默认值为0 //a、sizeCtr=0：默认值； //b、sizeCtr=-1：表示Map正在初始化中； //c、sizeCtr=-N：表示正在有N-1个线程进行扩容操作； //d、sizeCtr&gt;0: 未初始化则表示初始化Map的大小，已初始化则表示下次进行扩容操作的阈值； private transient volatile int sizeCtl; //用于存储链表或红黑数的数组，初始值为null，在第一次进行put操作的时候进行初始化，默认值为16； transient volatile Node&lt;K,V&gt;[] table; //在扩容时新生成的数组，其大小为当前table的2倍，用于存放table转移过来的值； private transient volatile Node&lt;K,V&gt;[] nextTable; //保存每个node节点中元素的数量 private transient volatile CounterCell[] counterCells;static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; volatile V val; //volatile 保证内存的可见性 volatile Node&lt;K,V&gt; next; //......}//ForwardingNode是一种临时节点只有扩容时使用，表明当前桶已做过处理。这是一个特殊Node节点，仅在进行扩容时用作占位符，表示当前位置已被移动或者为null，该node节点的hash值为-1；static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; { final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) { super(MOVED, null, null, null); this.nextTable = tab; } //......}public ConcurrentHashMap(int initialCapacity) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap; }public ConcurrentHashMap(int initialCapacity, float loadFactor) { this(initialCapacity, loadFactor, 1); }public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) { if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins initialCapacity = concurrencyLevel; // as estimated threads long size = (long)(1.0 + (long)initialCapacity / loadFactor); int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); this.sizeCtl = cap; }} put()方法详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396public V put(K key, V value) { return putVal(key, value, false); }final V putVal(K key, V value, boolean onlyIfAbsent) { if (key == null || value == null) throw new NullPointerException();//不允许放入null key int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) { Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0)//如果table未被初始化，调用initTable()初始化方法 tab = initTable();//初始化 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) { //得到table[index]节点，如果为空，直接CAS操作插入新节点。 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin } //如果不为空，说明存在哈希碰撞，当fh==MOED(-1),该插入的位置是表的连接点，说明数组正在扩容 else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f);//帮助当前线程扩容 //插入到该位置已有数据的节点上，即有hash冲突 //在这里为保证线程安全，会对当前数组位置上的第一个节点进行加锁，因此其他位置上 //仍然可以进行插入，这里就是jdk1.8相较于之前版本使用segment作为锁性能要高效的地方 else { V oldVal = null; //锁住该位置上第一个节点 synchronized (f) { //再一次判断f节点是否为第一个节点，防止其他线程已修改f节点 if (tabAt(tab, i) == f) { if (fh &gt;= 0) {//为链表 binCount = 1; for (Node&lt;K,V&gt; e = f;; ++binCount) {//将节点放入链表中 K ek; //如果已经存在相同key，则覆盖旧值并返回旧值 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) { oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; } Node&lt;K,V&gt; pred = e; //遍历到最后一个节点没有发现相等的key，尾插法插入新节点 if ((e = e.next) == null) { pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; } } } else if (f instanceof TreeBin) {//为红黑树 //为什么当前节点的hash&lt;0说明是红黑树结构？答案在TreeBin的构造方法中，将红黑树的节点.hash初始化为-2. Node&lt;K,V&gt; p; binCount = 2; //将节点插入红黑树中 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) { oldVal = p.val; if (!onlyIfAbsent) p.val = value; } } } }//结束，释放synchronized锁 //插入成功后判断插入数据所在位置上的节点数量， //如果数量达到了转化红黑树的阈值，则进行转换 if (binCount != 0) { if (binCount &gt;= TREEIFY_THRESHOLD) treeifyBin(tab, i); if (oldVal != null) return oldVal; break; } } } //使用cas统计数量增加1，同时判断是否满足扩容需求，进行扩容 addCount(1L, binCount); return null; } private final Node&lt;K,V&gt;[] initTable() { Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) { //若sizeCtl&lt;0，即存在其他线程正在初始化操作，确保只有一个线程进行初始化 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin //只能有一个线程执行初始化，必须挂起，执行yield()方法让出CPU时间片 //利用CAS方法把sizectl的值置为-1，表明已有线程进行初始化 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) { try { if ((tab = table) == null || tab.length == 0) { //获取table[]初始化容量 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings(\"unchecked\") //初始化Node[]数组并赋值 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; //计算扩容阈值0.75n : (n-n*3/4); sc = n - (n &gt;&gt;&gt; 2); } } finally { //Node[]已经初始化，则sizeCtl存储下一次的扩容阈值。 sizeCtl = sc; } break; } } return tab; }//计算由key.hascode()的hash值static final int spread(int h) { return (h ^ (h &gt;&gt;&gt; 16)) &amp; HASH_BITS; }//当扩容正在进行时，并发扩容提高扩容的速度final Node&lt;K,V&gt;[] helpTransfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt; f) { Node&lt;K,V&gt;[] nextTab; int sc; if (tab != null &amp;&amp; (f instanceof ForwardingNode) &amp;&amp; (nextTab = ((ForwardingNode&lt;K,V&gt;)f).nextTable) != null) { int rs = resizeStamp(tab.length); while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) { if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || transferIndex &lt;= 0) break; if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) { transfer(tab, nextTab); break; } } return nextTab; } return table; }//concurrentHashMap如何并发获得size大小？public int size() { long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n); }final long sumCount() { //这里保存了一份CounterCell数组，然后将每个数组的长度相加得到了size。那么CounterCell是什么？ CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; if (as != null) { for (int i = 0; i &lt; as.length; ++i) { if ((a = as[i]) != null) sum += a.value; } } return sum; }//它只有一个使用volatile修饰的属性value和构造。那么CounterCell数组是在哪里进行维护的？@sun.misc.Contended static final class CounterCell { volatile long value; CounterCell(long x) { value = x; } }//put()方法中的andCount()方法，相应的remove()中也有该方法，用来维护CounterCell[];private final void addCount(long x, int check) { CounterCell[] as; long b, s; // 给容器中的元素进行增或者减 // 如果 cs 不为 null（说明有并发情况）或者 baseCount 增减运算失败， if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) { CounterCell a; long v; int m; boolean uncontended = true; // 那么就会通过 cs 来进行计数。 // 如果 cs 是空（还不是并发）或者 (cs 中随机取余一个数组位置为空 或者 cs 这个位置的变量失败） // 说明通过 cs 来计数也失败了，最后才会调用 fullAddCount 来进行计数 if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) { // 与 LongAdder 实现一致，可以理解为并发情况下的一个计数器 fullAddCount(x, uncontended); return; } if (check &lt;= 1) return; // 统计当前节点的数量，与sizeCtl做比，判断是否扩容 s = sumCount(); } // 在增加元素的操作中 check 都会满足这个条件 if (check &gt;= 0) { // 检查扩容条件： // 1. 是否达到阀值: s &gt;= sizeCtl （上文已经解释了 sizeCtl，sizeCtl 大于 0 时表示下次扩容的临界点） // 2. 是否可以扩容: tab != null &amp;&amp; tab 当前的长度小于 1 &lt;&lt; 30 Node&lt;K,V&gt;[] tab, nt; int n, sc; while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) { // 根据当前桶的数量生成一个标志位 int rs = resizeStamp(n); // 如果正在扩容 if (sc &lt; 0) {// 检查当前扩容的进展: // 1. 如果 sc 的低 16 位不等于标识位（ sizeCtl 变化了，说明容器状态已经变化），退出 // 2. 如果 sc == 标识位 + 1 （通过下面代码可知，刚开始扩容时， sc = rs + 2，如果 sc = rs + 1，说明已经没有线程在扩容），退出 // 3. 如果 sc == 标识符 + 65535，参与扩容的线程已经达到最大数量，当前线程不再参与，退出 // 4. 如果 nextTable == null 说明扩容结束（nextTable 在扩容中起中转作用，所有的元素会被限移到 nextTable 中，最后让 tab = nextTable，nextTable == null 来完成扩容），退出 // 5. transferIndex &lt;= 0 说明没有桶还需要迁移了（transferIndex 用于标识当前迁移到哪个桶了，小于等于 0 说明已经迁移到最后一个桶或者已经迁移完成，迁移的顺序是从最后一个桶开始），退出。 if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 如果迁移还是进行，当前线程尝试参与扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); } // 如果当前不在扩容中，则发起一个新的扩容 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); // 统计当前节点的数量 s = sumCount(); } } }//扩容方法！重要！/** transferIndex 表示转移时的下标，初始为扩容前的 length。*/private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) { int n = tab.length, stride; // 将 length / 8 然后除以 CPU核心数。如果得到的结果小于 16，那么就使用 16。 // 这里的目的是让每个 CPU 处理的桶一样多，避免出现转移任务不均匀的现象，如果桶较少的话，默认一个 CPU（一个线程）处理 16 个桶 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range 细分范围 stridea：TODO // 新的 table 尚未初始化 if (nextTab == null) { // initiating try { // 扩容 2 倍 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; // 更新 nextTab = nt; } catch (Throwable ex) { // try to cope with OOME // 扩容失败， sizeCtl 使用 int 最大值。 sizeCtl = Integer.MAX_VALUE; return;// 结束 } // 更新成员变量 nextTable = nextTab; // 更新转移下标，就是 老的 tab 的 length transferIndex = n; } // 新 tab 的 length int nextn = nextTab.length; // 创建一个 fwd 节点，用于占位。当别的线程发现这个槽位中是 fwd 类型的节点，则跳过这个节点。 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); // 首次推进为 true，如果等于 true，说明需要再次推进一个下标（i--），反之，如果是 false，那么就不能推进下标，需要将当前的下标处理完毕才能继续推进 boolean advance = true; // 完成状态，如果是 true，就结束此方法。 boolean finishing = false; // to ensure sweep before committing nextTab // 死循环,i 表示下标，bound 表示当前线程可以处理的当前桶区间最小下标 for (int i = 0, bound = 0;;) { Node&lt;K,V&gt; f; int fh; // 如果当前线程可以向后推进；这个循环就是控制 i 递减。同时，每个线程都会进入这里取得自己需要转移的桶的区间 while (advance) { int nextIndex, nextBound; // 对 i 减一，判断是否大于等于 bound （正常情况下，如果大于 bound 不成立，说明该线程上次领取的任务已经完成了。那么，需要在下面继续领取任务） // 如果对 i 减一大于等于 bound（还需要继续做任务），或者完成了，修改推进状态为 false，不能推进了。任务成功后修改推进状态为 true。 // 通常，第一次进入循环，i-- 这个判断会无法通过，从而走下面的 nextIndex 赋值操作（获取最新的转移下标）。其余情况都是：如果可以推进，将 i 减一，然后修改成不可推进。如果 i 对应的桶处理成功了，改成可以推进。 if (--i &gt;= bound || finishing) advance = false;// 这里设置 false，是为了防止在没有成功处理一个桶的情况下却进行了推进 // 这里的目的是：1. 当一个线程进入时，会选取最新的转移下标。2. 当一个线程处理完自己的区间时，如果还有剩余区间的没有别的线程处理。再次获取区间。 else if ((nextIndex = transferIndex) &lt;= 0) { // 如果小于等于0，说明没有区间了 ，i 改成 -1，推进状态变成 false，不再推进，表示，扩容结束了，当前线程可以退出了 // 这个 -1 会在下面的 if 块里判断，从而进入完成状态判断 i = -1; advance = false;// 这里设置 false，是为了防止在没有成功处理一个桶的情况下却进行了推进 }// CAS 修改 transferIndex，即 length - 区间值，留下剩余的区间值供后面的线程使用 else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) { bound = nextBound;// 这个值就是当前线程可以处理的最小当前区间最小下标 i = nextIndex - 1; // 初次对i 赋值，这个就是当前线程可以处理的当前区间的最大下标 advance = false; // 这里设置 false，是为了防止在没有成功处理一个桶的情况下却进行了推进，这样对导致漏掉某个桶。下面的 if (tabAt(tab, i) == f) 判断会出现这样的情况。 } }// 如果 i 小于0 （不在 tab 下标内，按照上面的判断，领取最后一段区间的线程扩容结束） // 如果 i &gt;= tab.length(不知道为什么这么判断) // 如果 i + tab.length &gt;= nextTable.length （不知道为什么这么判断） if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) { int sc; if (finishing) { // 如果完成了扩容 nextTable = null;// 删除成员变量 table = nextTab;// 更新 table sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); // 更新阈值 return;// 结束方法。 }// 如果没完成 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {// 尝试将 sc -1. 表示这个线程结束帮助扩容了，将 sc 的低 16 位减一。 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT)// 如果 sc - 2 不等于标识符左移 16 位。如果他们相等了，说明没有线程在帮助他们扩容了。也就是说，扩容结束了。 return;// 不相等，说明没结束，当前线程结束方法。 finishing = advance = true;// 如果相等，扩容结束了，更新 finising 变量 i = n; // 再次循环检查一下整张表 } } else if ((f = tabAt(tab, i)) == null) // 获取老 tab i 下标位置的变量，如果是 null，就使用 fwd 占位。 advance = casTabAt(tab, i, null, fwd);// 如果成功写入 fwd 占位，再次推进一个下标 else if ((fh = f.hash) == MOVED)// 如果不是 null 且 hash 值是 MOVED。 advance = true; // already processed // 说明别的线程已经处理过了，再次推进一个下标 else {// 到这里，说明这个位置有实际值了，且不是占位符。对这个节点上锁。为什么上锁，防止 putVal 的时候向链表插入数据 synchronized (f) { // 判断 i 下标处的桶节点是否和 f 相同 if (tabAt(tab, i) == f) { Node&lt;K,V&gt; ln, hn;// low, height 高位桶，低位桶 // 如果 f 的 hash 值大于 0 。TreeBin 的 hash 是 -2 if (fh &gt;= 0) { // 对老长度进行与运算（第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为0） // 由于 Map 的长度都是 2 的次方（000001000 这类的数字），那么取于 length 只有 2 种结果，一种是 0，一种是1 // 如果是结果是0 ，Doug Lea 将其放在低位，反之放在高位，目的是将链表重新 hash，放到对应的位置上，让新的取于算法能够击中他。 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; // 尾节点，且和头节点的 hash 值取于不相等 // 遍历这个桶 for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) { // 取于桶中每个节点的 hash 值 int b = p.hash &amp; n; // 如果节点的 hash 值和首节点的 hash 值取于结果不同 if (b != runBit) { runBit = b; // 更新 runBit，用于下面判断 lastRun 该赋值给 ln 还是 hn。 lastRun = p; // 这个 lastRun 保证后面的节点与自己的取于值相同，避免后面没有必要的循环 } } if (runBit == 0) {// 如果最后更新的 runBit 是 0 ，设置低位节点 ln = lastRun; hn = null; } else { hn = lastRun; // 如果最后更新的 runBit 是 1， 设置高位节点 ln = null; }// 再次循环，生成两个链表，lastRun 作为停止条件，这样就是避免无谓的循环（lastRun 后面都是相同的取于结果） for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) { int ph = p.hash; K pk = p.key; V pv = p.val; // 如果与运算结果是 0，那么就还在低位 if ((ph &amp; n) == 0) // 如果是0 ，那么创建低位节点 ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else // 1 则创建高位 hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); } // 其实这里类似 hashMap // 设置低位链表放在新链表的 i setTabAt(nextTab, i, ln); // 设置高位链表，在原有长度上加 n setTabAt(nextTab, i + n, hn); // 将旧的链表设置成占位符 setTabAt(tab, i, fwd); // 继续向后推进 advance = true; }// 如果是红黑树 else if (f instanceof TreeBin) { TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; // 遍历 for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) { int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); // 和链表相同的判断，与运算 == 0 的放在低位 if ((h &amp; n) == 0) { if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; } // 不是 0 的放在高位 else { if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; } } // 如果树的节点数小于等于 6，那么转成链表，反之，创建一个新的树 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; // 低位树 setTabAt(nextTab, i, ln); // 高位数 setTabAt(nextTab, i + n, hn); // 旧的设置成占位符 setTabAt(tab, i, fwd); // 继续向后推进 advance = true; } } } } }} jdk7中的HashMapHashMap构造123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable{ //默认值定义 static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; static final float DEFAULT_LOAD_FACTOR = 0.75f; static final Entry&lt;?,?&gt;[] EMPTY_TABLE = {};//默认是空数组，16的容量在put()方法时初始化。 transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE; transient int size; int threshold; final float loadFactor; transient int modCount; static final int ALTERNATIVE_HASHING_THRESHOLD_DEFAULT = Integer.MAX_VALUE; transient int hashSeed = 0; //单链表元素节点 static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final K key; V value; Entry&lt;K,V&gt; next; int hash; } //构造函数 public HashMap() { this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR); } public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; init();//一个钩子 }} put()方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495public V put(K key, V value) { //如果table为空，初始化表 if (table == EMPTY_TABLE) { inflateTable(threshold); } //如果key是null，调用put null 方法 if (key == null) return putForNullKey(value);//其实是把null的key都放入table[0]的位置 //计算key的hash值 int hash = hash(key); //通过key的hash值'与'的方式，找到(key,value)在table[]中的位置。 int i = indexFor(hash, table.length); //遍历链表查找在table[i]位置是否已经存在该key值，存在则返回旧值并修改，否则头插法添加新节点 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++;//fast-fail机制 addEntry(hash, key, value, i); return null; } private void inflateTable(int toSize) { // Find a power of 2 &gt;= toSize int capacity = roundUpToPowerOf2(toSize); threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); table = new Entry[capacity]; initHashSeedAsNeeded(capacity); }static int indexFor(int h, int length) { // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; return h &amp; (length-1); }//判断上一次扩容后，是否达到阈值，若达到需要扩容，否则再开始插入新节点void addEntry(int hash, K key, V value, int bucketIndex) { //如果添加元素前超过阈值，并且table[bucketIndex]不为null，则先扩容 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) { //2倍扩容 resize(2 * table.length); //重新计算key的hash值，而1.8中HashMap不需要重新计算hash值 hash = (null != key) ? hash(key) : 0; //根据新hash值重新找到索引位置 bucketIndex = indexFor(hash, table.length); } createEntry(hash, key, value, bucketIndex); }//创建新节点，并头插法添加入table[bucketIndex]中void createEntry(int hash, K key, V value, int bucketIndex) { Entry&lt;K,V&gt; e = table[bucketIndex]; //e作为新节点的next，是头插法 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++; }//扩容方法！！！由于头插法复制，多线程下会产生循环死链问题！void resize(int newCapacity) { Entry[] oldTable = table;//旧table[] int oldCapacity = oldTable.length;//旧容量 if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } Entry[] newTable = new Entry[newCapacity];//创建新table[]数组 //拷贝旧table[]中的所有数据，放入新table[]中 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable;//更换引用 //重新计算阈值 threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); }//拷贝方法：计算新index后头插法。void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) { while(null != e) { Entry&lt;K,V&gt; next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity);//计算新的索引位置 //头插法拷贝节点。 e.next = newTable[i]; newTable[i] = e; e = next; } } } get()方法12345678910111213141516171819202122232425public V get(Object key) { if (key == null) return getForNullKey();//去table[0]中找，返回第一个key==null的value，否则返回空 //进入实际get过程 Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue(); }final Entry&lt;K,V&gt; getEntry(Object key) { if (size == 0) { return null; } //简单的遍历index位置上的链表。 int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } return null; } HashMap线程不安全体现在哪些方面？由于hash冲突的时候插入链表，采用的是头插法，导致扩容后链表的顺序和原来顺序相反，多个线程同时扩容会出现环形链表，get的时候陷入死循环。resize()扩容方法也是头插法，同时扩容也会产生环形链表。 jdk7中的ConcurrentHashMapConcurrentHashMap的构造12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class ConcurrentHashMap&lt;K, V&gt; extends AbstractMap&lt;K, V&gt; implements ConcurrentMap&lt;K, V&gt;, Serializable { //The default initial capacity for this table, static final int DEFAULT_INITIAL_CAPACITY = 16;//默认初始化容量16表示的是HashEntry[]数组的大小 //The default load factor for this table static final float DEFAULT_LOAD_FACTOR = 0.75f;//默认加载因子，0.75 //The default concurrency level for this table static final int DEFAULT_CONCURRENCY_LEVEL = 16;//并发级别，为Segment数组大小，即默认Segment[]数组大小默认为16个，与初始化容量区分开。 //无参的默认构造函数 public ConcurrentHashMap() { this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL); } //构造函数的实现 public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) { if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments //查找最适合参数的2的幂 int sshift = 0; int ssize = 1;//Segment&lt;K,V&gt;[]初始化的容量参数,只能是2的倍数,用于(key,value)定位Segment定位Segment while (ssize &lt; concurrencyLevel) { ++sshift; ssize &lt;&lt;= 1; } this.segmentShift = 32 - sshift; this.segmentMask = ssize - 1;//用于(key,value)定位Segment if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; //计算segment中HashEntry数组的容量(长度). int cap = MIN_SEGMENT_TABLE_CAPACITY;//默认cap == 2,即使上一步的c==1,segment中的HashEntry数组容量最少是2. while (cap &lt; c) cap &lt;&lt;= 1;//cap只能是2的倍数,用于在segment中通过&amp;找到指定的HashEntry // create segments and segments[0] //创建segments并且只初始化segments[0]节点. //只初始化segments[0]的目的就是在之后进行put操作时，不用重复计算新的Segment中HashEntry的大小 Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize];//初始化Segment&lt;K,V&gt;[]后,不会再改变,扩容只在segment内部进行HashEntry的扩容,不再增加Segment节点. //通过CAS放入ss(Segment数组)的S[0]位置. UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0] this.segments = ss; }} DEFAULT_INITIAL_CAPACITY默认初始化容量16表示的是HashEntry[]数组的大小 DEFAULT_CONCURRENCY_LEVEL并发级别为Segment数组大小，即默认Segment[]数组大小默认为16个 ConcurrentHashMap的put()方法put的大致流程，假如现在要将一个(key,value)放入ConcurrentHashMap中，首先需要得到key的下标（index = key.hash() % Segment.length - 1）。但是，会发现当前位置为null，所以需要先生成一个Segment对象。在创建好Segment之后，再调用其put方法，通过key判断应该将其放入HashEntry中的哪个位置（index = hashCode &amp; hashEntry.length - 1） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193 public V put(K key, V value) { Segment&lt;K,V&gt; s; if (value == null)//ConcurrentHashMap不允许null的value插入. throw new NullPointerException(); int hash = hash(key); int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask;//首先计算hash值，确定这个元素应该放入Segment数组的哪一个位置。j即这个元素在Segment数组下标位置。 //if块中利用UNSAFE.getObject从对象头中求Segment数组中下标为 j 的segment，如果为空，s = ensureSegment(j);方法确保在Segment[j]位置新建一个segment. if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment s = ensureSegment(j); //已经有segment了,下一步保证并发安全的放入到Segment数组HashEntry中去 return s.put(key, hash, value, false); }private int hash(Object k) { int h = hashSeed; if ((0 != h) &amp;&amp; (k instanceof String)) { return sun.misc.Hashing.stringHash32((String) k); } h ^= k.hashCode(); // Spread bits to regularize both segment and index locations, // using variant of single-word Wang/Jenkins hash. h += (h &lt;&lt; 15) ^ 0xffffcd7d; h ^= (h &gt;&gt;&gt; 10); h += (h &lt;&lt; 3); h ^= (h &gt;&gt;&gt; 6); h += (h &lt;&lt; 2) + (h &lt;&lt; 14); return h ^ (h &gt;&gt;&gt; 16); }private Segment&lt;K,V&gt; ensureSegment(int k) { final Segment&lt;K,V&gt;[] ss = this.segments; long u = (k &lt;&lt; SSHIFT) + SBASE; // raw offset Segment&lt;K,V&gt; seg; if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) { //利用ConcurrentHashMap构造时候创建的Segment[0],确定HashEntry的长度 Segment&lt;K,V&gt; proto = ss[0]; // use segment 0 as prototype //按照Segment[0]中的属性进行Segment的创建 int cap = proto.table.length; float lf = proto.loadFactor; int threshold = (int)(cap * lf); HashEntry&lt;K,V&gt;[] tab = (HashEntry&lt;K,V&gt;[])new HashEntry[cap]; //再次检查该位置的segment是否为null，保证线程安全后，继续创建segment过程。 if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) { // recheck Segment&lt;K,V&gt; s = new Segment&lt;K,V&gt;(lf, threshold, tab); //自旋再次检查 while ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) { //最后利用CAS将新建的s赋值给指定位置的segment(seg)。 if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s)) break; } } } //返回新建的seg。 return seg; }final V put(K key, int hash, V value, boolean onlyIfAbsent) { //该方法在Segment类内部实现,segment类继承了ReentrantLock类，实现了可重入锁。 //tryLock()尝试获取该segment的锁 //如果获取到锁，node为null。否则进入scanAndLockForPut()方法继续尝试获得锁，并返回node。 HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try {//获取锁后执行try方法块 HashEntry&lt;K,V&gt;[] tab = table;//取出该segment中的HashEntry数组 int index = (tab.length - 1) &amp; hash;//计算(key,value)在HashEntry数组中的索引位置 HashEntry&lt;K,V&gt; first = entryAt(tab, index);//由tab和index得到该位置上的第一个HashEntry节点,由于新构造的HashEntry节点的next指向了first，可得知使用了头插法。 for (HashEntry&lt;K,V&gt; e = first;;) { if (e != null) {//如果当前HashEntry节点不是空，即已经有HashEntry占据该位置，遍历链表 K k; //如果新节点已经在HashEntry中存在，则执行以下逻辑并退出循环，否则继续遍历 if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) { oldValue = e.value; if (!onlyIfAbsent) { e.value = value; ++modCount; } break; } e = e.next;//继续遍历链表查找 } else {//当HashEntry中没有元素，或者是遍历到链表的最后一个空节点的时候，准备插入 if (node != null)//获取锁的过程中已经预热，创建了新的节点，则直接插入。 node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first);//创建新的HashEntry节点，并由于first参数，使用头插法 int c = count + 1;//HashEntry数组的长度加1 //如果数组大小达到该segment的阈值，就进行扩容，扩容行为只在本segment中发生，而不是整个cuncurrentHashMap中进行 if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else//如果没有扩容发生 setEntryAt(tab, index, node);//将node放入tab的第index个位置，相当于hashMap中的下移操作，即将新的HashEntry链表重新赋值给HashEntry位置 ++modCount;//fast-fail机制 count = c; oldValue = null; break; } } } finally { unlock(); } return oldValue; } private HashEntry&lt;K,V&gt; scanAndLockForPut(K key, int hash, V value) { HashEntry&lt;K,V&gt; first = entryForHash(this, hash);//取出对应hash值下标的HashEntry节点 HashEntry&lt;K,V&gt; e = first; HashEntry&lt;K,V&gt; node = null; int retries = -1; // negative while locating node while (!tryLock()) {//尝试获得锁 HashEntry&lt;K,V&gt; f; // to recheck first below if (retries &lt; 0) {//若没有创建node节点 if (e == null) {//如果first位置的HashEntry为null，去创建一个新节点node并最终返回 if (node == null) // speculatively create node node = new HashEntry&lt;K,V&gt;(hash, key, value, null); retries = 0;//创建之后，retries为0，下次不会再创建。 } else if (key.equals(e.key))//如果在链表中发现该节点 retries = 0; else e = e.next;//继续遍历链表 } else if (++retries &gt; MAX_SCAN_RETRIES) {//重试获得锁超过一定次数，变为lock()阻塞式获取锁 lock(); break; } else if ((retries &amp; 1) == 0 &amp;&amp;//偶数次时候判断 (f = entryForHash(this, hash)) != first) {//如果链表结构发生变化，重新获得first位置的节点 e = first = f; // re-traverse if entry changed retries = -1; } } return node;//如果index位置的HashEntry节点/链表中已经存在key，则返回null，不存在则返回新建的node节点 }private void rehash(HashEntry&lt;K,V&gt; node) { HashEntry&lt;K,V&gt;[] oldTable = table;//保存旧数组 int oldCapacity = oldTable.length;//旧容量 int newCapacity = oldCapacity &lt;&lt; 1;//新容量，是旧容量的2倍。 threshold = (int)(newCapacity * loadFactor);//新扩容阈值 HashEntry&lt;K,V&gt;[] newTable = //新创建HashEntry[]数组 (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity]; int sizeMask = newCapacity - 1; for (int i = 0; i &lt; oldCapacity ; i++) { HashEntry&lt;K,V&gt; e = oldTable[i];//HashEntry[i]的头节点 if (e != null) { HashEntry&lt;K,V&gt; next = e.next;//HashEntry[i]链表的下一个节点 int idx = e.hash &amp; sizeMask;//计算扩容后该节点在新数组的位置 if (next == null) // Single node on list //如果next==null说明HashEntry[i]只有一个节点，此时直接将e赋值到新位置即可 newTable[idx] = e; else { // Reuse consecutive sequence at same slot //如果是链表结构 //在链表中找到一个lastRun节点,该节点以及之后所有的节点都在新数组的lastInx位置，好处就是不用移动lastRun后面的元素结点，直接将lastRun移动到newTable[lastIdx]位置 HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) { int k = last.hash &amp; sizeMask; if (k != lastIdx) { lastIdx = k; lastRun = last; } } newTable[lastIdx] = lastRun; // Clone remaining nodes //lastRun节点移动之后，开始转移链表中的剩余元素 for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) { V v = p.value; int h = p.hash; int k = h &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n);//头插法将节点插入新数组 } } } } //rehash是在put时候进行，该步骤添加刚加入的node节点进入新数组，以上是旧节点的转移过程。 int nodeIndex = node.hash &amp; sizeMask; // add the new node //头插法插入，因为已经获得锁，所以是并发安全的 node.setNext(newTable[nodeIndex]); newTable[nodeIndex] = node; //更新segment的HashEntry[]引用 table = newTable; }","link":"/2020/10/21/HashMap,ConcurrentHashMap%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/"},{"title":"Java项目读取Resources资源文件路径那点事","text":"今天在Java程序中读取Resources资源下的文件，由于对Java结构了解不透彻，遇到很多坑。正常在Java工程中读取某路径下的文件时，可以采用绝对路径和相对路径，绝对路径没什么好说的，相对路径，即相对于当前类的路径。在本地工程和服务器中读取文件的方式有所不同: （1）本地读取资源文件 Java类中需要读取Properties中的配置文件，可以采用文件（File）方式进行读取： 12File file = new File(\"src/main/resources/properties/test.properties\");InputStream in = new FileInputStream(file); 注意：当在IDEA中运行（不部署在服务器上），可以读取到该文件； 理解：Java文件只有编译成class文件才会被JVM执行，本地执行时，当前项目即为Java进程的工作空间，虽然class文件在target/classes目录下，但是target/classes不是class文件运行的目录，只是存放的目录，运行目录还是在IDEA的模块下，所以运行时会找到 src/main/resources资源文件！ （2）服务器（Tomcat）读取资源文件当工程部署到Tomcat中时，按照上边方式，则会抛出异常：FileNotFoundException。 原因：JavaWeb项目部署服务器中，会将项目打包成Jar包或者war包，此时就不会存在 src/main/resources 目录，这是由Maven工程结构决定的。由Maven构建的web工程，主代码放在src/main/java路径下，资源放在src/main/resources路径下，当构建jar包 或 war包时，JVM虚拟机会自动编译java文件为class文件存放在target/classes目录下，resource资源下的文件会原封不动的拷贝一份到 target/classes目录下。 方式一：此时读取资源文件时，采用流（Stream）的方式读取，并通过JDK中Properties类加载，可以方便的获取到配置文件中的信息： 1234InputStream in = this.getClass().getResourceAsStream(\"/properties/test.properties\");Properties properties = new Properties();properties.load(in);properties.getProperty(\"name\"); 重点理解：class.getResourceAStream() 与 class.getClassLoader().getResorceAsStream() 的区别 123InputStream inStream = PropertiesTest.class.getResourceAsStream(\"test.properties\"); inStream =PropertiesTest.class.getResourceAsStream(\"/com/test/demo/test.properties\")inStream=PropertiesTest.class.getClassLoader().getResourceAsStream(\"com/test/demo/test.properties\"); 1）第一种和第二种方式采用 Class 对象去加载，第三种方式采用 ClassLoader 对象去加载资源文件，之所以Class可以加载资源文件，是因为Class类封装的 ClassLoader 的 getResourceAsStream()方法，从 Class类中的源码可以看出： 12345678public InputStream getResourceAsStream(String name) { name = resolveName(name); ClassLoader cl = getClassLoader0(); if(cl==null) { // A system class. return ClassLoader.getSystemResourceAsStream(name); } return cl.getResourceAsStream(name);} 理由：之所以这样做无疑还是方便客户端的调用，省的每次获取ClassLoader才能加载资源文件的麻烦！ 2）.class是获取当前类的class对象，getClassLoader()是获取当前的类加载器，什么是类加载器？简单点说，就是用来加载java类的,类加载器就是负责把class文件加载进内存中,并创建一个java.lang.Class类的一个实例，也就是class对象，并且每个类的类加载器都不相同，getResourceAsStream(path)是用来获取资源的,因为这是ClassLoader（类加载器）获取资源，而类加载器默认是从 classPath下获取资源的，因为这下面有class文件。所以这段代码总的意思是通过类加载器在 classPath 目录下获取资源，并且是以流的形式。我们知道在Java中所有的类都是通过加载器加载到虚拟机中的，而且类加载器之间存在父子关系，就是子知道父，父不知道子，这样不同的子加载的类型之间是无法访问的（虽然它们都被放在方法区中），所以在这里通过当前类的加载器来加载资源也就是保证是和类类型是同一个加载器加载的。 这一部分是反射的重点！ （3）class.getClassLoader().getResourceAsStream() 和 class.getResouceAsStream() 的区别a）class.getClassLoader().getResourceAsStream(String name) 默认从classpath中找文件(文件放在resources目录下)，name不能带”/“，否则会抛空指针。采用相对路径, “/“就相当于当前进程的根目录，即项目根目录； 1inStream=PropertiesTest.class.getClassLoader().getResourceAsStream(\"com/test/demo/test.properties\"); b）class.getResourceAsStream(String name) 是采用绝对路径，绝对路径是相对于 classpath 根目录的路径，”/“ 就代表着classpath，所以 name 属性需要前面加上 “/“； 1inStream=PropertiesTest.class.getResourceAsStream(\"/com/test/demo/test.properties\") 方式二：采用Spring注解如果工程中使用Spring，可以通过注解的方式获取配置信息，但需要将配置文件放到Spring配置文件中扫描后，才能将配置信息放入上下文。 123&lt;context:component-scan base-package=\"com.xxxx.service\"/&gt;&lt;context:property-placeholder location=\"classpath:properties/xxx.properties\" ignore-unresolvable=\"true\"/&gt; 然后在程序中可以使用 @Value进行获取properties文件中的属性值，如下： 12@Value(\"${xxxt.server}\")private static String serverUrl; 方式三：采用Spring配置也可以在Spring配置文件中读取属性值，赋予类成员变量 123456789101112131415 &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd\"&gt; &lt;bean id=\"propertyConfigurer\" class=\"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\"&gt; &lt;property name=\"location\" value=\"classpath:properties/xxx.properties\"/&gt; &lt;/bean&gt; &lt;bean id=\"service\" class=\"com.xxxx.service.ServiceImpl\"&gt; &lt;property name=\"serverUrl\" value=\"${xxxt.server}\" /&gt; &lt;/bean&gt;&lt;/beans&gt;","link":"/2020/04/15/Java%E9%A1%B9%E7%9B%AE%E8%AF%BB%E5%8F%96Resources%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84/"},{"title":"Spring基础学习(一)","text":"首先由编译期依赖，分析程序的耦合和解耦的思路 编译期依赖以前实现过的Jdbc连接，存在以下代码： 12345678910111213141516171819202122public class JdbcDemo1 { public static void main(String[] args) throws Exception{ //1.注册驱动// DriverManager.registerDriver(new com.mysql.jdbc.Driver()); Class.forName(\"com.mysql.jdbc.Driver\"); //2.获取连接 Connection conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/eesy\",\"root\",\"1234\"); //3.获取操作数据库的预处理对象 PreparedStatement pstm = conn.prepareStatement(\"select * from account\"); //4.执行SQL，得到结果集 ResultSet rs = pstm.executeQuery(); //5.遍历结果集 while(rs.next()){ System.out.println(rs.getString(\"name\")); } //6.释放资源 rs.close(); pstm.close(); conn.close(); }} 如果在步骤1.注册驱动选择new新建对象com.mysql.jdbc.Driver，那么如果没有com.mysql.jdbc.Driver jar包，则程序在编译期产生错误，程序无法运行。这就是因为程序的耦合性导致编译期依赖。 那么什么是程序的耦合？ 程序的耦合： 耦合：程序间的依赖关系 包括： 类之间的依赖 方法间的依赖 解耦：降低程序间的依赖关系 实际开发中： 应该做到：编译期不依赖，运行时才依赖。 解耦的思路： 第一步：使用反射来创建对象，而避免使用new关键字。 第二步：通过读取配置文件来获取要创建的对象全限定类名。 再看一个例子。 以前实现的javaweb项目，结构为从持久层到业务层到表现层，即dao–&gt;service–&gt;client，都需要new上一层的对象实现调用。这样的代码耦合性非常大，使我们的代码独立性非常差。经常出现编译期错误。那么我们考虑如何解耦，即解除类之间的依赖。 工厂类和配置文件我们知道用工厂模式可以实现解耦，那么先看一下，工厂工作的原理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 一个创建Bean对象的工厂 * * Bean：在计算机英语中，有可重用组件的含义。 * JavaBean：用java语言编写的可重用组件。 * javabean &gt; 实体类(POPJ) * * 它就是创建我们的service和dao对象的。 * * 第一个：需要一个配置文件来配置我们的service和dao * 配置的内容：唯一标识=全限定类名（key=value) * 第二个：通过读取配置文件中配置的内容，反射创建对象 * * 我的配置文件可以是xml也可以是properties */public class BeanFactory { //定义一个Properties对象 private static Properties props; //使用静态代码块为Properties对象赋值 static { try { //实例化对象 props = new Properties(); //获取properties文件的流对象 InputStream in = BeanFactory.class.getClassLoader().getResourceAsStream(\"bean.properties\"); props.load(in); } }catch(Exception e){ throw new ExceptionInInitializerError(\"初始化properties失败！\"); } } /** * 根据Bean的名称获取bean对象 * @param beanName * @return */ public static Object getBean(String beanName){ Object bean = null; try { String beanPath = props.getProperty(beanName); System.out.println(beanPath); bean = Class.forName(beanPath). getDeclaredConstructors().newInstance();//每次都会创建一个默认构造函数，再利用构造函数的newInstance()方法创建需要的对象。 }catch (Exception e){ e.printStackTrace(); } return bean;//返回需要的对象，完成对象的创建！ }} 反射创建对象可以说，该工厂模式最最重要的部分是反射机制。在学习java的反射机制的时候，首先会通过Class.forName()获取字节码对象，然后再用这个对象调用getDeclaredConstructors()方法，创建这个类的构造器对象，再通过构造器对象（JDK9以后）去调用newInstance()方法，可以使用默认构造器也可以使用带参数的构造器。 使用newInstance有两个前提：1.这个类已经加载；2.这个类已经连接了。 newInstance()实际上是把new这个方式分解为两步，即首先调用Class加载方法加载某个类，然后实例化。 这样分步的好处是显而易见的。我们可以在调用class的静态加载方法forName时获得更好的灵活性，提供给了一种降耦(降低耦合度)的手段。 以上代码存在的问题思考一个问题，以上代码创建的对象是单例对象还是多例对象？并考虑一下单例对象和多例对象分别存在什么问题？ 单例对象，只被创建一次，从而类中的成员也就只会初始化一次，那么多个线程共享这个对象的时候，若对象存在类成员并且有对类成员进行操作的方法时，存在线程问题。所以定义servlet对象的时候尽量不要定义类成员。 对象被创建多次，执行效率没有单例对象高。 通过不断调用，我们发现其实创建的是多例对象。但其实我们并不需要多例对象，因为dao层和service层中的类并没有定义类成员。所以创建多例对象其实是降低了程序的效率。 由于newInstance()每次都创建一个新对象，所以我们需要定义一个容器去装载这些对象，需要使用时，就从容器中取出传给调用者。这样就不需要每次都创建新的多例对象了。 改进过后的代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class BeanFactory { //定义一个Properties对象 private static Properties props; //定义一个Map,用于存放我们要创建的对象。我们把它称之为容器 private static Map&lt;String,Object&gt; beans; //使用静态代码块为Properties对象赋值 static { try { //实例化对象 props = new Properties(); //获取properties文件的流对象 InputStream in = BeanFactory.class.getClassLoader().getResourceAsStream(\"bean.properties\"); props.load(in); //实例化容器 beans = new HashMap&lt;String,Object&gt;(); //取出配置文件中所有的Key Enumeration keys = props.keys(); //遍历枚举 while (keys.hasMoreElements()){ //取出每个Key String key = keys.nextElement().toString(); //根据key获取value String beanPath = props.getProperty(key); //反射创建对象 Object value = Class.forName(beanPath).newInstance(); //把key和value存入容器中 beans.put(key,value); } }catch(Exception e){ throw new ExceptionInInitializerError(\"初始化properties失败！\"); } } /** * 根据bean的名称获取对象 * @param beanName * @return */ public static Object getBean(String beanName){ return beans.get(beanName); } /** * 根据Bean的名称获取bean对象 * @param beanName * @return public static Object getBean(String beanName){ Object bean = null; try { String beanPath = props.getProperty(beanName);// System.out.println(beanPath); bean = Class.forName(beanPath).newInstance();//每次都会调用默认构造函数创建对象 }catch (Exception e){ e.printStackTrace(); } return bean; }*/} 在static静态代码块中，每次类加载完成后容器中已经存在所有的Bean对象，只需要传递给调用者即可。在实际开发中我们可以把三层的对象都使用配置文件配置起来，当启动服务器应用加载的时候，让一个类中的方法通过读取配置文件，把这些对象创建出来并存起来。在接下来的使用的时候，直接拿过来用就好了。 那么，这个读取配置文件，创建和获取三层对象的类就是工厂。 Ioc的概念和作用由于创建很多对象，需要集合来存。这时候有 Map和List供选择。到底选 Map 还是 List 就看我们有没有查找需求。有查找需求，选 Map。所以我们的答案就是在应用加载时，创建一个Map，用于存放三层对象。 我们把这个 map 称之为容器 工厂就是负责给我们从容器中获取指定对象的类。这时候我们获取对象的方式发生了改变。 原来，我们在获取对象时，都是采用 new的方式。是主动的。 现在我们获取对象时，同时跟工厂要，有工厂为我们查找或者创建对象。是被动的。 这种被动接收的方式获取对象的思想就是控制反转，它是 spring 框架的核心之一。 控制反转（Inversion of Control，缩写为IoC），是面向对象编程中的一种设计原则，可以用来减低计算机代码之间的耦合度。其中最常见的方式叫做依赖注入（Dependency Injection，简称DI），还有一种方式叫“依赖查找”（Dependency Lookup）。通过控制反转，对象在被创建的时候，由一个调控系统内所有对象的外界实体将其所依赖的对象的引用传递给它。也可以说，依赖被注入到对象中。 那么可以明确 ioc的作用： 削减计算机程序的耦合(解除我们代码中的依赖关系)。 使用 spring的 IOC解决程序耦合基于 XML 的配置 第一步：导jar包 第二步：在Resources路径下创建一个任意名称的xml文件。这里存在路径问题，具体查看另一文章。给配置文件导入约束： 1234567&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt;&lt;/beans&gt; 第三步：让 spring 管理资源，在配置文件中配置 service 和 dao。 1234567&lt;!-- bean 标签：用于配置让 spring 创建对象，并且存入 ioc 容器之中 id 属性：对象的唯一标识(key)。 class 属性：指定要创建对象的全限定类名(value) --&gt; &lt;!-- 配置 service --&gt; &lt;bean id=\"accountService\" class=\"com.itheima.service.impl.AccountServiceImpl\"&gt;&lt;/bean&gt; &lt;!-- 配置 dao --&gt;&lt;bean id=\"accountDao\" class=\"com.itheima.dao.impl.AccountDaoImpl\"&gt;&lt;/bean&gt; 配置成功！","link":"/2020/04/14/Spring%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E4%B8%80-%EF%BC%9ASpring%E6%A6%82%E8%BF%B0/"},{"title":"Java反射指南","text":"Java反射机制可以让我们在编译期(Compile Time)之外的运行期(Runtime)检查类，接口，变量以及方法的信息。反射还可以让我们在运行期实例化对象，调用方法，通过调用get/set方法获取变量的值。 前言参考：http://ifeve.com/java-reflection-tutorial/。 本指南更深入的去理解Java反射机制，它会阐述Java反射机制的基本原理包括如何去使用数组，注解，泛型以及动态代理还有类的动态加载以及类的重载的实现。同时也会向你展示如何实现一些比较有特性的功能，比如从一个类中读取所有的get/set方法，或者访问一个类的私有变量以及私有方法。在这个系列的指南中同时也会说明一些非反射相关的但是令人困惑的问题，比如哪些泛型信息在运行时是有效的，一些人声称所有的泛型信息在运行期都会消失，其实这是不对的。 该系列文章中所描述介绍的是Java 6版本的反射机制。 Java反射的例子 下面是一个Java反射的简单例子： 12345Method[] methods = MyObject.class.getMethods();for(Method method : methods){ System.out.println(\"method = \" + method.getName());} 在这个例子中通过调用MyObject类的class属性获取对应的Class类的对象，通过这个Class类的对象获取MyObject类中的方法集合。迭代这个方法的集合并且打印每个方法的名字。 Class对象在本节中我们会简短的涉及上述所提及的信息，上述的一些主题我们会使用单独的章节进行更详细的描述，比如这段内容会描述如何获取一个类的所有方法或者指定方法，但是在单独的章节中则会向你展示如何调用反射获得的方法(Method Object)，如何在多个同名方法中通过给定的参数集合匹配到指定的方法，在一个方法通过反射机制调用的时候会抛出那些异常？如何准确的获取getter/setter方法等等。本节的内容主要是介绍Class类以及你能从Class类中获取哪些信息。 在你想检查一个类的信息之前，你首先需要获取类的Class对象。Java中的所有类型包括基本类型(int, long, float等等)，即使是数组都有与之关联的Class类的对象。如果你在编译期知道一个类的名字的话，那么你可以使用如下的方式获取一个类的Class对象。 Class myObjectClass = MyObject.class;如果你在编译期不知道类的名字，但是你可以在运行期获得到类名的字符串,那么你则可以这么做来获取Class对象: String className = … ;//在运行期获取的类名字符串 Class class = Class.forName(className);在使用Class.forName()方法时，你必须提供一个类的全名，这个全名包括类所在的包的名字。例如MyObject类位于com.jenkov.myapp包，那么他的全名就是com.jenkov.myapp.MyObject。如果在调用Class.forName()方法时，没有在编译路径下(classpath)找到对应的类，那么将会抛出ClassNotFoundException。 类名你可以从Class对象中获取两个版本的类名。 通过getName() 方法返回类的全限定类名（包含包名）： 12Class aClass = ... //获取Class对象，具体方式可见Class对象小节 String className = aClass.getName(); 如果你仅仅只是想获取类的名字(不包含包名)，那么你可以使用getSimpleName()方法: 12Class aClass = ... //获取Class对象，具体方式可见Class对象小节 String simpleClassName = aClass.getSimpleName(); 修饰符可以通过Class对象来访问一个类的修饰符，即public,private,static等等的关键字，你可以使用如下方法来获取类的修饰符： 12Class aClass = ... //获取Class对象，具体方式可见Class对象小节 int modifiers = aClass.getModifiers(); 修饰符都被包装成一个int类型的数字，这样每个修饰符都是一个位标识(flag bit)，这个位标识可以设置和清除修饰符的类型。可以使用java.lang.reflect.Modifier类中的方法来检查修饰符的类型： 123456789101112Modifier.isAbstract(int modifiers); Modifier.isFinal(int modifiers); Modifier.isInterface(int modifiers); Modifier.isNative(int modifiers); Modifier.isPrivate(int modifiers); Modifier.isProtected(int modifiers); Modifier.isPublic(int modifiers); Modifier.isStatic(int modifiers); Modifier.isStrict(int modifiers); Modifier.isSynchronized(int modifiers); Modifier.isTransient(int modifiers); Modifier.isVolatile(int modifiers); 包信息可以使用Class对象通过如下的方式获取包信息： 12Class aClass = ... //获取Class对象，具体方式可见Class对象小节 Package package = aClass.getPackage(); 通过Package对象你可以获取包的相关信息，比如包名，你也可以通过Manifest文件访问位于编译路径下jar包的指定信息，比如你可以在Manifest文件中指定包的版本编号。更多的Package类信息可以阅读java.lang.Package。 父类通过Class对象你可以访问类的父类，如下例： 1Class superclass = aClass.getSuperclass(); 可以看到superclass对象其实就是一个Class类的实例，所以你可以继续在这个对象上进行反射操作。 实现的接口可以通过如下方式获取指定类所实现的接口集合： 12Class aClass = ... //获取Class对象，具体方式可见Class对象小节 Class[] interfaces = aClass.getInterfaces(); 由于一个类可以实现多个接口，因此getInterfaces()方法返回一个Class数组，在Java中接口同样有对应的Class对象。注意：getInterfaces()方法仅仅只返回当前类所实现的接口。当前类的父类如果实现了接口，这些接口是不会在返回的Class集合中的，尽管实际上当前类其实已经实现了父类接口。 构造器你可以通过如下方式访问一个类的构造方法： 1Constructor[] constructors = aClass.getConstructors(); 获取Constructor对象利用Java的反射机制你可以检查一个类的构造方法，并且可以在运行期创建一个对象。这些功能都是通过java.lang.reflect.Constructor这个类实现的。 我们可以通过Class对象来获取Constructor类的实例： 12Class aClass = ...//获取Class对象 Constructor[] constructors = aClass.getConstructors(); 返回的Constructor数组包含每一个声明为公有的（Public）构造方法。如果你知道你要访问的构造方法的方法参数类型，你可以用下面的方法获取指定的构造方法，这例子返回的构造方法的方法参数为String类型： 123Class aClass = ...//获取Class对象 Constructor constructor = aClass.getConstructor(new Class[]{String.class}); 如果没有指定的构造方法能满足匹配的方法参数则会抛出：NoSuchMethodException。 构造方法参数你可以通过如下方式获取指定构造方法的方法参数信息： 12Constructor constructor = ... //获取Constructor对象 Class[] parameterTypes = constructor.getParameterTypes(); 利用Constructor对象实例化一个类你可以通过如下方法实例化一个类： 123Constructor constructor = MyObject.class.getConstructor(String.class); MyObject myObject = (MyObject) constructor.newInstance(\"constructor-arg1\"); constructor.newInstance()方法的方法参数是一个可变参数列表，但是当你调用构造方法的时候你必须提供精确的参数，即形参与实参必须一一对应。在这个例子中构造方法需要一个String类型的参数，那我们在调用newInstance方法的时候就必须传入一个String类型的参数。 变量你可以通过如下方式访问一个类的成员变量： 1Field[] method = aClass.getFields(); 获取Field对象使用Java反射机制你可以运行期检查一个类的变量信息(成员变量)或者获取或者设置变量的值。通过使用java.lang.reflect.Field类就可以实现上述功能。在本节会带你深入了解Field对象的信息。 可以通过Class对象获取Field对象，如下例： 12Class aClass = ...//获取Class对象 Field[] methods = aClass.getFields(); 返回的Field对象数组包含了指定类中声明为公有的(public)的所有变量集合。如果你知道你要访问的变量名称，你可以通过如下的方式获取指定的变量： 12Class aClass = MyObject.class Field field = aClass.getField(\"someField\"); 上面的例子返回的Field类的实例对应的就是在MyObject类中声明的名为someField的成员变量，就是这样： 1234567891011public class MyObject{ public String someField = null; }``` 在调用getField()方法时，如果根据给定的方法参数没有找到对应的变量，那么就会抛出NoSuchFieldException。### 变量名称一旦你获取了Field实例，你可以通过调用Field.getName()方法获取他的变量名称，如下例：```javaField field = ... //获取Field对象 String fieldName = field.getName(); 变量类型你可以通过调用Field.getType()方法来获取一个变量的类型（如String, int等等） 12Field field = aClass.getField(\"someField\"); Object fieldType = field.getType(); 获取或设置（get/set）变量值一旦你获得了一个Field的引用，你就可以通过调用Field.get()或Field.set()方法，获取或者设置变量的值，如下例： 12345678Class aClass = MyObject.class Field field = aClass.getField(\"someField\"); MyObject objectInstance = new MyObject(); Object value = field.get(objectInstance); field.set(objetInstance, value); 传入Field.get()/Field.set()方法的参数objetInstance应该是拥有指定变量的类的实例。在上述的例子中传入的参数是MyObject类的实例，是因为someField是MyObject类的实例。如果变量是静态变量的话(public static)那么在调用Field.get()/Field.set()方法的时候传入null做为参数而不用传递拥有该变量的类的实例。(译者注：你如果传入拥有该变量的类的实例也可以得到相同的结果) 方法你可以通过如下方式访问一个类的所有方法： 1Method[] method = aClass.getMethods(); 获取Method对象使用Java反射你可以在运行期检查一个方法的信息以及在运行期调用这个方法，通过使用java.lang.reflect.Method类就可以实现上述功能。在本节会带你深入了解Method对象的信息。 可以通过Class对象获取Method对象，如下例： 12Class aClass = ...//获取Class对象 Method[] methods = aClass.getMethods(); 返回的Method对象数组包含了指定类中声明为公有的(public)的所有变量集合。如果你知道你要调用方法的具体参数类型，你就可以直接通过参数类型来获取指定的方法，下面这个例子中返回方法对象名称是“doSomething”，他的方法参数是String类型： 12Class aClass = ...//获取Class对象 Method method = aClass.getMethod(\"doSomething\", new Class[]{String.class}); 如果根据给定的方法名称以及参数类型无法匹配到相应的方法，则会抛出NoSuchMethodException。如果你想要获取的方法没有参数，那么在调用getMethod()方法时第二个参数传入null即可，就像这样： 12Class aClass = ...//获取Class对象 Method method = aClass.getMethod(\"doSomething\", null); 方法参数以及返回类型你可以获取指定方法的方法参数是哪些： 12Method method = ... //获取Class对象 Class[] parameterTypes = method.getParameterTypes(); 你可以获取指定方法的返回类型： 12Method method = ... //获取Class对象 Class returnType = method.getReturnType(); 通过Method对象调用方法你可以通过如下方式来调用一个方法： 123//获取一个方法名为doSomesthing，参数类型为String的方法 Method method = MyObject.class.getMethod(\"doSomething\", String.class); Object returnValue = method.invoke(null, \"parameter-value1\"); 传入的null参数是你要调用方法的对象，如果是一个静态方法调用的话则可以用null代替指定对象作为invoke()的参数，在上面这个例子中，如果doSomething不是静态方法的话，你就要传入有效的MyObject实例而不是null。Method.invoke(Object target, Object … parameters)方法的第二个参数是一个可变参数列表，但是你必须要传入与你要调用方法的形参一一对应的实参。就像上个例子那样，方法需要String类型的参数，那我们必须要传入一个字符串。 Getter,Setter方法使用Java反射你可以在运行期检查一个方法的信息以及在运行期调用这个方法，使用这个功能同样可以获取指定类的getters和setters，你不能直接寻找getters和setters，你需要检查一个类所有的方法来判断哪个方法是getters和setters。 首先让我们来规定一下getters和setters的特性： Getter Getter方法的名字以get开头，没有方法参数，返回一个值。 Setter Setter方法的名字以set开头，有一个方法参数。 setters方法有可能会有返回值也有可能没有，一些Setter方法返回void，一些用来设置值，有一些对象的setter方法在方法链中被调用（译者注：这类的setter方法必须要有返回值），因此你不应该妄自假设setter方法的返回值，一切应该视情况而定。 下面是一个获取getter方法和setter方法的例子： 123456789101112131415161718192021public static void printGettersSetters(Class aClass){ Method[] methods = aClass.getMethods(); for(Method method : methods){ if(isGetter(method)) System.out.println(\"getter: \" + method); if(isSetter(method)) System.out.println(\"setter: \" + method); }}public static boolean isGetter(Method method){ if(!method.getName().startsWith(\"get\")) return false; if(method.getParameterTypes().length != 0) return false; if(void.class.equals(method.getReturnType()) return false; return true;}public static boolean isSetter(Method method){ if(!method.getName().startsWith(\"set\")) return false; if(method.getParameterTypes().length != 1) return false; return true;} 访问私有变量在通常的观点中从对象的外部访问私有变量以及方法是不允许的，但是Java反射机制可以做到这一点。使用这个功能并不困难，在进行单元测试时这个功能非常有效。本节会向你展示如何使用这个功能。 注意：这个功能只有在代码运行在单机Java应用(standalone Java application)中才会有效,就像你做单元测试或者一些常规的应用程序一样。如果你在Java Applet中使用这个功能，那么你就要想办法去应付SecurityManager对你限制了。但是一般情况下我们是不会这么做的，所以我们不会探讨这个问题。 要想获取私有变量你可以调用Class.getDeclaredField(String name)方法或者Class.getDeclaredFields()方法。Class.getField(String name)和Class.getFields()只会返回公有的变量，无法获取私有变量。下面例子定义了一个包含私有变量的类，在它下面是如何通过反射获取私有变量的例子： 12345678910111213141516public class PrivateObject { private String privateString = null; public PrivateObject(String privateString) { this.privateString = privateString; }}PrivateObject privateObject = new PrivateObject(\"The Private Value\");Field privateStringField = PrivateObject.class.getDeclaredField(\"privateString\");privateStringField.setAccessible(true);String fieldValue = (String) privateStringField.get(privateObject);System.out.println(\"fieldValue = \" + fieldValue); 这个例子会输出”fieldValue = The Private Value”，The Private Value是PrivateObject实例的privateString私有变量的值，注意调用PrivateObject.class.getDeclaredField(“privateString”)方法会返回一个私有变量，这个方法返回的变量是定义在PrivateObject类中的而不是在它的父类中定义的变量。注意privateStringField.setAccessible(true)这行代码，通过调用setAccessible()方法会关闭指定类Field实例的反射访问检查，这行代码执行之后不论是私有的、受保护的以及包访问的作用域，你都可以在任何地方访问，即使你不在他的访问权限作用域之内。但是你如果你用一般代码来访问这些不在你权限作用域之内的代码依然是不可以的，在编译的时候就会报错。 访问私有方法访问一个私有方法你需要调用 Class.getDeclaredMethod(String name, Class[] parameterTypes)或者Class.getDeclaredMethods() 方法。 Class.getMethod(String name, Class[] parameterTypes)和Class.getMethods()方法，只会返回公有的方法，无法获取私有方法。下面例子定义了一个包含私有方法的类，在它下面是如何通过反射获取私有方法的例子： 1234567891011121314151617181920212223public class PrivateObject { private String privateString = null; public PrivateObject(String privateString) { this.privateString = privateString; } private String getPrivateString(){ return this.privateString; }}PrivateObject privateObject = new PrivateObject(\"The Private Value\");Method privateStringMethod = PrivateObject.class. getDeclaredMethod(\"getPrivateString\", null);privateStringMethod.setAccessible(true);String returnValue = (String) privateStringMethod.invoke(privateObject, null);System.out.println(\"returnValue = \" + returnValue); 这个例子会输出”returnValue = The Private Value”，The Private Value是PrivateObject实例的getPrivateString()方法的返回值。PrivateObject.class.getDeclaredMethod(“privateString”)方法会返回一个私有方法，这个方法是定义在PrivateObject类中的而不是在它的父类中定义的。同样的，注意Method.setAcessible(true)这行代码，通过调用setAccessible()方法会关闭指定类的Method实例的反射访问检查，这行代码执行之后不论是私有的、受保护的以及包访问的作用域，你都可以在任何地方访问，即使你不在他的访问权限作用域之内。但是你如果你用一般代码来访问这些不在你权限作用域之内的代码依然是不可以的，在编译的时候就会报错。 注解利用Java反射机制可以在运行期获取Java类的注解信息。 什么是注解注解是Java 5的一个新特性。注解是插入你代码中的一种注释或者说是一种元数据（meta data）。这些注解信息可以在编译期使用预编译工具进行处理（pre-compiler tools），也可以在运行期使用Java反射机制进行处理。下面是一个类注解的例子： 123@MyAnnotation(name=\"someName\", value = \"Hello World\") public class TheClass { } 在TheClass类定义的上面有一个@MyAnnotation的注解。注解的定义与接口的定义相似，下面是MyAnnotation注解的定义： 1234567@Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) public @interface MyAnnotation { public String name(); public String value(); } 在interface前面的@符号表名这是一个注解，一旦你定义了一个注解之后你就可以将其应用到你的代码中，就像之前我们的那个例子那样。 在注解定义中的两个指示@Retention(RetentionPolicy.RUNTIME)和@Target(ElementType.TYPE)，说明了这个注解该如何使用。 @Retention(RetentionPolicy.RUNTIME)表示这个注解可以在运行期通过反射访问。如果你没有在注解定义的时候使用这个指示那么这个注解的信息不会保留到运行期，这样反射就无法获取它的信息。 @Target(ElementType.TYPE)表示这个注解只能用在类型上面（比如类跟接口）。你同样可以把Type改为Field或者Method，或者你可以不用这个指示，这样的话你的注解在类，方法和变量上就都可以使用了。 类注解你可以在运行期访问类，方法或者变量的注解信息，下是一个访问类注解的例子： 12345678910Class aClass = TheClass.class;Annotation[] annotations = aClass.getAnnotations();for(Annotation annotation : annotations){ if(annotation instanceof MyAnnotation){ MyAnnotation myAnnotation = (MyAnnotation) annotation; System.out.println(\"name: \" + myAnnotation.name()); System.out.println(\"value: \" + myAnnotation.value()); }} 你还可以像下面这样指定访问一个类的注解： 12345678Class aClass = TheClass.class;Annotation annotation = aClass.getAnnotation(MyAnnotation.class);if(annotation instanceof MyAnnotation){ MyAnnotation myAnnotation = (MyAnnotation) annotation; System.out.println(\"name: \" + myAnnotation.name()); System.out.println(\"value: \" + myAnnotation.value());} 方法注解下面是一个方法注解的例子： 1234public class TheClass { @MyAnnotation(name=\"someName\", value = \"Hello World\") public void doSomething(){}} 你可以像这样访问方法注解： 12345678910Method method = ... //获取方法对象Annotation[] annotations = method.getDeclaredAnnotations();for(Annotation annotation : annotations){ if(annotation instanceof MyAnnotation){ MyAnnotation myAnnotation = (MyAnnotation) annotation; System.out.println(\"name: \" + myAnnotation.name()); System.out.println(\"value: \" + myAnnotation.value()); }} 你可以像这样访问指定的方法注解： 12345678Method method = ... // 获取方法对象Annotation annotation = method.getAnnotation(MyAnnotation.class);if(annotation instanceof MyAnnotation){ MyAnnotation myAnnotation = (MyAnnotation) annotation; System.out.println(\"name: \" + myAnnotation.name()); System.out.println(\"value: \" + myAnnotation.value());} 参数注解方法参数也可以添加注解，就像下面这样： 12345public class TheClass { public static void doSomethingElse( @MyAnnotation(name=\"aName\", value=\"aValue\") String parameter){ }} 你可以通过Method对象来访问方法参数注解： 1234567891011121314151617Method method = ... //获取方法对象Annotation[][] parameterAnnotations = method.getParameterAnnotations();Class[] parameterTypes = method.getParameterTypes();int i=0;for(Annotation[] annotations : parameterAnnotations){ Class parameterType = parameterTypes[i++]; for(Annotation annotation : annotations){ if(annotation instanceof MyAnnotation){ MyAnnotation myAnnotation = (MyAnnotation) annotation; System.out.println(\"param: \" + parameterType.getName()); System.out.println(\"name : \" + myAnnotation.name()); System.out.println(\"value: \" + myAnnotation.value()); } }} 需要注意的是Method.getParameterAnnotations()方法返回一个注解类型的二维数组，每一个方法的参数包含一个注解数组。 变量注解下面是一个变量注解的例子： 12345public class TheClass { @MyAnnotation(name=\"someName\", value = \"Hello World\") public String myField = null;} 你可以像这样来访问变量的注解： 12345678910Field field = ... //获取方法对象&lt;/pre&gt;&lt;pre&gt;Annotation[] annotations = field.getDeclaredAnnotations();for(Annotation annotation : annotations){ if(annotation instanceof MyAnnotation){ MyAnnotation myAnnotation = (MyAnnotation) annotation; System.out.println(\"name: \" + myAnnotation.name()); System.out.println(\"value: \" + myAnnotation.value()); }} 你可以像这样访问指定的变量注解： 12345678Field field = ...//获取方法对象Annotation annotation = field.getAnnotation(MyAnnotation.class);if(annotation instanceof MyAnnotation){ MyAnnotation myAnnotation = (MyAnnotation) annotation; System.out.println(\"name: \" + myAnnotation.name()); System.out.println(\"value: \" + myAnnotation.value());} 泛型反射我常常在一些文章以及论坛中读到说Java泛型信息在编译期被擦除（erased）所以你无法在运行期获得有关泛型的信息。其实这种说法并不完全正确的，在一些情况下是可以在运行期获取到泛型的信息。这些情况其实覆盖了一些我们需要泛型信息的需求。在本节中我们会演示一下这些情况。 运用泛型反射的经验法则下面是两个典型的使用泛型的场景：1、声明一个需要被参数化（parameterizable）的类/接口。2、使用一个参数化类。 当你声明一个类或者接口的时候你可以指明这个类或接口可以被参数化，java.util.List接口就是典型的例子。你可以运用泛型机制创建一个标明存储的是String类型list，这样比你创建一个Object的list要更好。 当你想在运行期参数化类型本身，比如你想检查java.util.List类的参数化类型，你是没有办法能知道他具体的参数化类型是什么。这样一来这个类型就可以是一个应用中所有的类型。但是，当你检查一个使用了被参数化的类型的变量或者方法，你可以获得这个被参数化类型的具体参数。总之： 你不能在运行期获知一个被参数化的类型的具体参数类型是什么，但是你可以在用到这个被参数化类型的方法以及变量中找到他们，换句话说就是获知他们具体的参数化类型。在下面的段落中会向你演示这类情况。 泛型方法返回类型如果你获得了java.lang.reflect.Method对象，那么你就可以获取到这个方法的泛型返回类型信息。如果方法是在一个被参数化类型之中（译者注：如T fun()）那么你无法获取他的具体类型，但是如果方法返回一个泛型类（译者注：如List fun()）那么你就可以获得这个泛型类的具体参数化类型。你可以在“Java Reflection: Methods”中阅读到有关如何获取Method对象的相关内容。下面这个例子定义了一个类这个类中的方法返回类型是一个泛型类型： 12345678public class MyClass { protected List&lt;String&gt; stringList = ...; public List&lt;String&gt; getStringList(){ return this.stringList; }} 我们可以获取getStringList()方法的泛型返回类型，换句话说，我们可以检测到getStringList()方法返回的是List而不仅仅只是一个List。如下例： 123456789101112Method method = MyClass.class.getMethod(\"getStringList\", null);Type returnType = method.getGenericReturnType();if(returnType instanceof ParameterizedType){ ParameterizedType type = (ParameterizedType) returnType; Type[] typeArguments = type.getActualTypeArguments(); for(Type typeArgument : typeArguments){ Class typeArgClass = (Class) typeArgument; System.out.println(\"typeArgClass = \" + typeArgClass); }} 这段代码会打印出 “typeArgClass = java.lang.String”，Type[]数组typeArguments只有一个结果 – 一个代表java.lang.String的Class类的实例。Class类实现了Type接口。 泛型方法参数类型你同样可以通过反射来获取方法参数的泛型类型，下面这个例子定义了一个类，这个类中的方法的参数是一个被参数化的List： 1234567public class MyClass { protected List&lt;String&gt; stringList = ...; public void setStringList(List&lt;String&gt; list){ this.stringList = list; }} 你可以像这样来获取方法的泛型参数： 1234567891011121314method = Myclass.class.getMethod(\"setStringList\", List.class);Type[] genericParameterTypes = method.getGenericParameterTypes();for(Type genericParameterType : genericParameterTypes){ if(genericParameterType instanceof ParameterizedType){ ParameterizedType aType = (ParameterizedType) genericParameterType; Type[] parameterArgTypes = aType.getActualTypeArguments(); for(Type parameterArgType : parameterArgTypes){ Class parameterArgClass = (Class) parameterArgType; System.out.println(\"parameterArgClass = \" + parameterArgClass); } }} 这段代码会打印出”parameterArgType = java.lang.String”。Type[]数组parameterArgTypes只有一个结果 – 一个代表java.lang.String的Class类的实例。Class类实现了Type接口。 泛型变量类型同样可以通过反射来访问公有（Public）变量的泛型类型，无论这个变量是一个类的静态成员变量或是实例成员变量。你可以在“Java Reflection: Fields”中阅读到有关如何获取Field对象的相关内容。这是之前的一个例子，一个定义了一个名为stringList的成员变量的类。 123456789101112131415public class MyClass { public List&lt;String&gt; stringList = ...;}Field field = MyClass.class.getField(\"stringList\");Type genericFieldType = field.getGenericType();if(genericFieldType instanceof ParameterizedType){ ParameterizedType aType = (ParameterizedType) genericFieldType; Type[] fieldArgTypes = aType.getActualTypeArguments(); for(Type fieldArgType : fieldArgTypes){ Class fieldArgClass = (Class) fieldArgType; System.out.println(\"fieldArgClass = \" + fieldArgClass); }} 这段代码会打印出”fieldArgClass = java.lang.String”。Type[]数组fieldArgClass只有一个结果 – 一个代表java.lang.String的Class类的实例。Class类实现了Type接口。 数组利用反射机制来处理数组会有点棘手。尤其是当你想要获得一个数组的Class对象，比如int[]等等。本节会讨论通过反射机制创建数组和如何获取数组的Class对象。 java.lang.reflect.ArrayJava反射机制通过java.lang.reflect.Array这个类来处理数组。不要把这个类与Java集合套件（Collections suite）中的java.util.Arrays混淆，java.util.Arrays是一个提供了遍历数组，将数组转化为集合等工具方法的类。 创建一个数组Java反射机制通过java.lang.reflect.Array类来创建数组。下面是一个如何创建数组的例子： 1int[] intArray = (int[]) Array.newInstance(int.class, 3); 这个例子创建一个int类型的数组。Array.newInstance()方法的第一个参数表示了我们要创建一个什么类型的数组。第二个参数表示了这个数组的空间是多大。 访问一个数组通过Java反射机制同样可以访问数组中的元素。具体可以使用Array.get(…)和Array.set(…)方法来访问。下面是一个例子： 123456789int[] intArray = (int[]) Array.newInstance(int.class, 3);Array.set(intArray, 0, 123);Array.set(intArray, 1, 456);Array.set(intArray, 2, 789);System.out.println(\"intArray[0] = \" + Array.get(intArray, 0));System.out.println(\"intArray[1] = \" + Array.get(intArray, 1));System.out.println(\"intArray[2] = \" + Array.get(intArray, 2)); 这个例子会输出： intArray[0] = 123intArray[1] = 456intArray[2] = 789 获取数组的Class对象如果不通过反射的话你可以这样来获取数组的Class对象： 1Class stringArrayClass = String[].class; 如果使用Class.forName()方法来获取Class对象则不是那么简单。比如你可以像这样来获得一个原生数据类型（primitive）int数组的Class对象： 1Class intArray = Class.forName(\"[I\"); 在JVM中字母I代表int类型，左边的‘[’代表我想要的是一个int类型的数组，这个规则同样适用于其他的原生数据类型。对于普通对象类型的数组有一点细微的不同： 1Class stringArrayClass = Class.forName(\"[Ljava.lang.String;\"); 注意‘[L’的右边是类名，类名的右边是一个‘;’符号。这个的含义是一个指定类型的数组。需要注意的是，你不能通过Class.forName()方法获取一个原生数据类型的Class对象。下面这两个例子都会报ClassNotFoundException： 12Class intClass1 = Class.forName(\"I\");Class intClass2 = Class.forName(\"int\"); 我通常会用下面这个方法来获取普通对象以及原生对象的Class对象： 123456public Class getClass(String className){ if(\"int\" .equals(className)) return int .class; if(\"long\".equals(className)) return long.class; ... return Class.forName(className);} 一旦你获取了类型的Class对象，你就有办法轻松的获取到它的数组的Class对象，你可以通过指定的类型创建一个空的数组，然后通过这个空的数组来获取数组的Class对象。这样做有点讨巧，不过很有效。如下例： 12Class theClass = getClass(theClassName);Class stringArrayClass = Array.newInstance(theClass, 0).getClass(); 这是一个特别的方式来获取指定类型的指定数组的Class对象。无需使用类名或其他方式来获取这个Class对象。为了确保Class对象是不是代表一个数组，你可以使用Class.isArray()方法来进行校验： 12Class stringArrayClass = Array.newInstance(String.class, 0).getClass();System.out.println(\"is array: \" + stringArrayClass.isArray()); 获取数组的成员类型一旦你获取了一个数组的Class对象，你就可以通过Class.getComponentType()方法获取这个数组的成员类型。成员类型就是数组存储的数据类型。例如，数组int[]的成员类型就是一个Class对象int.class。String[]的成员类型就是java.lang.String类的Class对象。下面是一个访问数组成员类型的例子：这个例子会打印“java.lang.String”代表这个数组的成员类型是字符串。 1234String[] strings = new String[3];Class stringArrayClass = strings.getClass();Class stringArrayComponentType = stringArrayClass.getComponentType();System.out.println(stringArrayComponentType); 这个例子会打印“java.lang.String”代表这个数组的成员类型是字符串。 动态代理利用Java反射机制你可以在运行期动态的创建接口的实现。java.lang.reflect.Proxy类就可以实现这一功能。这个类的名字（译者注：Proxy意思为代理）就是为什么把动态接口实现叫做动态代理。动态的代理的用途十分广泛，比如数据库连接和事物管理（transaction management）还有单元测试时用到的动态mock对象以及AOP中的方法拦截功能等等都使用到了动态代理。 创建代理你可以通过使用Proxy.newProxyInstance()方法创建动态代理。newProxyInstance()方法有三个参数：1、类加载器（ClassLoader）用来加载动态代理类。2、一个要实现的接口的数组。3、一个InvocationHandler把所有方法的调用都转到代理上。如下例： 12345InvocationHandler handler = new MyInvocationHandler();MyInterface proxy = (MyInterface) Proxy.newProxyInstance( MyInterface.class.getClassLoader(), new Class[] { MyInterface.class }, handler); 在执行完这段代码之后，变量proxy包含一个MyInterface接口的的动态实现。所有对proxy的调用都被转向到实现了InvocationHandler接口的handler上。有关InvocationHandler的内容会在下一段介绍。 InvocationHandler接口在前面提到了当你调用Proxy.newProxyInstance()方法时，你必须要传入一个InvocationHandler接口的实现。所有对动态代理对象的方法调用都会被转向到InvocationHandler接口的实现上，下面是InvocationHandler接口的定义： 123public interface InvocationHandler{ Object invoke(Object proxy, Method method, Object[] args) throws Throwable;} 下面是它的实现类的定义： 1234567public class MyInvocationHandler implements InvocationHandler{ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //do something \"dynamic\" }} 传入invoke()方法中的proxy参数是实现要代理接口的动态代理对象。通常你是不需要他的。 invoke()方法中的Method对象参数代表了被动态代理的接口中要调用的方法，从这个method对象中你可以获取到这个方法名字，方法的参数，参数类型等等信息。关于这部分内容可以查阅之前有关Method的文章。 Object数组参数包含了被动态代理的方法需要的方法参数。注意：原生数据类型（如int，long等等）方法参数传入等价的包装对象（如Integer， Long等等）。","link":"/2020/05/07/Java%E5%8F%8D%E5%B0%84%E6%8C%87%E5%8D%97/"},{"title":"Spring基础学习-三-：AOP中的代理模式","text":"AOP的实现方式是使用动态代理技术，那么需要深刻理解动态代理。 动态代理动态代理的特点不修改源码的基础上对方法增强，字节码随用随创建，随用随加载。它与静态代理的区别也在于此。因为静态代理是字节码一上来就创建好，并完成加载。装饰者模式就是静态代理的一种体现。 动态代理常用的两种方式 基于接口的动态代理 提供者：JDK官方的Proxy类`。不需要额外的jar包 要求：被代理类最少实现一个接口。 基于子类的动态代理 提供者：第三方的CGLib，如果报asmxxxx异常，需要导入asm.jar。 要求：被代理类不能是用final修饰的类（即不能是最终类）。 基于接口的动态代理动态代理的实现： 涉及的类：Proxy，JDK官方提供。 如何创建代理对象：使用Proxy类中的newProxyInstance方法 创建代理对象的要求：至少实现一个接口，如果没有则无法使用 newProxyInstance的参数： classloader:类加载器 用于加载该代理对象的字节码文件。和被代理对象使用相同的类加载器。 class[ ] :字节码数组 用于让该代理对象获得和被代理对象相同的方法。 InvocationHandler : 用于提供增强的方法 它是让我们写如何代理（如何增强），一般写一个该接口的实现类，通常情况下是匿名内部类。 关键在于如何增强。即InvocationHandler的编写。 //定义代理接口的一个实现类 final Producer producer = new Producer(); IProducer proxyProducer = (IProducer) Proxy.newProxyInstance( producer.getClass().getClassLoader(), producer.getClass().getInterfaces(), new InvocationHandler() { /** * 作用：执行被代理对象的任何接口方法都会经过该方法，实现增强，可以从方法，参数入手。 * 方法参数的含义 * @param proxy 当前代理对象的引用 * @param method 当前执行的方法 * @param args 当前执行方法所需的参数 * @return 和被代理对象方法有相同的返回值 * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //提供增强的代码 Object returnValue = null; //1.获取方法执行的参数 Float money = (Float)args[0]; //2.判断当前方法是不是销售 if(\"saleProduct\".equals(method.getName())) { returnValue = method.invoke(producer, money*0.8f); } return returnValue; } }); //使用动态代理增强后的方法 proxyProducer.saleProduct(10000f); 问题在于当接口不实现任何类的时候，无法使用。只能使用基于子类的代理 基于子类的动态代理动态代理的实现： 涉及的类：Enhancer ，第三方cglib库 如何创建代理对象：使用Enhancer类中的create方法 创建代理对象的要求：被代理类不能是最终类 create方法的参数： Class：字节码它是用于指定被代理对象的字节码。从而可以得到该对象的所有内容（反射）。 Callback：它是让我们写如何代理（如何增强），一般写一个该接口的实现类，通常情况下是匿名内部类。我们一般写的都是该接口的子接口实现类：MethodInterceptor。 final Producer producer = new Producer(); Producer cglibProducer = (Producer)Enhancer.create(producer.getClass(), new MethodInterceptor() { /** * 执行子类对象的任何方法都会经过该方法 * @param proxy * @param method * @param args * 以上三个参数和基于接口的动态代理中invoke方法的参数是一样的 * @param methodProxy ：当前执行方法的代理对象 * @return * @throws Throwable */ @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { //提供增强的代码 Object returnValue = null; //1.获取方法执行的参数 Float money = (Float)args[0]; //2.判断当前方法是不是销售 if(\"saleProduct\".equals(method.getName())) { returnValue = method.invoke(producer, money*0.8f); } return returnValue; } }); cglibProducer.saleProduct(12000f);","link":"/2020/04/19/Spring%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E4%B8%89-%EF%BC%9AAOP%E4%B8%AD%E7%9A%84%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/"},{"title":"javaSE之集合","text":"从JDBC中的Resultset对象看集合对对象的封装。 集合集合，异常，IO，网络编程等是javaSE中最基础的部分，本系列旨在于对基础的总结与提升。将结合Demo回顾知识点。本文主要谈集合。 集合最本质的概念：集合是java中提供的一种容器，可以用来存储多个数据。 与数组对比，集合的特点就是，集合存储的都是对象，且集合长度可变。 集合有两类，即单列集合java.util.Collection和双列集合java.util.Map。 单列Collection集合 Collection:单列集合类的根接口，有两个子接口，即java.util.List和java.util.Set。List的特点是元素有序、可重复。Set的特点是元素无序，不可重复。 List接口的主要实现类：java.util.ArrayList和java.util.LinkedList。 Set接口的主要实现类：java.util.HahSet和java.util.TreeSet。 Collection作为一个父接口，其中定义有单列集合通用的方法，可以操作所有单列集合。自行查阅API，如add，remove，contain，isEmpty，clear，toArray等方法。 增强for的原理—迭代器Iterator接口也是Java集合中的一员，主要用于遍历Collection中的元素。 for each内部是个Iterator迭代器，在遍历过程中，不能对集合中元素进行增删操作。 泛型集合中可以存放任意对象。但是实际上集合只存储同一类型对象。于是增加了泛型（generic）语法。 泛型：可以在类或者方法中预支的使用未知的类型。在创建对象时，将未知的类型确定具体的类型。若没有指定泛型，默认类型为Object类型。 泛型是数据类型的一部分，将类名与泛型合并一起看作数据类型。 泛型在创建对象时候使用，作为完整的数据类型！ List接口的集合List接口介绍List接口继承自Collection接口，List集合中允许出现重复的元素（对象）。元素以线性方式存储。特点是元素有序，即素的存入顺序和取出顺序一致。 List接口中常用方法自行查阅API。即add，get，remove，set。 List的子类ArrayList集合java.util.ArrayList集合数据存储的结构是数组结构。元素增删慢，查找快，由于日常开发中使用最多的功能为查询数据、遍历数据，所以ArrayList是最常用的集合。 LinkedList集合java.util.LinkedList集合数据存储的结构是链表结构。方便元素添加、删除的集合。 LinkedList是一个双向链表，提供了大量首尾操作的方法。 Set接口它与Collection接口中的方法基本一致，并没有对Collection接口进行功能上的扩充，只是比Collection接口更加严格了。与List接口不同的是，Set接口中元素无序，并且都会以某种规则保证存入的元素不出现重复。 Set集合取出元素的方式可以采用：迭代器、增强for。 HashSet集合介绍java.util.HashSet底层的实现是一个java.util.HashMap支持。 HashSet是根据对象的哈希值来确定元素在集合中的存储位置，因此具有良好的存取和查找性能。保证元素唯一性的方式依赖于：hashCode与equals方法。 HashSet集合存储数据的结构（哈希表）在JDK1.8之前，哈希表底层采用数组+链表实现，即使用链表处理冲突，同一hash值的链表都存储在一个链表里。但是当位于一个桶中的元素较多，即hash值相等的元素较多时，通过key值依次查找的效率较低。而JDK1.8中，哈希表存储采用数组+链表+红黑树实现，当链表长度超过阈值（8）时，将链表转换为红黑树，这样大大减少了查找时间。 简单的来说，哈希表是由数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的。保证HashSet集合元素的唯一，其实就是根据对象的hashCode和equals方法来决定的。如果我们往集合中存放自定义的对象，那么保证其唯一，就必须复写hashCode和equals方法建立属于当前对象的比较方式。 即HashSet&lt;generic&gt;中，如果泛型是自定义对象，若要使用该对象，必须重写自定义对象的hashCode和equals，才能保证唯一的特性！ LinkedHashSetHashSet保证元素唯一，可是元素存放进去是没有顺序的，那么我们要保证有序，需要使用HashSet下面的子类java.util.LinkedHashSet，它是链表和哈希表组合的一个数据存储结构。 Collectionsjava.utils.Collections是集合工具类，用来对集合进行操作。具体方法阅读API。主要掌握sort方法和自定义sort方法。自定义sort方法用于指定规则的排列。实现自定义的排列，即实现Comparator这个接口。默认的排列其实是实现了Comparatable这个接口。查看java.util.Comparator的API中规定的方法，自己去实现。 若要使用Collections.sort(list)；要求该list中元素类型必须实现比较器Comparable接口 Comparable：强行对实现它的每个类的对象进行整体排序。这种排序被称为类的自然排序，类的compareTo方法被称为它的自然比较方法。只能在类中实现compareTo()一次，不能经常修改类的代码实现自己想要的排序。实现此接口的对象列表（和数组）可以通过Collections.sort（和Arrays.sort）进行自动排序，对象可以用作有序映射中的键或有序集合中的元素，无需指定比较器。 Comparator：强行对某个对象进行整体排序。可以将Comparator 传递给sort方法（如Collections.sort或 Arrays.sort），从而允许在排序顺序上实现精确控制。还可以使用Comparator来控制某些数据结构（如有序set或有序映射）的顺序，或者为那些没有自然顺序的对象collection提供排序。通常在Collections的sort方法中使用匿名对象构造。 双列Map集合IP地址与主机名，身份证号与个人，系统用户名与系统用户对象等，这种一一对应的关系，就叫做映射。Java提供了专门的集合类用来存放这种对象关系的对象，即java.util.Map接口。 Collection中的集合，元素是孤立存在的（理解为单身），向集合中存储元素采用一个个元素的方式存储。 Map中的集合，元素是成对存在的(理解为夫妻)。每个元素由键与值两部分组成，通过键可以找对所对应的值。 Collection中的集合称为单列集合，Map中的集合称为双列集合。 需要注意的是，Map中的集合不能包含重复的键(key)，值(value)可以重复；每个键只能对应一个值。 Map常用子类常用HashMap集合、LinkedHashMap集合。 HashMap&lt;K,V&gt;：存储数据采用的哈希表结构，元素的存取顺序不能保证一致。由于要保证键的唯一、不重复，需要重写键的hashCode()方法、equals()方法。 LinkedHashMap&lt;K,V&gt;：HashMap下有个子类LinkedHashMap，存储数据采用的哈希表结构+链表结构。通过链表结构可以保证元素的存取顺序一致；通过哈希表结构可以保证的键的唯一、不重复，需要重写键的hashCode()方法、equals()方法。Map接口中常用方法 自行查阅API，重点方法： public Set&lt;K&gt; keySet(): 获取Map集合中所有的键（key），存储到Set集合中。(唯一所以存Set中) public V get(Object key) 根据指定的键，在Map集合中获取对应的值。 public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet(): 获取到Map集合中所有的键值对对象的集合(Set集合)。 键值对Entry为什么能存在Set集合中？ Map.Entry&lt;K,V&gt;：在Map接口中有一个内部接口Entry，当Map集合一创建，那么就会在Map集合中创建一个Entry对象，用来记录键与值(键值对对象，键与值的映射关系)。即Entry实质上是一个唯一的对象，可以存在Set集合中。 Map集合不能直接使用迭代器或者foreach进行遍历。但是转成Set之后就可以使用了。 Map集合遍历键找值方式keySet()+get(k key) Map集合遍历键值对方式entrySet()+getKey()+getValue() HashMap存储自定义类型键值 当给HashMap中存放自定义对象时，如果自定义对象作为key存在，这时要保证对象唯一，必须复写对象的hashCode和equals方法 如果要保证map中存放的key和取出的顺序一致，可以使用java.util.LinkedHashMap集合来存放。 LinkedHashMap成对元素存放进去是没有顺序的，那么我们要保证有序，在HashMap下面有一个子类LinkedHashMap，它是链表和哈希表组合的一个数据存储结构。 属性集Properties概述java.util.Properties 继承于Hashtable ，来表示一个持久的属性集。Properties 类表示了一个持久的属性集。Properties 可保存在流中或从流中加载。属性列表中每个键及其对应值都是一个字符串。 它使用键值结构存储数据，每个键及其对应值都是一个字符串。Hashtable已经不再使用，而因为Properties是唯一与流相关的集合，所以在读取配置文件时使用。 与流相关的方法除了通用的方法，Properties最典型的方法和流相关。 public void load(InputStream inStream)： 从字节输入流中读取(加载)键值对。 public void store(OutputStream out, String comments)：以适合使用load(InputStream) 方法加载到 Properties表中的格式，将此Properties表中的属性列表（键和元素对）写入输出流。 参数中使用了字节输入流，通过流对象，可以关联到某文件上，这样就能够加载文本中的数据了。文本数据格式: 123filename=a.txtlength=209385038location=D:\\a.txt 加载演示： 1234567891011121314151617public class ProDemo2 { public static void main(String[] args) throws FileNotFoundException { // 创建属性集对象 Properties pro = new Properties(); // 加载文本中信息到属性集 pro.load(new FileInputStream(\"read.txt\")); // 遍历集合并打印 Set&lt;String&gt; strings = pro.stringPropertyNames(); for (String key : strings ) { System.out.println(key+\" -- \"+pro.getProperty(key)); } }}输出结果：filename -- a.txtlength -- 209385038location -- D:\\a.txt","link":"/2020/04/04/javaSE%E4%B9%8B%E9%9B%86%E5%90%88/"},{"title":"maven在IDEA的配置与项目的创建","text":"本以为很简单的maven，没想到配置起来却问题重重，这里记载配置踩过的坑。 第一个是最基本也是最最重要的点，就是配置阿里云镜像仓库，以及忽略ssl证书的验证。 在maven配置文件setting.xml中添加代码 123456&lt;mirror&gt;&lt;id&gt;alimaven-new&lt;/id&gt;&lt;mirrorOf&gt;central&lt;/mirrorOf&gt;&lt;name&gt;aliyun maven&lt;/name&gt;&lt;url&gt;https://maven.aliyun.com/repository/central/&lt;/url&gt;&lt;/mirror&gt; 在IDEA中的File–&gt;settings–&gt;Maven–&gt;Importing的VM Options添加 1-Dmaven.wagon.http.ssl.insecure=true -Dmaven.wagon.http.ssl.allowall=true 即可正常使用阿里云镜像仓库下载jar包和插件。 第2就是如何创建项目 到目前为止，还是不能使用Maven骨架直接创建web项目，需要手动添加文件，形成web项目。 如图所示步骤，在简单的maven项目上手动形成。另外再说下pom.xml的配置。 12345678910111213141516171819202122&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.encoding&gt;UTF-8&lt;/maven.compiler.encoding&gt; &lt;java.version&gt;11&lt;/java.version&gt; &lt;maven.compiler.source&gt;11&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;11&lt;/maven.compiler.target&gt;&lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;11.0&lt;/source&gt; &lt;target&gt;11.0&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;//如不限制JDK版本，tomcat可能会报错。","link":"/2020/04/10/maven%E5%9C%A8IDEA%E7%9A%84%E9%85%8D%E7%BD%AE%E4%B8%8E%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%88%9B%E5%BB%BA/"},{"title":"Spring基础学习（三）：AOP面向切面编程","text":"AOP：全称是 Aspect Oriented Programming 即：面向切面编程。简单的说它就是把我们程序重复的代码抽取出来，在需要执行的时候，使用动态代理的技术，在不修改源码的基础上，对我们的已有方法进行增强。 AOP相关术语Joinpoint连接点：所谓连接点是指那些被拦截到的点。在spring中,这些点指的是方法,因为spring只支持方法类型的连接点。 Pointcut切入点：所谓切入点是指我们要对哪些Joinpoint进行拦截的定义。 Advince通知/增强：所谓通知是指拦截到Joinpoint之后所要做的事情就是通知。通知的类型：前置通知,后置通知,异常通知,最终通知,环绕通知。 Aspect切面: 是切入点和通知的结合。 基于xml的AOP配置maven导入jar包导入必备jar包aspectjweaver-。 在配置文件bean.xml中引入aop约束123456789&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd\"&gt; &lt;/beans&gt; 配置需要的ioc抽取公共通知制作成通知123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * 控制当前线程的事务处理 * 包含了 开启事务，提交事务，回滚事务，和释放连接 */public class transactionControl { private ConnectionUtils connectionUtils; public void setConnectionUtils(ConnectionUtils connectionUtils) { this.connectionUtils = connectionUtils; } public void beginTransaction(){ try { connectionUtils.getThreadLocalConnnection().setAutoCommit(false); } catch (SQLException throwables) { throwables.printStackTrace(); } } public void commit(){ try { connectionUtils.getThreadLocalConnnection().commit(); } catch (SQLException throwables) { throwables.printStackTrace(); } } public void rollback(){ try { connectionUtils.getThreadLocalConnnection().rollback(); } catch (SQLException throwables) { throwables.printStackTrace(); } } public void close(){ try { //返回连接给连接池 connectionUtils.getThreadLocalConnnection().close(); //解除当前线程对当前连接的绑定，否则下次获得的线程仍绑定已被返回到线程池中的连接 connectionUtils.removeThreadLocalConnnection(); } catch (SQLException throwables) { throwables.printStackTrace(); } } /** *配置环绕通知 */ public object transactionAround(proceedingJoinPoint pjp){ object rtnValue = null; try{ this.beginTransaction(); object[] args=pjp.getargs(); rtnValue = pjp.proceed(args); this.commit(); }catch(Throwable e){ this.rollback; e.printStackTrace; }finally{ this.finally; } return rtnValue; }} 配置切面首先要保证通知类的ioc已经在bean.xml中配置过 &lt;aop:config&gt;：开启aop切面配置。 &lt;aop:config&gt; &lt;!--所有的切面配置都写在此处--&gt; &lt;/aop:config&gt;&lt;aop:aspect&gt;: 配置切面. &lt;aop:aspect id=&quot;tCAdbance&quot; ref=&quot;tControl&quot;&gt; &lt;!-- 配置通知类型 --&gt; &lt;/aop:aspect&gt;&lt;aop:pointcut&gt;:配置切入点表达式。 &lt;aop:pointcut id=&quot;pc1&quot; execution=&quot;execution(* com.lehirt.service.impl.*.*(..)))&quot;&gt;使用 &lt;aop:xxx&gt; 配置对应的通知类型 &lt;aop:before method=&quot;beginTransaction&quot; pointcut-ref=&quot;pc1&quot;&gt; &lt;aop:after-returning method=&quot;commit&quot; pointcut-ref=&quot;pc1&quot;&gt; &lt;aop:after-throwing method=&quot;rollback&quot; pointcut-ref=&quot;pc1&quot;&gt; &lt;aop:after method=&quot;close&quot; pointcut-ref=&quot;pc1&quot;&gt;环绕通知配置方式: &lt;aop:config&gt; &lt;aop:pointcut expression=&quot;execution(*com.lehirt.service.impl.*.*(..))&quot; id=&quot;pc1&quot;/&gt; &lt;aop:aspect id=&quot;tCAdvice&quot; ref=&quot;tControl&quot;&gt; &lt;!-- 配置环绕通知 --&gt; &lt;aop:around method=&quot;transactionAround&quot; pointcut-ref=&quot;pt1&quot;/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; aop:around：用于配置环绕通知. method:指定环绕通知方法。 基于注解的AOP配置在配置文件bean.xml中引入aop约束在Ioc约束，aop约束基础上添加context约束。 在必要的类上添加Ioc注解指定spring要扫描的包&lt;!-- 告知 spring，在创建容器时要扫描的包 --&gt; &lt;context:component-scan base-package=&quot;com.itheima&quot;&gt;&lt;/context:component-scan&gt; &lt;!--配置切面--&gt; &lt;aop:aspectj-autoproxy&gt;&lt;/aop:aspectj-autoproxy&gt;配置注解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * 控制当前线程的事务处理 * 包含了 开启事务，提交事务，回滚事务，和释放连接 */@Component(\"tControl\")@Aspectpublic class transactionControl { @Autowired private ConnectionUtils connectionUtils; @Pointcut(\"execution(* com.lehirt.service.impl.*.*(..))\") private void pc1(){}; @Before(\"pc1()\") public void beginTransaction(){ try { connectionUtils.getThreadLocalConnnection().setAutoCommit(false); } catch (SQLException throwables) { throwables.printStackTrace(); } } @After-returning(\"pc1()\") public void commit(){ try { connectionUtils.getThreadLocalConnnection().commit(); } catch (SQLException throwables) { throwables.printStackTrace(); } } @After-throwing(\"pc1()\") public void rollback(){ try { connectionUtils.getThreadLocalConnnection().rollback(); } catch (SQLException throwables) { throwables.printStackTrace(); } } @After(\"pc1()\") public void close(){ try { //返回连接给连接池 connectionUtils.getThreadLocalConnnection().close(); //解除当前线程对当前连接的绑定，否则下次获得的线程仍绑定已被返回到线程池中的连接 connectionUtils.removeThreadLocalConnnection(); } catch (SQLException throwables) { throwables.printStackTrace(); } } // @Around(\"pc1()\") public Object arroundAspct(ProceedingJoinPoint pjp){ Object rtnValue = null; try { Object[] args = pjp.getArgs(); this.beginTransaction(); rtnValue= pjp.proceed(args); this.commit(); }catch (Throwable e){ this.rollback(); e.printStackTrace(); }finally { this.close(); } return rtnValue; }}","link":"/2020/04/21/Spring%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E4%B8%89-%EF%BC%9AAOP%E9%9D%A2%E5%90%91%E5%88%87%E9%9D%A2%E7%BC%96%E7%A8%8B/"},{"title":"java中的类型擦除和桥方法","text":"Java在语法中虽然存在泛型的概念，但是在虚拟机中却没有泛型的概念，虚拟机中所有的类型都是普通类。无论何时定义一个泛型类型，编译后类型会被都被自动转换成一个相应的原始类型。原始类型的名字就是删去类型参数后的泛型类型名。擦除（erased）类型, 并替换为限定类型（无限定的变量用Object）。 一、Java泛型的实现方法：类型擦除Java的泛型是伪泛型。为什么说Java的泛型是伪泛型呢？因为，在编译期间，所有的泛型信息都会被擦除掉。正确理解泛型概念的首要前提是理解类型擦除（type erasure）。 Java中的泛型基本上都是在编译器这个层次来实现的。在生成的Java字节码中是不包含泛型中的类型信息的。使用泛型的时候加上的类型参数，会在编译器在编译的时候去掉。这个过程就称为类型擦除。 如在代码中定义的List&lt;object&gt;和List&lt;String&gt;等类型，在编译后都会变成List。JVM看到的只是List，而由泛型附加的类型信息对JVM来说是不可见的。Java编译器会在编译时尽可能的发现可能出错的地方，但是仍然无法避免在运行时刻出现类型转换异常的情况。类型擦除也是Java的泛型实现方法与C++模版机制实现方式之间的重要区别。 可以通过两个简单的例子，来证明java泛型的类型擦除。 123456789public class Test { public static void main(String[] args) { ArrayList&lt;String&gt; arrayList1=new ArrayList&lt;String&gt;(); arrayList1.add(\"abc\"); ArrayList&lt;Integer&gt; arrayList2=new ArrayList&lt;Integer&gt;(); arrayList2.add(123); System.out.println(arrayList1.getClass()==arrayList2.getClass()); } } 在这个例子中，我们定义了两个ArrayList数组，不过一个是ArrayList泛型类型，只能存储字符串。一个是 ArrayList泛型类型，只能存储整形。最后，我们通过arrayList1对象和arrayList2对象的getClass方法获取它们的类的信息，最后发现结果为true。说明泛型类型String和Integer都被擦除掉了，只剩下了原始类型。 12345678910public class Test { public static void main(String[] args) throws IllegalArgumentException, SecurityException, IllegalAccessException, InvocationTargetException, NoSuchMethodException { ArrayList&lt;Integer&gt; arrayList3=new ArrayList&lt;Integer&gt;(); arrayList3.add(1);//这样调用add方法只能存储整形，因为泛型类型的实例为Integer arrayList3.getClass().getMethod(\"add\", Object.class).invoke(arrayList3, \"asd\"); for (int i=0;i&lt;arrayList3.size();i++) { System.out.println(arrayList3.get(i)); } }} 在程序中定义了一个ArrayList泛型类型实例化为Integer的对象，如果直接调用add方法，那么只能存储整形的数据。不过当我们利用反射调用add方法的时候，却可以存储字符串。这说明了Integer泛型实例在编译之后被擦除了，只保留了原始类型。 二、类型擦除后保留的原始类型在上面，两次提到了原始类型，什么是原始类型？原始类型（raw type）就是擦除去了泛型信息，最后在字节码中的类型变量的真正类型。无论何时定义一个泛型类型，相应的原始类型都会被自动地提供。类型变量被擦除 （crased），并使用其限定类型（无限定的变量用Object）替换。 比如这个类 12345678910class Pair&lt;T&gt; { private T value; public T getValue() { return value; } public void setValue(T value) { this.value = value; }} 在编译后就变成了 12345678910class Pair { private Object value; public Object getValue() { return value; } public void setValue(Object value) { this.value = value; } } 因为在Pair中，T是一个无限定的类型变量，所以用Object替换。其结果就是一个普通的类，如同泛型加入java变成语言之前已经实现的那样。在程序中可以包含不同类型的Pair，如Pair或Pair，但是，擦除类型后,它们就成为原始的Pair类型了，原始类型都是Object。 从上面的那个例2中，我们也可以明白ArrayList被擦除类型后，原始类型也变成了Object，所以通过反射我们就可以存储字符串了。 如果类型变量有限定，那么原始类型就用第一个边界的类型变量来替换。 比如Pair这样声明 123public class Pair&lt;T extends Comparable&amp; Serializable&gt; { } 那么原始类型就是Comparable 如果Pair这样声明public class Pair&lt;T extends Serializable&amp;Comparable&gt; ，那么原始类型就用Serializable替换，而编译器在必要的时要向Comparable插入强制类型转换。为了提高效率，应该将标签（tagging）接口（即没有方法的接口）放在边界限定列表的末尾。 对类型变量进行替换的规则有两条： 若为无限定的类型，如，被替换为Object 若为限定类型，如&lt;T extends Comparable &amp; Serializable&gt;，则用第一个限定的类型变量来替换，在这里被替换为Comparable 要区分原始类型和泛型变量的类型 在调用泛型方法的时候，可以指定泛型，也可以不指定泛型。 在不指定泛型的情况下，泛型变量的类型为 该方法中的几种类型的同一个父类的最小级，直到Object。 在指定泛型的时候，该方法中的几种类型必须是该泛型实例类型或者其子类。 123456789101112131415161718public class Test2{ public static void main(String[] args) { /**不指定泛型的时候*/ int i=Test2.add(1, 2); //这两个参数都是Integer，所以T为Integer类型 Number f=Test2.add(1, 1.2);//这两个参数一个是Integer，以风格是Float，所以取同一父类的最小级，为Number Object o=Test2.add(1, \"asd\");//这两个参数一个是Integer，以风格是Float，所以取同一父类的最小级，为Object /**指定泛型的时候*/ int a=Test2.&lt;Integer&gt;add(1, 2);//指定了Integer，所以只能为Integer类型或者其子类 int b=Test2.&lt;Integer&gt;add(1, 2.2);//编译错误，指定了Integer，不能为Float Number c=Test2.&lt;Number&gt;add(1, 2.2); //指定为Number，所以可以为Integer和Float } //这是一个简单的泛型方法 public static &lt;T&gt; T add(T x,T y){ return y; } } 在泛型类中，不指定泛型的时候，也差不多，只不过这个时候的泛型类型为Object，就比如ArrayList中，如果不指定泛型，那么这个ArrayList中可以放任意类型的对象。 123456public static void main(String[] args) { ArrayList arrayList=new ArrayList(); arrayList.add(1); arrayList.add(\"121\"); arrayList.add(new Date()); } 三、类型擦除引起的问题及解决方法因为种种原因，Java不能实现真正的泛型，只能使用类型擦除来实现伪泛型，这样虽然不会有类型膨胀的问题，但是也引起了许多新的问题。所以，Sun对这些问题作出了许多限制，避免我们犯各种错误。 1、先检查，在编译，以及检查编译的对象和引用传递的问题既然说类型变量会在编译的时候擦除掉，那为什么我们往ArrayList arrayList=new ArrayList();所创建的数组列表arrayList中，不能使用add方法添加整形呢？不是说泛型变量 Integer会在编译时候擦除变为原始类型Object吗，为什么不能存别的类型呢？既然类型擦除了，如何保证我们只能使用泛型变量限定的类型呢？ java是如何解决这个问题的呢？java编译器是通过先检查代码中泛型的类型，然后再进行类型擦除，在进行编译的。 举个例子说明： 12345678910111213public static void main(String[] args) { ArrayList&lt;String&gt; arrayList=new ArrayList&lt;String&gt;(); arrayList.add(\"123\"); arrayList.add(123);//编译错误 }``` 在上面的程序中，使用add方法添加一个整形，在ide中，直接就会报错，说明这就是**在编译之前的检查**。因为如果是在编译之后检查，类型擦除后，原始类型为Object，是应该运行任意引用类型的添加的。可实际上却不是这样，这恰恰说明了关于泛型变量的使用，是会在编译之前检查的。那么，这么类型检查是针对谁的呢？我们先看看**参数化类型与原始类型的兼容**以ArrayList举例子，以前的写法：```javaArrayList arrayList=new ArrayList(); 现在的写法： 1ArrayList&lt;String&gt; arrayList=new ArrayList&lt;String&gt;(); 如果是与以前的代码兼容，各种引用传值之间，必然会出现如下的情况： 12ArrayList&lt;String&gt; arrayList1=new ArrayList(); //第一种 情况 ArrayList arrayList2=new ArrayList&lt;String&gt;();//第二种 情况 这样是没有错误的，不过会有个编译时警告。 不过在第一种情况，可以实现与完全使用泛型参数一样的效果，第二种则完全没效果。 因为，本来类型检查就是编译时完成的。new ArrayList()只是在内存中开辟一个存储空间，可以存储任何的类型对象。而真正涉及类型检查的是它的引用，因为我们是使用它的引用arrayList1来调用它的方法，比如说调用add()方法。所以arrayList1引用能完成泛型类型的检查。 而引用arrayList2没有使用泛型，所以不行。 举例子： 12345678910111213141516171819public class Test { public static void main(String[] args) { // ArrayList&lt;String&gt; arrayList1=new ArrayList(); arrayList1.add(\"1\");//编译通过 arrayList1.add(1);//编译错误 String str1=arrayList1.get(0);//返回类型就是String ArrayList arrayList2=new ArrayList&lt;String&gt;(); arrayList2.add(\"1\");//编译通过 arrayList2.add(1);//编译通过 Object object=arrayList2.get(0);//返回类型就是Object new ArrayList&lt;String&gt;().add(\"11\");//编译通过 new ArrayList&lt;String&gt;().add(22);//编译错误 String string=new ArrayList&lt;String&gt;().get(0);//返回类型就是String } } 通过上面的例子，我们可以明白，类型检查就是针对引用的，谁是一个引用，用这个引用调用泛型方法，就会对这个引用调用的方法进行类型检测，而无关它真正引用的对象。 从这里我们可以再讨论下，泛型中参数化类型为什么不考虑继承关系 在Java中，像下面形式的引用传递是不允许的： 12ArrayList&lt;String&gt; arrayList1=new ArrayList&lt;Object&gt;();//编译错误 ArrayList&lt;Object&gt; arrayList1=new ArrayList&lt;String&gt;();//编译错误 我们先看第一种情况，将第一种情况拓展成下面的形式： 1234ArrayList&lt;Object&gt; arrayList1=new ArrayList&lt;Object&gt;(); arrayList1.add(new Object()); arrayList1.add(new Object()); ArrayList&lt;String&gt; arrayList2=arrayList1;//编译错误 实际上，在第4行代码的时候，就会有编译错误。那么，我们先假设它编译没错。那么当我们使用arrayList2引用用get()方法取值的时候，返回的都是String类型的对象（上面提到了，类型检测是根据引用来决定的），可是它里面实际上已经被我们存放了Object类型的对象，这样，就会有 ClassCastException了。所以为了避免这种极易出现的错误，Java不允许进行这样的引用传递。（这也是泛型出现的原因，就是为了解决类型转换的问题，我们不能违背它的初衷）。 在看第二种情况，将第二种情况拓展成下面的形式： 1234ArrayList&lt;String&gt; arrayList1=new ArrayList&lt;String&gt;(); arrayList1.add(new String()); arrayList1.add(new String()); ArrayList&lt;Object&gt; arrayList2=arrayList1;//编译错误 没错，这样的情况比第一种情况好的多，最起码，在我们用arrayList2取值的时候不会出现ClassCastException，因为是从String转换为Object。可是，这样做有什么意义呢，泛型出现的原因，就是为了解决类型转换的问题。我们使用了泛型，到头来，还是要自己强转，违背了泛型设计的初衷。所以java不允许这么干。再说，你如果又用arrayList2往里面add()新的对象，那么到时候取得时候，我怎么知道我取出来的到底是String类型的，还是Object类型的呢？ 所以，要格外注意，泛型中的引用传递的问题。 2、自动类型转换因为类型擦除的问题，所以所有的泛型类型变量最后都会被替换为原始类型。这样就引起了一个问题，既然都被替换为原始类型，那么为什么我们在获取的时候，不需要进行强制类型转换呢？看下ArrayList中的get方法： 1234public E get(int index) { RangeCheck(index); return (E) elementData[index]; } 可以看到，在return之前，会根据泛型变量进行强转。 3、类型擦除与多态的冲突和解决方法类型擦除后，就产生了一个奇怪的现象。 假设有一个超类泛型类： 123456789101112class Pair&lt;T&gt; { private T value; public void setValue(T value) { this.value = value; } public T getValue() { return value; } } 以及一个子类继承它： 123456789101112class DateInter extends Pair&lt;Date&gt; { @Override public void setValue(Date value) { super.setValue(value); } @Override public Date getValue() { return super.getValue(); } } 在这个子类中，我们设定父类的泛型类型为Pair，在子类中，我们覆盖了父类的两个方法，我们的原意是这样的： 将父类的泛型类型限定为Date，那么父类里面的两个方法的参数都为Date类型： 12345678910111213141516171819202122public Date getValue() { return value; } public void setValue(Date value) { this.value = value; }``` 所以，我们在子类中**重写**这两个方法一点问题也没有，实际上，从他们的@Override标签中也可以看到，一点问题也没有，实际上是这样的吗？实际上，类型擦除后，父类的的泛型类型全部变为了原始类型Object，所以父类编译之后会变成下面的样子：```javaclass Pair { private Object value; public Object getValue() { return value; } public void setValue(Object value) { this.value = value; } } 再看子类的两个重写的方法的类型： 12345678@Override public Date getValue() { return super.getValue(); } @Override public void setValue(Date value) { super.setValue(value); } 先来分析setValue方法，父类的类型是Object，而子类的类型是Date，参数类型不一样，这如果是在普通的继承关系中，根本就不会是重写，而是重载。 我们在一个main方法测试一下,企图实现多态性： 12345public static void main(String[] args) throws ClassNotFoundException { DateInter dateInter=new DateInter(); dateInter.setValue(new Date()); dateInter.setValue(new Object());//编译错误 } 如果是重载，那么子类中两个setValue方法，一个是参数Object类型，一个是Date类型，不会发生编译错误，可是我们发现，根本就没有这样的一个子类继承自父类的Object类型参数的方法。所以说，确实是重写了，而不是重载了。 为什么会这样呢？ 原因是这样的，我们传入父类的泛型类型是Date，Pair，我们的本意是将泛型类变为如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Pair { private Date value; public Date getValue() { return value; } public void setValue(Date value) { this.value = value; } }``` 然后再子类中重写参数类型为Date的那两个方法，实现继承中的多态。可是由于种种原因，虚拟机并不能将泛型类型变为Date，只能将类型擦除掉，变为原始类型Object。这样，我们的本意是进行重写，实现多态。可是类型擦除后，只能变为了重载。这样，类型擦除就和多态有了冲突。JVM知道你的本意吗？知道！！！可是它能直接实现吗，不能！！！如果真的不能的话，那我们怎么去重写我们想要的Date类型参数的方法？于是JVM采用了一个特殊的方法，来完成这项功能，那就是**桥方法**。首先，我们用`javap -c className`的方式反编译下DateInter子类的字节码，结果如下：```javaclass com.tao.test.DateInter extends com.tao.test.Pair&lt;java.util.Date&gt; { com.tao.test.DateInter(); Code: 0: aload_0 1: invokespecial #8 // Method com/tao/test/Pair.\"&lt;init&gt;\":()V 4: return public void setValue(java.util.Date); //我们重写的setValue方法 Code: 0: aload_0 1: aload_1 2: invokespecial #16 // Method com/tao/test/Pair.setValue:(Ljava/lang/Object;)V 5: return public java.util.Date getValue(); //我们重写的getValue方法 Code: 0: aload_0 1: invokespecial #23 // Method com/tao/test/Pair.getValue:()Ljava/lang/Object; 4: checkcast #26 // class java/util/Date 7: areturn public java.lang.Object getValue(); //编译时由编译器生成的桥方法 Code: 0: aload_0 1: invokevirtual #28 // Method getValue:()Ljava/util/Date 去调用我们重写的getValue方法; 4: areturn public void setValue(java.lang.Object); //编译时由编译器生成的桥方法 Code: 0: aload_0 1: aload_1 2: checkcast #26 // class java/util/Date 5: invokevirtual #30 // Method setValue:(Ljava/util/Date;去调用我们重写的setValue方法)V 8: return } 从编译的结果来看，我们本意重写setValue和getValue方法的子类，竟然有4个方法，其实不用惊奇，最后的两个方法，就是编译器自己生成的桥方法。可以看到桥方法的参数类型都是Object，也就是说，子类中真正覆盖父类两个方法的就是这两个我们看不到的桥方法。而打在我们自己定义的setvalue和getValue方法上面的@Oveerride只不过是假象。而桥方法的内部实现，就只是去调用我们自己重写的那两个方法。 所以，虚拟机巧妙的使用了桥方法，来解决了类型擦除和多态的冲突。 最后有以下测试代码，企图实现多态： 12345678910public class MainApp{ public static void main(String[] args) { DateInter dateInter = new DateInter(); Pair&lt;Date&gt; pair = dateInter; pair.setValue(new Date()); }} 运行的时候，会对DateInter类的方法表进行搜索，先分析一下DateInter类的方法表里有哪些东西： setValue(Object value) : 从类型被擦除后的超类中继承过来 setValue(Date value) : 自己新增的方法，和超类毫无联系 一些从Object类继承来的方法，这里忽略 按理来说，这段测试代码应该不能通过编译，因为要实现多态的话，所调用的方法必须在子类中重写，但是在这里DateInter类并没有重写Pair类中的setValue(Object value)方法，只是单纯的继承而已，并且新加了一个参数不同的同名方法,实现了重载。 但是结果是可以正常运行。 原因是编译器在DateInter类中自动生成了一个桥方法： 1234public void setValue(Object value){ setValue((Date) value);} 可以看出，这个桥方法实际上就是对超类中setValue(Obejct)的重写。这样做的原因是，当程序员在子类中写下以下这段代码的时候，本意是对超类中的同名方法进行重写，但因为超类发生了类型擦除，加入了桥方法的机制来避免类型擦除与多态发生冲突。 桥方法并不需要自己手动生成，一切都是编译器自动完成的。 不过，要提到一点，这里面的setValue和getValue这两个桥方法的意义又有不同。 setValue方法是为了解决类型擦除与多态之间的冲突。 而getValue却有普遍的意义，怎么说呢，如果这是一个普通的继承关系： 那么父类的setValue方法如下： public Object getValue() { return super.getValue();} 而子类重写的方法是： public Date getValue() { return super.getValue();} 但是正如前面所述，重写并没有起作用，甚至还应该报错，因为在子类中，根据函数签名=方法名+参数的原则，重写需要保证子类方法的参数列表、方法名称、返回值必须和父类方法一致，但是返回参数不同。从超类继承的方法与新增的方法冲突了。 但实际上这样的代码是可以工作的，原因在于，JVM是用返回值+方法名+参数的方式来计算函数签名的，所以编译器就可以借助这一原则来生成一个桥方法。不过这种计算函数签名的方法仅仅存在于虚拟机中。 总之，需要记住有关 Java 泛型转换的事实： 虚拟机中没有泛型，只有普通的类和方法。 所有的类型参数都用它们的限定类型替换。 桥方法被合成来保持多态。 为保持类型安全性，必要时插入强制类型转换。","link":"/2020/05/05/java%E4%B8%AD%E7%9A%84%E7%B1%BB%E5%9E%8B%E6%93%A6%E9%99%A4%E5%92%8C%E6%A1%A5%E6%96%B9%E6%B3%95/"},{"title":"Spring基础学习(二)：基于XML的IOC配置","text":"讨论基于xml的IOC配置的细节问题 Spring中工厂类的结构图 1234567891011121314151617181920/** *client层中利用Spring工厂获取需要的对象 * 获取spring的Ioc核心容器，并根据id获取对象 * * ApplicationContext的三个常用实现类： * ClassPathXmlApplicationContext:它可以加载类路径下的配置文件，要求配置文件必须在类路径下。不在的话无法加载 * FileSystemXmlApplicationContext:它可以加载磁盘任意路径下的配置文件（必须有访问权限） * AnnotationConfigApplicationContext：它用于读取注解创建容器的。 * * BeanFactory 才是 Spring 容器中的顶层接口。 ApplicationContext 是它的子接口。 * 核心容器的两个接口引发的问题： * ApplicationContext： 单例对象适用 * 它在构建核心容器时，创建对象采取的策略是采用立即加载的方式。也就是说， * 只要一读完配置文件马上就创建配置文件中配置的对象 * BeanFactory： 多例对象使用 * 它在构建核心容器时，创建对象采取的策略是采用延迟加载的方式。也就是说， * 什么适合根据id获取对象了，什么时候才真正创建对象。 * * */ 实例化 Bean 的三种方式第一种方式：使用默认无参构造函数1234&lt;!--在默认情况下： 它会根据默认无参构造函数来创建类对象。如果 bean 中没有默认无参构造函数，将会创建失败。&lt;bean id=\"accountService\"class=\"com.itheima.service.impl.AccountServiceImpl\"/&gt; 第二种方式：spring管理实例工厂-使用实例工厂的方法创建对象123456789101112131415161718/** * 模拟一个实例工厂，创建业务层实现类 * 此工厂创建对象，必须现有工厂实例对象，再调用方法 */ public class InstanceFactory { public IAccountService createAccountService(){ return new AccountServiceImpl(); } } &lt;!-- 此种方式是： 先把工厂的创建交给 spring 来管理。 然后在使用工厂的 bean 来调用里面的方法 factory-bean 属性：用于指定实例工厂 bean 的 id。 factory-method 属性：用于指定实例工厂中创建对象的方法。 --&gt; &lt;bean id=\"instancFactory\" class=\"com.itheima.factory.InstanceFactory\"&gt;&lt;/bean&gt; &lt;bean id=\"accountService\" factory-bean=\"instancFactory\" factorymethod=\"createAccountService\"&gt; &lt;/bean&gt; 该方法通常用于类没有默认构造函数，且在jar包中，我们无法改变其字节流文件。 第三种方式：spring管理静态工厂-使用静态工厂的方法创建对象1234567891011121314/** * 模拟一个静态工厂，创建业务层实现类 */ public class StaticFactory { public static IAccountService createAccountService(){ return new AccountServiceImpl(); }} &lt;!-- 此种方式是: 使用 StaticFactory 类中的静态方法 createAccountService 创建对象，并存入 spring 容器 id 属性：指定 bean 的 id，用于从容器中获取 class 属性：指定静态工厂的全限定类名 factory-method 属性：指定生产对象的静态方法 --&gt; &lt;bean id=\"accountService\" class=\"com.itheima.factory.StaticFactory\" factory-method=\"createAccountService\"&gt;&lt;/bean&gt; 该方法同第二种，但是可以直接通过工厂静态方法创建需要的bean对象。 IOC 中 bean 标签和管理对象细节bean 标签作用： 用于配置对象让 Spring 来创建bean的。 默认情况下它调用的是类中的无参构造函数。如果没有无参构造函数则不能创建成功。 属性： id：给对象在容器中提供一个唯一标识。用于获取对象。一般取为对象的类名。 class：指定类的全限定类名。用于反射创建对象。默认情况下调用无参构造函数。 scope：指定对象的作用范围。 singleton:默认值，单例的对象. prototype:多例的对象. request :WEB 项目中,Spring 创建一个 Bean 的对象,将对象存入到 request 域中. session:WEB 项目中,Spring 创建一个 Bean 的对象,将对象存入到 session 域中. global session :WEB 项目中,应用在集群环境.如果没有 Portlet 环境那么 globalSession 相当于 session. init-method：指定类中的初始化方法名称。 destroy-method：指定类中销毁方法名称。 bean 的作用范围和生命周期单例对象：scope=”singleton” 一个应用只有一个对象的实例。 它的作用范围就是整个引用。生命周期： 对象出生：当应用加载，创建容器时，对象就被创建了。 对象活着：只要容器在，对象一直活着。 对象死亡：当应用卸载，销毁容器时，对象就被销毁了。总结：单例对象生命周期和容器相同。 多例对象：scope=”prototype” 每次访问对象时，都会重新创建对象实例。 生命周期： 对象出生：当使用对象时，创建新的对象实例。 对象活着：只要对象在使用中，就一直活着。 对象死亡：当对象长时间不用时，被 java 的垃圾回收器回收了。即使容器销毁，对象也不会销毁，因为spring无法判断创建出的所有对象是否仍在使用中。 spring 的依赖注入依赖注入的概念依赖注入是Spring的灵魂所在。用new的话写着很简单，一行就完事了，但是后期维护怎么办，比如我们玩的LOL，今天无尽的暴击25%，明天我要改成20%，难道就回去修改源代码吗？并不是，而是打一个补丁包，用的就是这种依赖注入的方式。要牢牢把握依赖注入的概念。 依赖注入：Dependency Injection。它是 spring 框架核心 ioc 的具体实现。 我们的程序在编写时，通过控制反转，把对象的创建交给了 spring，但是代码中不可能出现没有依赖的情况。 Ioc 解耦只是降低他们的依赖关系，但不会消除。例如：我们的业务层仍会调用持久层的方法。 那这种业务层和持久层的依赖关系，在使用 spring 之后，就让 spring 来维护了。在当前类需要用到其他类的对象时，由spring为我们提供，我们只需要在配置文件中说明。那么这种依赖关系的维护，就称之为依赖注入。 简单的说，就是坐等框架把持久层对象传入业务层，而不用我们自己去获取。 我们只需要编写配置文件即可。 依赖注入 能注入的数据，有三类 基本类型和String 其他bean类型（在配置文件中或者注解配置过的bean） 复杂类型/集合类型 注入的方式，有三种 使用构造函数提供 使用set方法提供 使用注解提供 构造函数注入当一个类和另一个类产生了依赖，那么可以将被依赖的类定义为被注入类的成员变量。spring通过使用构造函数提供的方法注入被依赖类。 要求被注入类提供一个对应参数列表的构造函数。 12345678910111213141516&lt;!-- 使用构造函数的方式，给 service 中的属性传值要求： 类中需要提供一个对应参数列表的构造函数。 涉及的标签： constructor-arg 属性： index:指定参数在构造函数参数列表的索引位置 从0开始type:指定参数在构造函数中的数据类型 name:指定参数在构造函数中的名称 常用的 =======上面三个都是找给谁赋值，下面两个指的是赋什么值的============== value:它能赋的值是基本数据类型和 String 类型 ref:它能赋的值是其他 bean 类型，也就是说，必须得是在配置文件中配置过的bean --&gt; &lt;bean id=\"accountService\" class=\"com.itheima.service.impl.AccountServiceImpl\"&gt; &lt;constructor-arg type=\"java.lang.String\" value=\" 张三 \"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"age\" value=\"18\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg name=\"birthday\" ref=\"now\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;bean id=\"now\" class=\"java.util.Date\"&gt;&lt;/bean&gt; 构造函数注入的方法 优点:在获取bean对象时，注入数据是必须的操作，否则对象无法创建成功。 弊端：改变了bean对象的实例化方式，使我们在创建对象时，如果用不到这些数据，也必须提供。如果写多个构造函数，会非常麻烦。当依赖对象比较多的时候，构造方法的参数会比较长。 除非避无可避，否则我们一般不用这种方式。 set方法注入顾名思义，就是在类中提供需要注入成员的set方法，即用set方法代替了构造函数。 123456789101112&lt;!-- 通过配置文件给bean中的属性传值：使用set方法的方式涉及的标签： property 属性： name：找的是类中set方法后面的部分 ref：给属性赋值是其他bean类型的 value：给属性赋值是基本数据类型和string类型的 实际开发中，此种方式用的较多。 --&gt;&lt;bean id=\"accountService\" class=\"com.itheima.service.impl.AccountServiceImpl\"&gt; &lt;property name=\"name\" value=\"test\"&gt;&lt;/property&gt; &lt;property name=\"age\" value=\"21\"&gt;&lt;/property&gt; &lt;property name=\"birthday\" ref=\"now\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean id=\"now\" class=\"java.util.Date\"&gt;&lt;/bean&gt; set注入的方法 优点:创建对象没有明确的限制，可以直接使用默认构造函数 弊端：如果有某个成员必须有值，但是获取对象时有可能set方法没有执行。 注入集合属性顾名思义，就是给类中的集合成员传值，它用的也是set方法注入的方式，只不过变量的数据类型都是集合。 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;!-- 注入集合数据 List 结构的： array,list,set Map 结构的 map,entry,props,prop --&gt; &lt;bean id=\"accountService\" class=\"com.itheima.service.impl.AccountServiceImpl\"&gt; &lt;!-- 在注入集合数据时，只要结构相同，标签可以互换 --&gt; &lt;!-- 给数组注入数据 --&gt; &lt;property name=\"myStrs\"&gt; &lt;set&gt; &lt;value&gt;AAA&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;CCC&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; &lt;!-- 注入 list 集合数据 --&gt; &lt;property name=\"myList\"&gt; &lt;array&gt; &lt;value&gt;AAA&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;CCC&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;!-- 注入 set 集合数据 --&gt; &lt;property name=\"mySet\"&gt; &lt;list&gt; &lt;value&gt;AAA&lt;/value&gt; &lt;value&gt;BBB&lt;/value&gt; &lt;value&gt;CCC&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!-- 注入 Map 数据 --&gt; &lt;property name=\"myMap\"&gt; &lt;props&gt; &lt;prop key=\"testA\"&gt;aaa&lt;/prop&gt; &lt;prop key=\"testB\"&gt;bbb&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;!-- 注入 properties 数据 --&gt; &lt;property name=\"myProps\"&gt; &lt;map&gt; &lt;entry key=\"testA\" value=\"aaa\"&gt;&lt;/entry&gt; &lt;entry key=\"testB\"&gt; &lt;value&gt;bbb&lt;/value&gt; &lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt;","link":"/2020/04/15/Spring%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0-%E4%BA%8C-%EF%BC%9A%E5%9F%BA%E4%BA%8EXML%E7%9A%84IOC%E9%85%8D%E7%BD%AE/"},{"title":"mybatis基础学习","text":"学习了3天的mybatis的基础，现在做一个总结，并且记录自己不太清楚的地方。 Mybatis入门 Mybatis是⼀个基于Java的持久层框架。⽆论是Mybatis、Hibernate都是ORM的⼀种实现框架，都是对JDBC的⼀种封装。 对象关系映射ORM（Object Relational Mapping）是通过使用描述对象和数据库之间映射的元数据，将面向对象语言程序中的对象自动持久化到关系数据库中。本质上就是将数据从一种形式转换到另外一种形式。 快速入门创建普通工程，使用Maven，引入依赖。 创建Mybatis配置文件Mybatis核心在于.xml文件的配置（另有注解开发）。 配置resources目录下的SqlMapConfig.xml 123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!-- 设置⼀个默认的连接环境信息 --&gt; &lt;environments default=\"mysql\"&gt; &lt;!-- 连接环境信息，取⼀个任意唯⼀的名字 --&gt; &lt;environment id=\"mysql\"&gt; &lt;!-- mybatis使⽤jdbc事务管理⽅式 --&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;!-- mybatis使⽤连接池⽅式来获取连接 POOLED/UNPOOLED/JUNIT --&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;!-- 配置与数据库交互的4个必要属性 可以直接填写，也可以引用resources下的资源文件jdbc.properties value=${jdbc.driver/url/username/password} --&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql:///mybatis\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"root\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource=\"com/lehirt/dao/UserDao.xml\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 创建实体与映射关系文件配置实体与表的映射关系 配置resources.com.lehirt.dao.UserDao.xml 12345678910111213141516171819202122232425262728&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;!-- namespace属性是名称空间，必须唯⼀,使SqlMapConfig.xml能够找到--&gt;&lt;mapper namespace=\"com.lehirt.dao.UserDao\"&gt; &lt;!--namespace+id 标识了唯一的dao层接口和接口中的唯一方法 --&gt; &lt;!--几个重要属性：resultType,resultMap,parameterType --&gt; &lt;select id=\"findAll\" resultType=\"com.lehirt.domain.User\"&gt; select * from user ; &lt;/select&gt; &lt;insert id=\"insertUser\" parameterType=\"com.lehirt.domain.User\"&gt; &lt;selectKey keyProperty=\"id\"keyColumn=\"id\"order=\"AFTER\" resultType=\"java.lang.Integer\"&gt; select last_insert_id(); &lt;/selectKey&gt; insert into user (username, birthday, sex, address) values (#{username},#{birthday},#{sex},#{address}); &lt;/insert&gt; &lt;update id=\"updateUser\" parameterType=\"com.lehirt.domain.User\"&gt; update user set username = #{username} , birthday = #{birthday} where id = #{id} &lt;/update&gt; &lt;delete id=\"deleteUser\" parameterType=\"com.lehirt.domain.User\"&gt; delete from user where id=#{id}; &lt;/delete&gt;&lt;/mapper&gt; 将配置文件和映射文件关联起来在SqlMapConfig.xml中，添加 12345&lt;mappers&gt; &lt;!--resource属性必须写映射文件的全限定类名 --&gt; &lt;!--与之区别的是package属性 --&gt; &lt;mapper resource=\"com/lehirt/dao/UserDao.xml\"/&gt;&lt;/mappers&gt; 编写dao层接口主要是定义操作数据库的方法，且不用写实现类。 几个知识点 在Mybatis中，有两种占位符。 #{}实际上就是调用了实体属性的get方法，解析传递进来的参数数据。作为JDBC中的”?”，防止SQL注入。 与之对应的是${}表示引用，对传递进来的参数原样拼接在SQL中 Mybatis中的事务是默认开启的，因此在完成操作以后，需要手动去提交事务，即SqlSession.commit()。 Mybatis工作流程： 通过Resources.getResourceAsStream（”SqlMapConfig.xml”）获取流 new SqlSessionFactoryBuilder().build(in)获取工厂对象factory factory.openSession()获取当前线程SqlSession SqlSession.getMapper(UserDao.class)获取userDao对象 提交事务，关闭连接。 关于映射文件.xml的配置，几个标签 123456789101112&lt;!-- resultMap标签：映射实体与表，将实体变量与表字段一一对应 type属性：表示实体全限定类名（除了有package标签） id属性：为实体和表的映射取一个唯一且任意的名字标识--&gt; &lt;!--id标签：映射主键属性 result标签：映射非主键属性 property属性：实体的属性名 column属性：表的字段名 --&gt;&lt;!--查询语句select的执行，若有resultMap则使用 属性resultMap=\"#{id}\"代替resultType resultMap可以解决别名问题。--&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061 ## Mybatis的分页分页需要方法接收多个参数。**使用Map集合来装载**多个参数。那么UserDao中方法传递参数类型为Map（其它集合也可以），即`parameterType=&quot;Map&quot;`。返回类型为`List&lt;E&gt;`，可以实现分页。## 动态SQL动态SQL就是自动拼接SQL语句。在我们的多条件组合查询中经常会碰到。这里有几个动态SQL的标签即`if`，`foreach`，`where`。- \\&lt;if&gt;标签的test属性中写的是对象的属性名，如果是包种类的对象要使用**OGNL表达式**的写法。- \\&lt;为了简化where 1=1的条件拼装，采用\\&lt;where&gt;标签简化开发&gt;- \\&lt;foreach&gt;标签，传入多个参数，需要遍历参数。属性： - collection:代表要遍历的集合，注意编写时不要写#{} - open:代表语句的开始部分 - close:代表结束部分重点，自己查看实现的demo。## Mybatis多表查询（表的连接查询）### 一对一查询一条记录只能对应另一张表中另一条记录，即一对一。如Account对User。#### 方式一创建一个新的POPJ类，将查询后的结果（两表连接的新表）直接放入POPJ中。dao方法中的sql语句都在初始的两张表中，POPJ仅承担封装任务。此方法较为简单，企业中使用普遍。 #### 方式二在Account 类中加入User类的对象作为Account类的一个属性。 则满足一对一查询的条件：一个Account只能对应一个User。编写Account的dao方法，结果封装在Account中即可。重新定义AccountDao.xml文件。​```xml&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt; &lt;mapper namespace=&quot;com.itheima.dao.IAccountDao&quot;&gt; &lt;!-- 建立对应关系 --&gt; &lt;resultMap type=&quot;account&quot; id=&quot;accountMap&quot;&gt; &lt;id column=&quot;aid&quot; property=&quot;id&quot;/&gt; &lt;result column=&quot;uid&quot; property=&quot;uid&quot;/&gt; &lt;result column=&quot;money&quot; property=&quot;money&quot;/&gt; &lt;!-- 它是用于指定从表方的引用实体属性的 --&gt; &lt;association property=&quot;user&quot; javaType=&quot;user&quot;&gt; &lt;id column=&quot;id&quot; property=&quot;id&quot;/&gt; &lt;result column=&quot;username&quot; property=&quot;username&quot;/&gt; &lt;result column=&quot;sex&quot; property=&quot;sex&quot;/&gt; &lt;result column=&quot;birthday&quot; property=&quot;birthday&quot;/&gt; &lt;result column=&quot;address&quot; property=&quot;address&quot;/&gt; &lt;/association&gt; &lt;/resultMap&gt; &lt;select id=&quot;findAll&quot; resultMap=&quot;accountMap&quot;&gt; select u.*,a.id as aid,a.uid,a.money from account a,user u where a.uid =u.id; &lt;/select&gt; &lt;/mapper&gt; 一对多查询一条记录对应另一张表中多条记录，即一对多。每个User可以拥有很多Account。查询过程中如果用户没有账户信息，此时也要将用户信息查询出来。 一般SQL语句使用左/右外连接。 在User类中加入List&lt;Account&gt;作User类的一个属性。 则满足一对多查询的条件：一个User可以对应多个Account。编写User的dao方法，结果封装在User中即可。 123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.itheima.dao.IUserDao\"&gt; &lt;resultMap type=\"user\" id=\"userMap\"&gt; &lt;id column=\"id\" property=\"id\"&gt;&lt;/id&gt; &lt;result column=\"username\" property=\"username\"/&gt; &lt;result column=\"address\" property=\"address\"/&gt; &lt;result column=\"sex\" property=\"sex\"/&gt; &lt;result column=\"birthday\" property=\"birthday\"/&gt; &lt;!-- collection 是用于建立一对多中集合属性的对应关系 ofType 用于指定集合元素的数据类型 --&gt; &lt;collection property=\"accounts\" ofType=\"account\"&gt; &lt;id column=\"aid\" property=\"id\"/&gt; &lt;result column=\"uid\" property=\"uid\"/&gt; &lt;result column=\"money\" property=\"money\"/&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;!-- 配置查询所有操作 --&gt; &lt;select id=\"findAll\" resultMap=\"userMap\"&gt; select u.*,a.id as aid ,a.uid,a.money from user u left outer join account a on u.id =a.uid &lt;/select&gt; &lt;/mapper&gt; collection 部分定义了用户关联的账户信息。表示关联查询结果集property=\"accounts\" ： 关联查询的结果集存储在 User 对象的上哪个属性。accounts是定义在User中的List&lt;Account&gt;。ofType=\"account\" ： 指定关联查询的结果集中的对象类型即List中的对象类型。此处可以使用别名，也可以使用全限定名。 Mybatis 多表查询之多对多","link":"/2020/04/13/mybatis%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/"},{"title":"基于xml的Ioc单表操作","text":"学习完spring基于xml和基于注解的配置，那么现在来看一个案例。 该案例使用dbutils+spring实现一个对Account表的CRUD操作。主要注意几个关于xml配置的关键问题。 业务层AccountImpl中需要依赖持久层的AccountDaoImpl去实现对数据库的增删查改操作。 持久层AccountDaoImpl中需要依赖dbutils中的类QueryRunner。 在表现层中是通过1. 获取spring容器2.从容器中获取业务层对象AccountImpl。 于是在bean.xml中需要配置AccountImpl，同时对AccountImpl进行依赖注入，一般使用set方法，且需要配置AccountDaoImpl，使用ref标签。 配置AccountDaoImpl时，需要注入对QueryRunner的依赖。而QueryRunner类此时需要对数据源的注入。数据源中不存在set方法，使用默认构造函数进行注入，即标签constructor-arg。需要注意的是，QueryRunner是单例对象时，面对多个dao的使用时，有可能产生线程安全问题，所以scope属性为prototype 数据源同样需要配置，需要注入连接数据库的4个基本信息。 123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!--配置Service--&gt; &lt;bean id=\"AccountImpl\" class=\"com.lehirt.service.impl.AccountImpl\"&gt; &lt;!--注入dao，需要先配置dao--&gt; &lt;property name=\"AccountDao\" ref=\"AccountDaoImpl\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置Controller--&gt; &lt;bean id=\"AccountDaoImpl\" class=\"com.lehirt.dao.impl.AccountDaoImpl\"&gt; &lt;!--注入runner对象--&gt; &lt;property name=\"Runner\" ref=\"runner\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置Runner--&gt; &lt;bean id=\"runner\" class=\"org.apache.commons.dbutils.QueryRunner\" scope=\"prototype\"&gt; &lt;!--注入数据源--&gt; &lt;constructor-arg name=\"ds\" ref=\"dataSource\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!--配置数据源--&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;!--注入连接数据库的基本信息--&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql:///myspring\"&gt;&lt;/property&gt; &lt;property name=\"user\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"root\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 现在再来看一下基于注解的Ioc配置。 首先要导入javax.annotation-apijar包，在bean.xml中，基本配置不同。最重要的是要告知spring获取容器时的扫描对象。由于dbutils在jar包中，仍需要在bean.xml中配置。 1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;context:annotation-config/&gt; &lt;!--告知spring获取容器时的扫描对象--&gt; &lt;context:component-scan base-package=\"com.lehirt\" &gt;&lt;/context:component-scan&gt; &lt;!--配置Runner--&gt; &lt;bean id=\"runner\" class=\"org.apache.commons.dbutils.QueryRunner\" scope=\"prototype\"&gt; &lt;!--注入数据源--&gt; &lt;constructor-arg name=\"ds\" ref=\"dataSource\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;!--配置数据源--&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;!--注入连接数据库的基本信息--&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"&gt;&lt;/property&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql:///myspring\"&gt;&lt;/property&gt; &lt;property name=\"user\" value=\"root\"&gt;&lt;/property&gt; &lt;property name=\"password\" value=\"root\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 业务层，持久层分别用注解@Service和@Reposity，类中的依赖可以使用自动依赖注入注释@Autowired。如果有依赖未被注入，则会产生空指针异常。 现在存在一个问题，就是我们仍无法删除配置文件bean.xml，因为数据库对象QueryRunner类不是由我们自定义的bean，而是jar包中的字节流文件。所以需要其他的注解。 为了删除bean.xml，我们需要在com.config包路径下创建一个配置类SpringConfiguration，该类就是注解的配置类。 @Configuration：指明当前类是一个配置类 @ComponentScan：告知Spring扫描包读取注解。相当于在bean.xml中配置&lt;context:component-scan base-package=”com.lehirt” &gt;&lt;/context:component-scan&gt; 为了获取jar包中的类对象，需要创建工厂方法，而普通的工厂方法无法自动将创建的对象放入spring容器中，这是和bean.xml最大的区别，所以需要注解@Bean，将创建的对象放入spring容器中。 Bean：用于把当前方法的返回值存入spring容器中。name属性:用于指定bena在容器（map）中的key值。 容易知道此时QueryRunner是单例的，与我们的xml配置相悖。需要注解@scope。 如果不想扫描其他配置包，同时不想在创建AnnotationConfigApplicationContext时传入字节码文件，那么需要注解@Import，导入需要的字节码文件。","link":"/2020/04/18/%E5%9F%BA%E4%BA%8Exml%E7%9A%84Ioc%E5%8D%95%E8%A1%A8%E6%93%8D%E4%BD%9C/"},{"title":"从wireshark抓包分析TCP","text":"记录《计算机网络：自顶向下方法》实验—捕获从计算机到远程服务器的批量TCP传输。通过追踪TCP流，对整个网络系统有更整体的把握。 实验操作：将文本文件”alice.txt”传输到 http://gaia.cs.umass.edu/wireshark-labs/TCP-wireshark-file1.html。wireshark抓包分析。 取消wireshark默认配置，对TCP的相对序号。则会显示实际序号，如第一帧中客户机连接请求中Seq=1468244655是随机选取的序号。 以上是对“向服务器传送一个文本文件”的TCP流追踪。 当应用程序发起一个HTTP请求时，会先进行三次握手。第4个包才是HTTP包（TCP字段中有PUSH标志。），说明Http协议确实是使用TCP建立连接。 本文不纠结TCP细节。主要思考，TCP和HTTP的关系。 TCP连接建立以后（三次握手后），开始传输数据。数据的传输遵从HTTP协议。第4个包中表明数据开始传输，仍是TCP协议。从第4个包中开始传输HTTP头以及数据（alice.txt）。由于MTU和MSS的限制，所有数据不得不分为TCP报文段分段传送。即可以在wireshark中看到大量的[TCP segment of a reassembled PDU]。每个TCP报文段中均包含一部分数据，根据TCP追踪流可以准确知道任意部分数据属于哪一TCP报文段传输。从第4帧push字段开始传输数据，到第198帧HTTP出现为止，表示客户数据已经传输完毕。此时仍有服务器对TCP报发送ACK，服务器所有ACK发送完毕，根据HTTP协议最后发送一个HTTP回复报文。之后开始四次挥手解除连接。","link":"/2020/04/04/%E4%BB%8Ewireshark%E6%8A%93%E5%8C%85%E5%88%86%E6%9E%90TCP/"},{"title":"springMVC构建web项目的坑","text":"一生之敌Maven骨架构建项目。盘点构建maven web项目中的404坑 因为环境问题无法利用maven骨架创建appweb项目，于是手动创建了一个web项目。然而由于配置的不熟悉，所以产生了很多404错误。 springMVC构建了一个简单的web项目。启动服务器。 index.jsp 404. 所有web资源404. 首先检查pom.xml。注意打包方式 1&lt;packaging&gt;war&lt;/packaging&gt; 简单来说，JavaSE程序可以打包成Jar包；而war包是JavaWeb程序打的包。区别就是WAR文件代表了一个Web应用程序，JAR是类的归档文件。所以一定一定不要打成jar包！ 之后就是服务器Tomcat的问题。 服务器启动部署（deploy at the server startup）一定要选择该项目下的war包方式。否则也会产生404问题。","link":"/2020/04/21/springMVC%E6%9E%84%E5%BB%BAweb%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%9D%91/"},{"title":"ssm整合过程","text":"做了一个简单的留言板demo，主要为了熟悉ssm的整合过程。 先来看一下最终的项目结构 整合步骤保证Spring框架在web工程中独立运行编写spring配置文件并导入约束12345678910111213141516171819202122&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!--配置spring容器扫描注解的包 --&gt; &lt;context:component-scan base-package=\"com.lehirt\"&gt; &lt;!-- Controller由springMVC配置文件管理，不扫描 --&gt; &lt;context:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;/context:component-scan&gt;&lt;/beans&gt; 使用spring注解配置业务层和持久层12@Service(\"loginService\")public class loginServiceImpl implements loginService {} 12@Repository(\"loginDao\")public class loginDaoImpl implements loginDao {} 测试spring能否独立运行123456789public class Test01Spring { public static void main(String[] args) { ApplicationContext ac = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); loginService as = ac.getBean(\"loginService\",loginService.class); as.findAll(); } } 保证springMVC在web工程中单独运行在web.xml中配置核心控制器(DispatcherServlet)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app version=\"3.0\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd\"&gt; &lt;display-name&gt;ssm_web&lt;/display-name&gt; &lt;!--配置spirngMVC的核心控制器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 全局初始化参数，为了加载springMVC配置文件 --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-parm&gt; &lt;!-- 配置servlet对象的创建时间点：应用加载时创建。取值是非0的正整数，表示启动顺序 --&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;dispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!-- 配置springMVC编码过滤器，解决中文乱码问题 --&gt; &lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;!-- 设置过滤器中的属性值 --&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;!-- 启动过滤器 --&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;!-- 过滤所有请求 --&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; 编写springMVC的配置文件1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"&gt; &lt;!-- 配置创建spring容器要扫描的包,只扫描Controller --&gt; &lt;context:component-scan base-package=\"com.lehirt\"&gt; &lt;context:include-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/&gt; &lt;/context:component-scan&gt; &lt;!--配置视图解析器--&gt; &lt;bean id=\"internalResourceViewResolver\" class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;!--配置文件所在的目录--&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/pages/\"&gt;&lt;/property&gt; &lt;!--配置文件的后缀名--&gt; &lt;property name=\"suffix\" value=\".jsp\"&gt;&lt;/property&gt; &lt;/bean&gt; &lt;!--配置过滤静态资源，无--&gt; &lt;!--配置springMVC注解支持 --&gt; &lt;mvc:annotation-driven/&gt; 编写Controller注解12@Controller(\"loginController\")public class loginController {} 整合Spirng和SpringMVCweb.xml中配置监听器实现启动服务器创建容器123456789&lt;!--配置spring配置文件的监听对象,默认只扫描WEB-INF目录下的applicationContext.xml--&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;!--手动指定文件扫描目录--&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt; 保证Mybatis框架在web工程中独立运行编写dao层映射配置文件采用注解配置可以不配置该文件，直接使用注解方式。 1234567&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.lehirt.dao.loginDao\"&gt; &lt;/mapper&gt; 配置SqlMapConfig配置文件123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt; &lt;configuration&gt; &lt;properties resource=\"jdbcConfig.properties\"&gt;&lt;/properties&gt; &lt;environments default=\"mysql\"&gt; &lt;environment id=\"mysql\"&gt; &lt;transactionManager type=\"JDBC\"&gt;&lt;/transactionManager&gt; &lt;dataSource type=\"pooled\"&gt; &lt;property name=\"driver\" value=\"${jdbc.driver}\"/&gt; &lt;property name=\"url\" value=\"${jdbc.url}\"/&gt; &lt;property name=\"username\" value=\"${jdbc.username}\"/&gt; &lt;property name=\"password\" value=\"${jdbc.password}\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper package=\"com/lehirt/dao\"/&gt; &lt;/mappers&gt; &lt;/configuration&gt; properties 文件中的内容： jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/ssm jdbc.username=root jdbc.password=root 整合spring和Mybatisspring接替Mybatis的Session工厂在applicationContext.xml文件中配置，不再需要Mybatis的SqlMapConfig.xml文件。 123456789101112131415161718192021222324252627282930313233343536&lt;!--spring整合mybatis--&gt;&lt;!--配置连接池--&gt;&lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;property name=\"driverClass\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql:///mydbms\"/&gt; &lt;property name=\"user\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"root\"/&gt;&lt;/bean&gt;&lt;!--配置SqlsessionFactory工厂--&gt;&lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt;&lt;/bean&gt;&lt;!--配置dao层接口--&gt;&lt;bean id=\"mapperScanner\" class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.lehirt.dao\"/&gt;&lt;/bean&gt;&lt;!-- 配置事务管理器 --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"&gt;&lt;/property&gt;&lt;/bean&gt; &lt;!-- 配置事务的通知 --&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;tx:attributes&gt; &lt;tx:method name=\"*\" propagation=\"REQUIRED\" read-only=\"false\"/&gt; &lt;tx:method name=\"find*\" propagation=\"SUPPORTS\" read-only=\"true\"/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt; &lt;!-- 配置 aop --&gt; &lt;aop:config&gt; &lt;!-- 配置切入点表达式 --&gt; &lt;aop:pointcut expression=\"execution(* com.itheima.service.impl.*.*(..))\" id=\"pc1\"/&gt; &lt;!-- 建立通知和切入点表达式的关系 --&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"pc1\"/&gt; &lt;/aop:config&gt; 整个ssm整合完毕。","link":"/2020/04/26/ssm%E6%95%B4%E5%90%88%E8%BF%87%E7%A8%8B/"},{"title":"算法之回溯法","text":"回溯法对解空间作深度优先搜索，因此在一般情况下可用递归函数来实现回溯法。在许多递归问题当中，我们采取的方法都是穷尽所有的可能，从而找出合法的解。但是在某些情况下，当递归到某一层的时候，根据设置的判断条件，可以 judge 此解是不合法的。在这种情况下，我们就没必要再进行深层次的递归，从而可以提高算法效率。这一类算法我们称为“回溯法”，设置的判断条件称为“剪枝函数”。 回溯法的递归形式： 12Input : X = {X1, X2, ..., Xn}Output: T = (t1, t2, ..., tn) 12345678910111213141516171819back-track-rec(int now){ for x0 in X { T[now] = x0 if (T[0...now] is valid) //如果有效则进行，否则尝试下一个x0 { if (now == n) //是完整解 { print(T[1...now]); return; } else if (now &lt; n) //是部分解 { back-track-rec(now+1); } } }} 如何选择递归的出口？简单来说，回溯法中把出口语句放在递归函数的第一行就行。 如何对递归函数的参数进行设计？简单来说，如果当前递归过程的处理参数符合要求，则执行相关赋值或其它操作，然后转入下一次递归，如果下一次递归不能找到出口，则把之前相关赋值或其它操作重置为初始状态。 0-1背包问题中很明显的一步设计，就是递归函数return后，进行回退操作，即将上一次加上的参数减去。 n后问题pos[N] 来表示皇后的位置，pos[i] 123456789101112131415161718```cvoid backTrackRec(int now){ if (now == N) { print(); return; } for (int x = 0; x &lt; N; x++) { pos[now] = x; if (check(now)) { backTrackRec(now + 1); } }} 我们使用 pos 数组来记录位置，已经能保证每个皇后在不同的行上。因此，在 check 函数当中，需要检查新添的皇后是否有同列或者在对角线上（两点斜率为 1 ）的情况。 123456789bool check(int index){ for (int i = 0; i &lt; index; i++) { if (pos[i] == pos[index] || abs(i - index) == abs(pos[i] - pos[index])) return false; } return true;} 回溯法无回退操作，因为每一行均可以选出最优解 背包问题由于有最优选择的问题，所以不满足最优需要回退","link":"/2020/04/01/%E7%AE%97%E6%B3%95%E4%B9%8B%E5%9B%9E%E6%BA%AF%E6%B3%95/"},{"title":"泛型的约束与局限性","text":"由于类型擦除的原因和影响，使用java泛型时有一些限制。 不能用基本类型实例化类型参数不能用类型参数代替基本类型。因此， 没有 Pair&lt;double&gt;, 只有 Pair&lt;Double&gt;。 当然, 其原因是类型擦除。擦除之后， Pair 类含有 Object 类型的域， 而 Object 不能存储 double 值。 运行时类型查询只适用于原始类型虚拟机中的对象总有一个特定的非泛型类型。也就是说，虚拟机中的对象都是非泛型化的类型。因此，所有的类型查询只产生原始类型。 举个例子 1Pair&lt;String&gt; a =new Pair&lt;String&gt;(); 因为类型擦除之后,Pair只剩下原始类型，泛型信息String不存在了。 那么，运行时进行类型查询的时候使用下面的方法是错误的 1if (a instanceof Pair&lt;String&gt;) // Error 实际上仅仅测试 a 是否是任意类型的一个 Pair。试图查询一个对象是否属于某个泛型类型时，倘若使用 instanceof 会得到一个编译器错误， 1if( arrayList instanceof Pair&lt;?&gt;) 再看强制类型转换 1Pair&lt;String&gt; p = (Pair&lt;String&gt;) a; // Warning-can only test that a is a Pair 如果使用强制类型转换会得到一个警告。 同样的道理，getClass 方法总是返回原始类型 1234Pair&lt;String&gt; stringPair = new Pair&lt;String&gt;();Pair&lt;Employee&gt; employeePair = new Pair&lt;Employee&gt;(); if (stringPair.getClass() == employeePair.getClass()) // they are equal //两次调用getClass()都返回Pair.class 不能创建参数化类型的数组不能声明参数化类型的数组。如： 1Pair&lt;String&gt;[] table = new Pair&lt;String&gt;[10]; // Error 这有什么问题呢？ 擦除之后， table 的类型是 Pair[ ]。可以把它转换为Object: 1Object[] objarray = table; 数组会记住它的元素类型， 如果试图存储其他类型的元素， 就会抛出一个 ArrayStoreException 异常： 1objarray[0] = \"Hello\"; // Error component type is Pair 对于泛型而言，擦除降低了这个机制的效率。下面的赋值可以通过数组存储的检测，但仍然会导致类型错误。出于这个原因，不允许创建参数化类型的数组。 1objarray[0] = new Pair&lt;Employee&gt;()； 需要说明的是， 只是不允许创建这些数组， 而声明类型为Pair&lt;String&gt;[]的变量仍是合法的。不过不能用new Pair&lt;String&gt;[10]初始化这个变量。如果需要收集参数化类型对象，只有一种安全而有效的方法:使用 ArrayList:ArrayList&lt;Pair(). Varargs 警告如果向参数个数可变的方法传递一个泛型类型的实例。例如 12345678910public static &lt;T&gt; void addAll(Collections coll, T... ts) { for (t : ts) coll.add(t)； } //应该记得，实际上参数 ts 是一个数组， 包含提供的所有实参。 现在考虑以下调用：Col1ection&lt;Pair&lt;String&gt; table = . . .; Pair&lt;String&gt; pairl = ...; Pair&lt;String&gt; pair2 = ...;addAll(table, pairl, pair2); 为了调用这个方法，Java 虚拟机必须建立一个 Pair&lt;String&gt;数组， 这就违反了上一节中不能有泛型类型数组的规则。不过，对于这种情况，规则有所放松，你只会得到一个警告，而不是错误。 不能实例化类型变量不能实例化泛型类型。如， 1first = new T(); //ERROR 是错误的，类型擦除会使这个操作做成new Object()。 不能建立一个泛型数组。 1234public&lt;T&gt; T[] minMax(T[] a){ T[] mm = new T[2]; //ERROR ... } 类似的，擦除会使这个方法总是构靠一个Object[2]数组。 但是，可以用反射构造泛型对象和数组。 利用反射，调用Array.newInstance: 1234567publicstatic &lt;T extends Comparable&gt; T[]minmax(T[] a) { T[] mm == (T[])Array.newInstance(a.getClass().getComponentType(),2); ... // 以替换掉以下代码 // Obeject[] mm = new Object[2]; // return (T[]) mm; } 泛型类的静态上下文中类型变量无效泛型类中的静态方法和静态变量不可以使用泛型类所声明的泛型类型参数。 举例说明： 123456public class Test2&lt;T&gt; { public static T one; //编译错误 public static T show(T one){ //编译错误 return null; } } 因为泛型类中的泛型参数的实例化是在定义对象的时候指定的，而静态变量和静态方法不需要使用对象来调用。对象都没有创建，如何确定这个泛型参数是何种类型，所以当然是错误的。 但是要注意区分下面的一种情况： 12345public class Test2&lt;T&gt; { public static &lt;T &gt;T show(T one){//这是正确的 return null; } } 因为这是一个泛型方法，在泛型方法中使用的T是自己在方法中定义的T，而不是泛型类中的T。 不能抛出或捕获泛型类的实例1、不能抛出也不能捕获泛型类的对象。事实上，泛型类扩展Throwable都不合法。例如：下面的定义将不会通过编译： 1public class Problem&lt;T&gt; extends Exception{......} //error 为什么不能扩展Throwable，因为异常都是在运行时捕获和抛出的，而在编译的时候，泛型信息全都会被擦除掉，那么，假设上面的编译可行，那么，在看下面的定义： 1234567try{ }catch(Problem&lt;Integer&gt; e1){ 。。 }catch(Problem&lt;Number&gt; e2){ ... } 类型信息被擦除后，那么两个地方的catch都变为原始类型Object，那么也就是说，这两个地方的catch变的一模一样,就相当于下面的这样 1234567try{ }catch(Problem&lt;Object&gt; e1){ 。。 }catch(Problem&lt;Object&gt; e2){ ... } 这个当然就是不行的。就好比，catch两个一模一样的普通异常，不能通过编译一样： 1234567try{ }catch(Exception e1){ 。。 }catch(Exception e2){//编译错误 ... } 2、不能在catch子句中使用泛型变量 1234567public static &lt;T extends Throwable&gt; void doWork(Class&lt;T&gt; t){ try{ ... }catch(T e){ //编译错误 ... } } 因为泛型信息在编译的时候已经变味原始类型，也就是说上面的T会变为限定类型Throwable，那么如果可以在catch子句中使用泛型变量，那么，下面的定义呢： 123456789public static &lt;T extends Throwable&gt; void doWork(Class&lt;T&gt; t){ try{ ... }catch(T e){ //编译错误 ... }catch(IndexOutOfBounds e){ } } 根据异常捕获的原则，一定是子类在前面，父类在后面，那么上面就违背了这个原则。即使你在使用该静态方法的使用T是 ArrayIndexOutofBounds，在编译之后还是会变成Throwable，ArrayIndexOutofBounds是 IndexOutofBounds的子类，违背了异常捕获的原则。所以java为了避免这样的情况，禁止在catch子句中使用泛型变量。 但是在异常声明中可以使用类型变量。即可以在throws子句声明中正常使用类型变量，下面方法是合法的。 12345678public static&lt;T extends Throwable&gt; void doWork(T t) throws T{ try{ ... }catch(Throwable realCause){ t.initCause(realCause); throw t; }} 上面的这样使用是没问题的。 注意擦除后的冲突1、当泛型类型被擦除后，创建条件不能产生冲突。如果在Pair类中添加下面的equals方法： 12345class Pair&lt;T&gt; { public boolean equals(T value) { return null; } } 考虑一个Pair。从概念上，它有两个equals方法： 12boolean equals(String); //在Pair&lt;T&gt;中定义boolean equals(Object); //从object中继承 但是，这只是一种错觉。实际上，擦除后方法 1boolean equals(T) 1变成了方法 boolean equals(Object) 这与Object.equals方法是冲突的！当然，补救的办法是重新命名引发错误的方法。 2、泛型规范说明提及另一个原则“要支持擦除的转换，需要强行制一个类或者类型变量不能同时成为两个接口的子类，而这两个子类是同一接口的不同参数化。” 下面的代码是非法的： 123class Calendar implements Comparable&lt;Calendar&gt;{ ... } class GregorianCalendar extends Calendar implements Comparable&lt;GregorianCalendar&gt;{...} //ERROR GregorianCalendar会实现Comparable和Compable，这是同一个接口的不同参数化实现。 这一限制与类型擦除的关系并不很明确。非泛型版本： 123class Calendar implements Comparable{ ... } class GregorianCalendar extends Calendar implements Comparable{...} //ERROR 是合法的。","link":"/2020/05/06/%E6%B3%9B%E5%9E%8B%E7%9A%84%E7%BA%A6%E6%9D%9F%E4%B8%8E%E5%B1%80%E9%99%90%E6%80%A7/"},{"title":"泛型类型的继承规则和通配符类型的使用","text":"Employee类是Manager类的超类，但是需要注意的是Pair和Pair并没有超类和子类的关系。那么用Pair变量去引用Pair对象就是不合法的。 泛型类型的继承规则下面代码是不合法的 12Manager[] topHonchos = ...;Pair&lt;Employee&gt; result = ArrayAlg.minmax(topHonchos);//ERROR minmax 方法返回 Pair，而不是Pair，并且这样的赋值是不合法的。无论S和T什么关系,Pair&lt;S&gt;和Pair&lt;T&gt;并没有什么关系。这样做对于类型安全非常必要。 假设允许将 Pair 转换为 Pair。考虑下面代码： 123Pair&lt;Manager&gt; managerBuddies = new Pair&lt;&gt;(ceo, cfo);//一个Pair对象 包含ceo cfo两个高级职员Pair&lt;Employee&gt; employeeBuddies = managerBuddies;//error，如果我们假设这一句能正常编译employeeBuddies.setFirst(lowlyEmployee); 最后一句肯定是合法的，如果允许第二句成功引用，这里就把Pair类型的managerBuddies的first域变成了Employee类型了，显然是有问题的，所以通过这样的反证，我们也明白了Java不允许这样的赋值。 但是泛型和数组不同，一个Employee[]数组去引用一个Manager[]数组是完全合法的。 永远可以将参数化类型转换为一个原始类型。例如，Pair 是原始类型 Pair 的一个子类型。在与遗留代码衔接时，这个转换非常必要。 12Pair&lt;Manager&gt; managerBuddies = new Pair&lt;&gt;(ceo, cfo);Pair rawBuddies = managerBuddies; //It's OK. 遗憾的是，这样的引用是合法的，但是通过rawBuddies去调用setFirst方法依旧是编译错误，当使用getFirst获得对象赋值给Manager变量时，会抛出ClassCastException，就是Pair也并不是Pair的超类，他只是允许了引用而已。 最后， 泛型类可以扩展或实现其他的泛型类。就这一点而言，与普通的类没有什么区别。例如，ArrayList 类实现 List接口。这意味着， 一个 ArrayList 可以被转换为一个 List。但是，如前面所见，一个 ArrayList 不是一个 ArrayList 或 List 通配符类型泛型中使用通配符有两种形式：子类型限定&lt;? extends xxx&gt;和超类型限定&lt;? super xxx&gt;。还有一种无限定通配符 &lt;?&gt; 。 子类型限定通配符类型中，允许类型参数变化： 1Pair&lt;? extends Employee&gt; 表示任何泛型Pair类型，它的类型参数是Employee的子类，如Pair。 看这个例子： 12345public static void printBuddies(Pair&lt;Employee&gt; p){ Employee first = p.getFirst(); Employee second = p.getSecond(); System.out.println(first.getName() + \" and \" + second.getName() + \" are buddies.\" } 之前谈到过的泛型继承规则中，出于安全考虑，把Pair传给这个方法是不合法的，而通配符就是Java设计者用来解决泛型的一些缺陷而设计的方案。 只要更改成这样： 1public static void printBuddies(Pair&lt;? extends Employee&gt; p) corejava上说，Pair是Pair&lt;? extends Employee&gt;的子类型，从这个传递参数来看，通过Pair&lt;? extends Employee&gt;引用Pair是合法的，使用通配符会通过这个引用”破坏”Pair吗？和Pair调用相关方法会编译错误类似的，通配符引用去调用setFirst(lowlyEmployee)也会编译错误： 123Pair&lt;Manager&gt; managerBuddies = new Pair&lt;&gt;(ceo, cto);Pair&lt;? extends Employee&gt; wiledcardBuddies = managerBuddies;//it's okwiledcardBuddies.setFirst(lowlyEmployee);//compile-time error 调用setFirst会有一个类型错误，为什么呢？类型Pair&lt;? extends Employee&gt;的方法替换后里是这样的(并不是真正的Java语法，仅作分析)： ` ? extends Employee getFirst() void setFirst(? extends Employee) 编译器只知道setFirst需要某个Employee类的子类，然而并不知道具体类型，它会拒绝接受传递过来的任何特定的类型，毕竟？不能用来匹配。连Employee类也不放过。 而getFirst不存在这样的问题，getFirst的返回值是Employee类型的子类，即便由于？的问题，不知道具体类型，但是它总是可以被赋值给一个Employee引用的，它是有”上界”的。 简而言之，一个是安全的访问器方法，另一个是不安全的更改器方法。上述的通配符类型可以使用返回值，可以引用子类型的对象，但是为更改器方法提供参数则是不安全的。这就是引人有限定的通配符的关键之处。现在已经有办法区分安全的访问器方法和不安全的更改器方法了。 超类型限定通配符限定与类型变量限定有一定的类似之处，而通配符还可以指定一个超类型限定（supertype bound）: 12? super Manager这个通配符限制为Manager的超类型，比较欣慰的是，这块的super和我们之前理解的super语义上是一致的，不像extends。。。 我们用和上一节同样的分析方法来看一下访问器和更改器的安全性问题： 12? super Manager getFirst()void setFirst(? super Manager) 先看第一个返回的，由于返回的类型是Manager的超类，所以Object类呀Employee呀都有可能，那么你用什么类型的引用去接收这个返回值？编译器无法知道getFirst返回值的真正类型，只有通过Object引用去接收才是合法的。 再看第二个setFirst参数中的通配符，编译器同样无法知道参数的具体类型，但是这个类型是有“下界”的，就是说传来的参数只要是Manager类或者它的子类，那么这样的传参都是可以接受的，编译器由于知道下界，这些传参就是安全的。 总结： 通配符Pair&lt;? extends Employee&gt;和 Pair&lt;? super Employee&gt;表示某种特定类型 ，但是并不关心这个实际的类型到底是什么，反正是Employee的子类型或超类型，Employee是上界或下界。那么对这样的一个 Pair 我们能做什么呢？其实如果我们不知道这个 Pair 到底持有什么类型，用Pair&lt;? extends Employee&gt;变量去引用Pair&lt;Employee的某个子类&gt;是合法的，用Pair&lt;? super Employee&gt;变量去引用Pair&lt;Employee的某个超类&gt;是合法的。在使用方法时需要注意一些点，下面以setFirst和getFirst为例讲解。 对于setFirst方法参数类型，如果是Pair&lt;? extends Employee&gt;，我们只清楚方法参数的上界是什么，那它的下面有各种可能，怎么可能用setFirst方法安全的添加一个对象呢？相反，由于Pair&lt;? super Employee&gt;有下界，我们不用管它到底是什么，只要传递过来的参数是Employee的超类就可以了，这是安全的。 同理对于getFirst方法返回类型，如果是Pair&lt;? super Employee&gt;,我们只知道它的下界，它的上面依旧是可能性无限，除了Object外，怎么可能安全的用Employee的某个特定的超类变量去接受这个getFirst返回值呢？相反，由于Pair&lt;? extends Employee&gt;有上界，我们很清楚只要使用Employee类型或其超类变量就可以引用这个返回值。 我们也常常把前面两节讲到的通配符分别称为上边界限定通配符和下边界限定通配符，分别可以安全的读泛型对象读取（如接受返回值）和向泛型对象写入（如传递参数）。 1234567891011public static void minmaxBonus(Manager[] a, Pair&lt;? super Manager&gt; result){ if(a.length == 0) return; Manager min = a[0]; Manager max = a[0]; for(int i = 0; i &lt; a.length; i++){ if(min.getBonus() &gt; a[i].getBonus()) min = a[i]; if(max.getBonus() &lt; a[i].getBonus()) max = a[i]; } result.setFirst(min); result.setSecond(max);} 这是一个示例。想把奖金最高和最低的经理放在一个Pair中，第二个通配符类型的参数可以接受合理的Pair，如Pair&lt;Employee&gt; ,Pair&lt;Object&gt;，Pair&lt;Manager&gt;等。 有上界下界限定的通配符，那么也必然有无界通配符。 无限定通配符无限定通配符是指没有extends和super而只有？的通配符。例如Pair，这和原始的Pair类型是不一样的。我们还是用上面一样的分析方法，看一下Pair中有哪些方法： 12? getFirst()void setFirst(?) 没有上界也没有下界，我们唯一能确定的就是第一个getFirst方法返回的可以赋给一个Object类型的变量，而setFirst方法干脆就不能以任何形式调用。 但是可以调用setFirst(null),但好像没有什么意义。。 这中通配符类型很”脆弱”，为什么要有这种类型呢？corejava解释它对于很多简单的操作非常有用，如这个方法用来测试一个Pair是否包含一个null引用，它不需要实际的类型： 123public static boolean hasNulls(Pair&lt;?&gt; p){ return p.getFirst() == null || p.getSecond() == null;} 这样就可以完成检测null。当然也可以使用泛型方法： 1public static &lt;T&gt; boolean hasNulls(Pair&lt;T&gt; p)","link":"/2020/05/07/%E6%B3%9B%E5%9E%8B%E7%B1%BB%E5%9E%8B%E7%9A%84%E7%BB%A7%E6%89%BF%E8%A7%84%E5%88%99%E5%92%8C%E9%80%9A%E9%85%8D%E7%AC%A6%E7%B1%BB%E5%9E%8B%E7%9A%84%E4%BD%BF%E7%94%A8/"},{"title":"网络层之控制平面","text":"运输层依赖于网络层的主机到主机的通信服务。然而运输层工作时不具备任何有关网络层实际实现这种服务。由于在网络中的每一台主机和路由器中都有一个网络层部分，网络层协议是协议栈中最复杂，最难实现的部分。将网络层分解为两个相互作用的部分—数据平面和控制平面，便于整体把握网络层的功能。 网络层：控制平面控制平面功能控制数据报沿着从源主机到目的主机的端到端路径中路由器之间的路由方式，而且控制网络层组件和服务如何配置和管理。主要有以下方面： 路由选择算法 OSPF和BGP路由选择协议 软件定义网络—SDN控制器 概述 路由选择算法是路由选择协议OSPF和BGP的基础； OSPF是运行于单一ISP的网络中的路由选择协议； BGP是一种在因特网中用于互联所有网络（ISP）的路由选择算法，即因特网的粘合剂；另外，我们看到了转发表和流表是链接网络层的数据平面和控制平面的首要元素。那么转发表和流表是如何计算、维护和安装的？ 每路由器控制。 逻辑集中式控制。 路由选择算法链路状态路由选择算法该算法必须知道网络中每条链路的开销，以所有节点之间的连通性及所有链路的开销为输入。像这种具有全局状态信息的算法常被称作链路状态（Link State，LS）算法 实践中的具体实现即是Dijkstra算法—计算从某节点（源节点u）到网络中所有其他节点的最低开销路径（最短路径）。 存在的问题：若网络拓扑比较复杂（更接近现实），那么链路开销是非对称的，即同一条链路来去开销不同，于是拥塞敏感的路由选择会产生“震荡”。解决方法： 强制链路开销不依赖于所承载的流量，该方法不可接受因为违背路由选择的初衷。 另一种就是确保并非所有的路由器都同时运行LS算法，由于路由器之间存在“自同步”现象，则用随机时间发送通告的方法完成时间随机化。 距离向量路由选择算法距离向量（Distance-Vector, DV）算法是一种迭代的、异步的和分布式的算法，而LS算法是一种使用全局信息的算法。节点具有的唯一信息是它到直接相连邻居的链路开销和它从这些邻居接收到的信息。 简单描述节点执行DV算法过程—从邻居接受更新距离向量、重新计算路由选择表项和通知邻居到目的地的最低开销路径的开销已经变化，一直重复直到无更新报文发送，算法进入静止状态。算法停留在静止状态，直到一条链路开销发生改变。 实践中许多类似DV的算法被用于多种路由选择协议中，包括因特网的RIP和BGP。 下面看该算法存在的问题： 链路开销改变与链路故障 当一个链路开销发生变化，那么相邻节点根据算法更新距离向量并通知邻居节点。那么开销减少的“好消息”通过网络会迅速传播，“坏消息”却传播的很慢（路由环路的出现）。下面是解决方法： 增加毒性逆转 毒性逆转思想：欺骗经过的节点，然而只能解决直接相邻（涉及3个或更多则不行）的邻居节点的环路问题。 LS与DV路由算法的比较 报文复杂度 由LS和DV算法特点，LS每次改变链路开销就必须向所有节点发送新的链路开销，而DV算法仅在两个直接相邻的节点之间发生交换报文。 收敛速度 DV算法收敛较慢，且在收敛时候会遇到路由选择环路，遭遇无穷计数问题。 健壮性 LS算法下，每个节点是分离开来的—自己算自己，提供了一定程度的健壮性。而DV算法中一个不正确的节点计算值会扩散到整个网络！ 总之，两个算法都得到了应用，也各有缺点和优点。 因特网中自治系统内部的路由选择：OSPF讨论实践时，必须考虑实际问题中的模型处理不能简单化处理。实践中有两个问题不得不考虑： 规模 互联网规模巨大，LS算法和DV算法都无法完成如此庞大的任务。必须采取措施减少规模的复杂性。 管理自洽 每个ISP（组织）应当按照自己的愿望运行和管理网络，同时与外部网络连接起来。 以上两个问题，通过将路由器组织进自洽系统（AS）来解决。 其中每个AS由一组通常处在相同管理控制下的路由器组成。 一个ISP中的路由器以及互联它们的链路构成一个AS。某些ISP将它们的网络划分为多个AS。 一个自治系统由其全局唯一的AS号（ASN）所标识。就像IP地址那样。 在相同AS中的路由器都运行相同的路由选择算法并且有彼此的信息。在一个自治系统内运行的路由选择算法叫作自治系统内部路由选择协议。 开放最短路优先（OSPF） OSPF是一种链路状态协议，它使用洪泛链路状态信息和Dijkstra最低开销路径算法。 路由器向自治系统内所有其他路由器广播路由选择信息，且是周期性的。广泛用于AS内部路由选择。 ISP之间的路由选择：BGP现在思考一个问题，AS内部用OSPF协议，那么AS之间如何进行路由？我们需要一个自治系统间路由选择协议。所有的AS运行相同的AS间路由选择协议，称为边界网关协议（BGP）。BGP可能是最重要的因特网协议（唯一的竞争者是IP协议）—正是这个协议将因特网中数以千计的ISP粘合起来。BGP是一种分布式和异步的协议—与距离向量路由选择协议一脉相承。 BGP的作用在BGP中，分组并不是路由到一个特定的目的地址，相反是路由到CIDR化的前缀, 其中每个前缀表示一个子网或一个子网的集合。 作为一种AS间的路由选择协议，BGP为每台路由器提供了一种完成以下任务的手段: 从邻居AS获得前缀的可达性信息。 确定到该前缀的“最好的”路由。 通告BGP路由信息概念：网关路由器和内部路由器，BGP连接，eBGP连接和iBGP连接。 为了传播可达性信息，使用了 iBGP和eBGP会话。简单来说，一个eBGP会话向相邻AS系统报告自己知道某个前缀x。接收到该报文的AS系统通过iBGP会话向自己的AS系统中所有路由器报告前缀x的信息。即边界用eBGP，内部用iBGP。 下面讨论多条不同的路径问题，每条通过了不同的AS序列。 确定最好的路由用BGP术语来说，前缀及其属性称为路由。BGP属性：AS-PATH和NEXT-HOP。 BGP路由器使用AS-PATH属性来检测和防止通告环路。NEXT-HOP是AS-PATH起始的路由器接口的IP地址。每条BGP路由包含3个组件：NEXT- HOP； ASPATH；目的前缀。NEXT-HOP有一个重要特质：NEXT- HOP属性不属于ASN的某路由器的IP地址；然而，包含该IP地址的子网直接连接到ASN。 下面讨论具体的BGP路由选择算法： 热土豆路由选择。 使用热土豆路由选择，（从所有可能的路由中）选择的路由到开始该路由的NEXT-HOP路由器具有最小开销。 对于路由器,尽可能快地将分组送出其AS （更明确地说，用可能的最低开销），而不担心其AS外部到目的地的余下部分的开销。就“热土豆路由选择”名称而言，分组被类比为烫手的热土豆。因为它烫手，你要尽可能快地将它传给另一个人（另一个AS）。热土豆路由选择因而是自私的算法，即它试图减小在它自己AS中的开销，而忽略在其AS之外的端到端开销的其他部分。 路由器选择算法。 在实践中，BGP使用了一种比热土豆路由选择更为复杂但却结合了其特点的算法。如果到相同的前缀有两条或多条路由，则顺序地调用消除规则直到余下一条路由。 我们看到使用路由选择算法，BGP不再是一种自私的算法，即它先查找具有短AS路径的路由（因而很可能减小端到端时延）。 IP任播BGP还常被用于实现IP任播（anycast）服务，该服务通常用于DNS中。IP任播被DNS系统广泛用于将DNS请求指向最近的根DNS服务器。 SDN控制平面网络管理和SNMP","link":"/2020/04/06/%E7%BD%91%E7%BB%9C%E5%B1%82%E4%B9%8B%E6%8E%A7%E5%88%B6%E5%B9%B3%E9%9D%A2/"},{"title":"网络层之数据平面","text":"简单来说，控制平面控制路由器如何转发，那么数据平面就是每台路由器的功能。数据平面功能决定到达路由器输入链路之一的数据报（即网络层的分组）如何转发到该路由器的输出链路之一。每台路由器的数据平面的主要作用是从其输入链路向其输出链路转发数据报。 主要有以下方面： 传统的IP转发（基于数据报的目的地址） 通用的转发 IPv4和IPv6协议及其寻址 网络层之数据平面","link":"/2020/04/07/%E7%BD%91%E7%BB%9C%E5%B1%82%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%B9%B3%E9%9D%A2/"},{"title":"计算机组成原理之存储器","text":"简单对存储器做一个总结。主要是主存和Cache，以及了解存储器的体系结构。本文不包括辅助存储器，不包括对《深入理解计算机系统》的总结，但包括部分内容。 存储器的体系结构概述主要问题： 存储器可分为哪些类型？ 现代存储器的层次结构，为什么要分层？ 对2的回答，在计算机存储体系中，就是存储速度越快，价格就会越贵。因为价格的限制，我们在存储器中，就得有个恰当的搭配，以达到价格与性能的平衡。在前面那些大神的不断努力之后，弄出了很多种材料，不同的存储器，最后，得到了下面这张图。 对1的回答，存储器的分类由不同的方式分为 按存储介质分类 半导体存储器 TTL，MOS 磁表面存储器 磁头，载磁体 磁芯存储器 硬磁材料，环状元件 光盘存储器 激光，磁光材料 按存取方式分类 存取时间与物理地址无关（随机访问） 随机存储器 在程序的执行过程中 可读可写 只读存储器 在程序的执行过程中 只读 存取时间与物理地址有关（串行访问） 顺序存取存储器 磁带 直接存取存储器 磁盘 按在计算机中的作用分类 注意： Flash Memory 半导体存储器，比主存慢，比磁盘快。便携式存储器（U盘），还可以作为计算机硬盘 Flash Memory可以作为主存与辅存之间的缓存，ssd核心材料就是Flash Memory 高速缓冲存储器（Cache）即静态RAM，比主存快 存储器的层次结构存储器三个主要特性的关系 寄存器不仅在CPU中，IO中也有；部分缓存被集成到CPU中 一些寄存器对程序员是透明的，程序员无法操作；另一些是提供给程序原操作的寄存器，称为体系结构寄存器。 寄存器容量最小，速度最快；越向下容量越大。单一的存储器都无法满足用户对高速度，大容量，低价格的需求； 层次结构形成存储体系 存储体系：把两种或两种以上的存储器用软件或硬件或软硬件结合，连接成整体。从程序员角度看，有高速度，大容量。该存储体系是透明的。由软硬件自动完成程序或数据的移动。 缓存-主存层次和主存-辅存层次 主存的容量有限，无法完全放下程序数据或资料，需要辅存。程序的运行在主存，需要将数据从辅存传入主存。即2个存储层次。 在程序员看来，这个层次结构是透明的，即既有主存的快速度，又有辅存的大容量 CPU和主存的发展速度存在“剪刀差”，引入缓存（cache）解决CPU速度快而主存速度慢的问题。缓存中保存有主存的副本，CPU可以直接从缓存中获得数据。拓展—-程序的局部性原理 缓存-主存层次：硬件连接成整体。透明的。主要解决速度问题。用主存储器的地址（实地址）-&gt;物理地址 主存-辅存层次：软硬件连接成整体。透明的。主要解决容量问题。虚地址（逻辑地址）-&gt;由0开始的逻辑地址，程序运行由软件转换成内存单元中的物理地址。 主存储器概述主存的基本组成 MAR（主存地址寄存器）保存了我们要访问的存储单元的地址。必须经过译码器的译码以后才能访问存储体中指定的存储单元。 MDR（主存数据寄存器）保存了我们要读出或写入的数据。通过读写控制电路控制。如果是写入，数据经过读写电路写入MAR指定的存储单元 中；如果是读出，存储单元中数据经过读写电路送到MDR。 控制电路控制数据方向 主存与CPU之间的联系 CPU和主存之间的联系分为三类：数据总线，地址总线和控制总线。 在CPU和主存之间就通过这三种类型的信号连接 数据总线完成了CPU和主存之间的数据传输，数据总线直接连接在MDR上，是双向的，可以读出和写入。 地址总线连接在MAR寄存器和主存的地址总线之间，给出了要访问的内存单元的地址，它是单向的，从CPU送到主存的。 控制信号也都是单向的，从CPU送到主存 主存中存储单元地址的分配 24根地址线，有2^24个地址，至于每个地址代表的容量，要看数据线的要求，在题中，每个地址表示一个字节。所以数据的容量就是 2^24*1字节=16M字节。根据字对字节不同的换算，求后两题。 这边的M不是MB是兆（单位M），2^20=1024*1024≈10^6，10^6为1兆。即16Mb 字长16位，则1个字2个字节；字节范围是16M，则16M/2=8M每个字（8MW）；同理，字长32位，1个字4个字节；字节范围16M，则16M/4=4MW 主存的技术指标 存储容量 主存中存放字节的总数 存储速度 存取时间 存储器的 访问时间 ​ （读出时间 写入时间） 存取周期 连续两次独立的存储器操作 （读或写）所需的 最小间隔时间 一般存取周期长于存取时间，因为存取周期=找地址时间加复原时间。 存储器的带宽 位/秒 半导体存储芯片简介半导体存储芯片的基本结构 基本结构：存储矩阵，译码驱动和读写电路。 还有接口，地址线，数据线，片选线，读/写控制线 地址线（有多少货车）和数据线（每辆货车装多少货物）确定芯片容量（位）。芯片容量其实就是重合法中设计的存储矩阵 片选线，芯片选择线。有两种标识方式，低电平有效 读写控制线，低电平写操作，高电平写操作。 16K和64K均可视为地址线，1和8视为数据线。 如何用1位数据线芯片制造8位数据线芯片？将8个1位芯片串成一组，每一组同时工作即可。在这8个一组的芯片中，取地址线相同表示的数据共同输出成为8位数据。再并联4个此组就满足要求了。 当地址为0-（16K-1）时在第一组；地址为16K-（32K-1）时在第二组；32K-（48K-1）在第3组；48K-64K-1在第4组 半导体存储芯片的译码驱动方式译码驱动方式：给定存储单元地址，如何找到存储单元。方法有二： 线选法 重合法线选法：K位地址码经过译码，得到2K根地址线，每根地址线对应一个存储单元。在线选法中，地址码只需进行一次译码就可选择存储单元，其地址码位数越长，译码器结构越复杂，成本越高，故该寻址方式适合在速度较快、容量较小的存储芯片中使用。 重合法：将线选法中单一的地址译码器分成了行地址译码器和列地址译码器，通过两者互“与”来选中存储单元，大大简化了外部译码线路，主要用于大容量的存储器结构 随机存取存储器（RAM）1. 静态RAM（SRAM）保存0和1的原理是什么？利用 双稳态触发器 基本单元电路的构成是什么？对单元电路如何读出和写入？典型芯片的结构是什么样子的？ A0~A9根地址线，有2^10=1K个地址单元。I/O1-I/O4,有4个数据线，则最终有4位输出结果。则存储容量为1K*4=4K位。 静态RAM芯片是如何进行读出和写入操作？4K=2^12=2^62^6。于是可以设计*6464*的存储矩阵列完成译码驱动。 译码驱动选择重合法 2. 动态RAM（DRAM）保存在电容中以后有机会再来写这个 动态RAM为什么要刷新，刷新方法 利用电容存储电荷保存信息，电容做的非常小，很容易漏电。如果一段时间不对电容刷新，那么会漏电，失去保存的信息。 动态RAM刷新只与行地址有关。每次刷新是刷新一行而不是某个存储单元。在读数据线和写数据线之间加上刷新放大器，每一列都加，则每一行都能被刷新。 假设每一行存取周期是0.5us，最大刷新间隔为2ms，则动态RAM需要在2ms内完成所有行的刷新。128行矩阵集中刷新，需要0.5128=64us。该刷新时间段，CPU和IO只能等待，称为*死区 ** 。 每一行的存取周期为读写时间加刷新时间。每一个存取周期可以刷新一行，128行需要的刷新时间为1281us=128us。刷新间隔为128us。则在2ms内可以完成对每一行15.6次刷新。**刷新时间为 （2ms / 128） \\ (128 * 0.5μs) = 1ms**实际上是过度刷新，动态RAM不需要频繁的刷新。 集中刷新，是直接读了所有的128行同时刷新，CPU或者IO没办法读取 但是分散刷新，除了正在读取和刷新的1行，还有剩下的127行可以在0.5us的读写周期中读写数据 概念：指对每行存储单元的刷新分散到每个存取周期内完成。 将2ms平分到128行中，每行有15.6us，则每行可以在15.6us内（15.6us内的任意时间）完成一次刷新，即可保证2ms内每行都刷新一次。每行单独刷新属于分散刷新，但同时不会过度刷新；在15.6us内可以进行任意的读写操作，属于集中刷新。 3. 动态RAM和静态RAM的比较 DRAM单元电路比较简单，只有一个晶体管和一个电容，集成度高；SRAM单元电路比较复杂，有6个晶体管，集成度低 DRAM行地址和列地址可以分别进行传送，地址线可以减少为原来的一半，引脚少。SRAM需要发挥高速度的优势，行地址和列地址同时传送，引脚多 SRAM有3个晶体管一直在导通电，功耗大 DRAM电容储存，做主存（内存条）；SRAM（CPU和主存之间的缓存） 只读存储器（ROM） 掩模ROM（MROM） PROM（一次性编程） EPROM（多次性编程） EEPROM（多次性编程） Flash Memory（闪速型存储器） *存储器与CPU的连接 存储器容量的扩展位扩展（增加存储字长） 2片2114接相同地址线，则表示对相同的存储单元。接不同的8根数据线，每一根数据线表示1位，则完成输出8位的扩展。 关键点在于把2个芯片当作1个芯片来用，同时进行相同的操作。要保证同时，就是把两个芯片的片选线用相同的信号控制。 字扩展（增加存储字的数量） 2片2114接相同地址线，但需要表示不同的存储单元。接相同的8根数据线，防止2片芯片同时对数据操作而造成8根地址线的冲突，需要A10片选线的电位来控制该操作对哪一个芯片起作用。最终结果，地址若在01K-1则选第一个芯片，若在1K2K-1,则选第二个芯片。通过对地址数的扩展，最终完成对芯片存储字的数量（容量）扩展。 同时扩展（位，字扩展） 计算总存储容量，8*1K*4位=4K*8位，所以总共需要8片1K*4位的存储芯片 分析： 先进行位扩展，将1K*4位芯片扩展为 1K*8位的芯片，则共有4组1K*8位的芯片 再进行字扩展，1K芯片有10根地址线，4K芯片有12根地址线，则多余的两根地址线作为片选线，决定对哪一组芯片进行操作。即A10和A11通过片选译码器控制。 简而言之，位扩展就是对数据线进行扩展；字扩展就是对地址线的扩展。 存储器与CPU的连接 地址线的连接 数据线的连接 读/写命令线的连接 片选线的连接 合理选择存储芯片 其他 时序、负载 存储器的校验略 提高访存速度的措施 采用高速器件 采用层次结构 Caceh-主存 调整主存结构单体多字系统 调整主存结构 ​ 由于CPU速度远远大于主存，于是调整主存结构，实现CPU一次传输可读/写多条指令。实际上增加了存储器的带宽 存在问题：CPU对4个W位寄存器的存取是同时且顺序进行的，导致很多问题。比如指令的跳转导致后3条指令作废；写入一条指令时会同时更改后3条指令。 多体并行系统改进后，有多体并行系统 高位交叉 高位对存储体编号。则4个存储体可以并行工作。即在CPU访存后，存储器工作时，CPU可以再次访问其他地址单元。 但是由于程序运行的原理，会造成CPU对同一个存储体的多次访问，而其他存储体空闲的情况。一核有难，多核围观的情况。高位交叉只适合对容量的扩展。 于是再次改进，有了低位交叉并行系统 低位交叉 特点：分离式方式。 下面来了解一下低位并行系统中，CPU对存储器中数据的存取方式流水线 满足T=4ε时，可以形成CPU到存储器之间的线路是被充满的。 CPU的指令从M0开始控制M0读数据。经过一个ε（一个总线传输周期）后开始控制从M1读数据。则可以连续读取4个字。 低位交叉用于存储器带宽和访问速度的提高。 高性能存储芯片 SDRAM（同步DRAM） CPU无需等待 RDRAM 带Cache的DRAM 在 DRAM 的芯片内集成了一个由SRAM组成的Cache，有利于猝发式读取 高速缓冲存储器概述为什么用Cache避免CPU“空等”现象 程序访问的局部性原理。 时间的局部性：当前正在被使用的指令不久之后可能会重复使用。 空间的局部性：与当前正在被使用的指令相邻的指令不久之后可能会被使用。 Cache的工作原理主存和缓存的编址 主存和cache中块大小相同。M&gt;&gt;C。 CPU中地址分为两部分。块内地址位数决定主存块的大小。比如块大小16字节，且内存编制为字节。则b=4位，能唯一寻到块中16个字节。CPU中地址剩余部分就是主存块号。 同样，cache同主存一样，地址也分为两部分，但cache地址意义不大。同时也不需要真正形成cache的地址。 主存和缓存块大小相同，传输时是块整体传输，所以块内地址完全相同。 cache标记位标记了主存块和cache块的对应关系。如果主存块调用进入cache中，则将主存块号写入标记中。CPU给出一个内存地址，首先要确定该内存块是否在cache中。即将地址中的主存块号和cache中的标记号比较。如果在cache中该标记号存在，则表示主存中的块已经存储在cache中，CPU可以直接调用cache中的该块。 经上述讨论，在主存-cache层次中，是按块进行存储，传送的。 命中与未命中 标记记录保存的就是主存和cache块之间的对应关系。 Cache的命中率命中率与Cache的容量和块长有关。块长太大则cache中整体块数少；快长太小则cache中每块保存的指令较少 ，不得不频繁从主存中拿出块。一般每块可取4~8个字。 Cache-主存系统的效率 该情况是CPU访问cache的同时并行访问主存的效率；如果CPU先访问cache再访问主存那么公式变为e=tc/tc+(1+h)th。 Cache的基本结构 CPU访问主存中的块，需要给出一个地址。这个地址包括块号和块内地址两部分。由于主存和Cache之间是以块为单位传送的，则块内地址可以直接传送给Cache地址中的块内地址。块号送入地址映射变换机构，去判断该块号是否在Cache中命中。如果命中，需要给出当前这个内存块保存在Cache中的哪个块中，形成Cache地址中的块号。 如果没有命中，需要查Cache中是否有空间可以装下主存块。如果有空间，则访问主存，将该块装入Cache中。如果可以装入的空间都是满的，那么启动Cache的替换机构，由Cache的替换机构，根据Cache的替换算法，决定Cache中哪一个块要从Cache中推出，写回到主存或者直接作废，并且把主存中要用到的块写入到Cache中。 地址映射和地址变换机构的作用。映射是一种规则，主存中的块如果要放到Cache中的话，它可以放入哪一个块需要遵守该地址映射规则。地址变换，就是把主存的块号变换成相应的Cache的块号或者把Cache的块号变换成相应的主存的块号。 有些系统中CPU若发送不命中，则可以通过数据总线先把主存块中的数据传输到CPU中。 Cache的读写操作 读操作较写操作简单，因为不用考虑数据的一致性。 一定要解决Cache和主存的一致性 写直达法，缺点是可能会导致不断对同一主存连续的写。如一个求和函数，对和变量不断重写。 写回法，在多核系统中，每个CPU都有自己的Cache，那么会造成数据不一致的情况。且硬件实现更复杂。 Cache的改进 增加Cache的级数。 很多处理器至少有3级的Cache 统一缓存和分立缓存。 冯诺依曼结构把指令和数据以同等的方式保存在存储器中。Cache也是存储器，如果采用冯氏结构，那么即采用统一缓存，指令和数据都保存在同一个Cache中。如果采用哈佛结构，那么就是把指令Cache和数据Cache分开，这与指令执行的控制方式有关，比如是否流水，避免了流水冲突。 Cache-主存的地址映射地址映射就是指，主存中的任意一块，如果要加载到Cache中的话，可以加载到Cache中的哪些块。 直接映射 主存中任意一个给定块只能映射（装载）到指定的Cache块中。 将主存储体划分为若干个Cache存储体大小的区。主存中每个区的块编号都可以从0~2^C-1。那么主存中每个块，必须按编号放入相同的Cache块中。每个区相同的字块映射到相同的Cache块中。 CPU给出的地址，中间c位表示Cache块（按映射方法也就是主存块）的地址。前t位表示Cache块中的标记位。由字块地址和块标记即可判断是否命中。字块内地址的偏移量唯一确定所需要的字节。 问题在于Cache的利用率可能会很低。即Cache在调用的过程中冲突的可能性非常大。 全相联映射 主存中任何一个块可以被放入Cache中任何一个块中。则Cache的利用率高，只要Cache中有空闲块，那么就可以把主存中块调入Cache。 CPU给出一个主存地址，那么需要将主存字块标记和Cache中所有标记做对比来判断是否命中，电路复杂，成本高，速度较慢。 参加的比较位数太长，m=t+c位，比较器的位数比较长。 组相联映射 将Cache中的块分成组。每组中可以包括很多块。把主存储器中块也进行分区，每个区的大小和Cache的组数相同。即Cache中包含了多少组，那么主存储器中每个区就有多少块。 每个区的第0块可以放到第0组的任何一个位置。与直接相联映射相比，即使一个位置被占用，还可以使用同组中另外的块。与全相联映射相比，只需要确定块在主存区中的哪个块，那么块就在Cache中对应的组，再判断标记位即可。 靠近CPU的Cache用直接相联映射，中间的Cache用组相联，最远的Cache考虑利用率，用全相联映射。 替换算法 先进先出（FIFO）算法 近期最少使用（LRU）算法","link":"/2020/03/31/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%B9%8B%E5%AD%98%E5%82%A8%E5%99%A8/"},{"title":"计算机组成原理之CPU","text":"记录对CPU的学习。高级语言编写的程序，必须经过编译程序和汇编程序的编译和汇编以后，变成由机器语言编程的程序，才能够在计算机的硬件上执行。指令系统是计算机系统的软硬件交界面的最重要组成部分。由机器指令构成的机器语言程序，要在计算机硬件上执行，每一条指令都由CPU从内存中取出，分析执行，并进行结果的返回。本篇进一步分析机器语言指令是如何在硬件中执行的。 CPU的结构和功能从CPU的结构和功能入手，进而讨论一条指令在计算机硬件上的执行过程。以及一种提高计算机指令运行的非常重要的方法—指令流水。最后有中断系统。 CPU的结构CPU的功能 先讨论CPU具有什么样的功能，然后讨论什么样的结构能具有相应的功能。CPU首要的功能就是对一条指令进行解释。解释的执行过程包括 控制器的功能 取指令。 CPU将指令从内存单元中取出来。 分析指令。 对指令的操作码部分进行解码，分析指令要完成什么样的功能，是指令集中的哪一条指令。 执行指令， 发出各种操作命令。CPU的控制器发出各种控制命令。由这些命令控制相应的部件去完成指令要求的操作。且这些命令有一定的先后顺序。 控制程序输入及结果的输出。 总线管理。 对总线的控制权和使用权的管理 处理异常情况和特殊请求。 运算器的功能 实现算术运算和逻辑运算归纳CPU的功能，即指令控制，操作控制，时间控制，处理中断，数据加工。CPU的结构框图 CPU通过总线和其它部分进行通信。 控制总线 双向的 数据总线 双向的 地址总线 单向的，都是CPU通往外部的接口 取指令需要的硬件：PC指出了我们要取的指令所在的地址。IR是指令寄存器，从内存中取出的指令，存放在CPU的内部IR寄存器中。从指令控制角度，CPU要有寄存器。 从操作控制和时间控制功能来看，CPU需要控制单元（CU），由控制单元对指令进行译码，之后在给定的时刻给出指定的命令。则CPU需要CU。 从数据加工角度，CPU需要ALU进行数据的运算。另外在运算过程中还需要寄存器保存数据，运算的结果也需要输出到寄存器中。 CPU的中断处理需要中断系统的支持，所以还需要中断系统。 CPU中还有其他的辅助电路，以及CPU中各个部分进行连接的内部的互联机构。 CPU的寄存器不同的CPU，不同的指令集结构，对寄存器的设置要求是不一样的。此为抽象的概括，主要介绍CPU中寄存器的分类。以下2种分类方法 用户可见寄存器/用户不可见寄存器 通用寄存器 存放操作数。可作某种寻址方式所需的专用寄存器。 数据寄存器 存放操作数（满足各种数据类型）。两个急促七年拼接存放双倍字长数据。如乘法操作中，将ACC寄存器和mq寄存器拼接在一起，用于保存两个数据相乘之后的积。 地址寄存器 存放地址，其位数应满足最大的地址范围。用于特殊的寻址方式，如段基值，栈指针。 条件寄存器 存放条件码，可作程序分支的依据。如根据正，负，零，溢出，进位等判断程序下一步分支 。 控制和状态寄存器 控制寄存器 PC–&gt;MAR–&gt;M–&gt;MDR–&gt;IR 若我们要从主存中取出一条指令，我们要从PC开始，PC把指令地址送给MAR（主存地址寄存器），MAR再把它包含的要取的指令的地址传送给M（主存储器），并且控制单元发出读命令，读出的指令放在MDR（主存数据寄存器）中，进一步把它放入IR中。涉及的4个寄存器PC,MAR,MDR,IR是控制CPU操作的，有的是用户可见，有的不可见。可见意味编写程序时可以读到寄存器的值。MAR,MDR,IR是不可见的，PC是用户可见的。 状态寄存器 反映指令执行的情况或者软件硬件的状态。可以用于存放状态码。 PSW寄存器 程序状态字寄存器，用于存放程序状态字。那么什么是程序状态字？在中断或者是子程序调用过程中，为了让程序正确的返回到断点，且返回断电后还能够接着执行给定的程序，那么在中断或者转子程序之前，就要保存程序的运行现场和断点。这些程序的运行现场和断点包括了程序运行的软件信息和硬件信息。这些信息保存在寄存器中。有些表示程序运行状态的寄存器可以通过指令集中的指令进行读或者写，而有些没办法读或者写，因为涉及的状态比较多。如果为每个状态设计一个指令的话，那么指令集将非常庞大。为了完成程序现场和程序断点的保存，将软硬件相关的寄存器集合成一个大的寄存器，这个寄存器就是程序状态字寄存器。程序状态字长度比较长，有些程序状态字长几千位。我们可以利用交换程序状态字的方式，完成程序现场的切换。这使得程序中保存程序或者恢复程序断点的工作变得简单。 控制单元CU和中断系统 CU 控制单元产生全部指令的位操作命令序列。任何一条指令要在CPU上执行，CPU要对指令进行译码，根据指令是什么样的类型，进行什么样的操作，要产生完成这些操作的命令。序列要求不仅仅要产生这些命令，而且保证命令间一定的先后顺序。有两种设计方式： 组合逻辑设计 完全由组合逻辑的硬件实现，即硬连线逻辑。这种方式速度快。比如精简指令计算机通常采用硬连线逻辑。 微程序设计 采用存储逻辑实现。比较简单，适用于复杂功能指令的设计。 中断系统 ALU指令周期控制单元要完成指令解释的全部过程，包括指令从内存单元的取出，分析指令，执行指令，最后写回结果。指令周期作为理解指令解释的基础。 指令周期的基本概念 指令周期，即取出并执行一条指令所需的全部时间（或解释一条指令所需要的全部时间）。完成一条指令包括取指、分析的取指周期，和执行的执行周期。不同的CPU或指令集有不同的分类法。那么我们在此，一个指令周期包括取指阶段和执行阶段。取指阶段完成了把指令从内存中取出送入到CPU中，把操作码送到CU，由CU确定是系统中的哪一条指令。执行阶段包括了取操作数，执行，以及执行结果的返回。 每条指令的指令周期不同 不同的指令，指令周期的长度或者指令包含的机器周期的个数也可能是不一样的。 有的指令只包括取指周期不包括执行周期（NOP空指令） 有的指令周期包括相同时间的取指周期和执行周期。（ADD mem） 有的指令周期取指周期和执行周期长度不一样。（MUL mem） 具有间接寻址的指令周期 指令集中支持多种类型的寻址方式，特别是间址寻址的方式。在寻找操作数的地址的过程中，也需要访问存储器。在执行阶段，如果把所有的取操作数和执行都放在执行周期中，那么执行周期中需要2次访存。第一次访存取操作数地址，第二次访存取操作数。那么执行周期就会比较长。于是专门加一个间址周期。则取值周期取出指令，间址周期取出操作数的地址，执行周期进行相应的运算和结果的保存。 带有中断周期的指令周期 在执行周期结束后，就要确认是否有中断请求，如果有中断请求，需要响应中断，响应中断需要保存程序的断点，形成中断程序的入口地址，硬件中断，这些都在中断周期中进行。 指令周期流程 一条指令至少包括取指周期和执行周期，可能有间址周期和中断周期。完成一条指令如下流程： CPU工作周期的标志 指令周期的不同阶段，控制器需要进行不同的操作，控制器在不同的阶段发出不同的控制命令，同时控制器也需要知道当前指令处于哪个阶段。CPU访存有四种性质 CPU访存方式 指令周期阶段 取 指令 取值周期 取 地址 间址周期 存取 操作数或结果 执行周期 存 程序断点 中断周期 这就是CPU的4个工作周期，我们采用D触发器对CPU4个周期进行标识，以确认一条指令当前处于什么阶段。 指令周期的数据流 取指周期数据流 PC指示了一条指令所在的内存地址。要访问存储器，存储器的地址保存在MAR中,数据保存在MDR中。取回来的指令保存在IR中。所有的操作由CU来控制。取指周期数据流从PC开始，PC知道一条指令所在的内存地址，要将地址传送给存储器，PC先将地址传送给MAR，MAR将地址送到地址总线上，然后地址总线送给存储器，存储器此时得知指令所在地址。取指令即读操作，读命令由CU发出，CU将控制信号送到控制总线上，再由控制总线送到存储器，此时存储器进行读操作，把相应的数据送到数据总线上，再送到MDR，此时一条指令被送入到CPU。最后MDR将指令送入CPU中专门保存指令的IR寄存器中。之后仍要为取下条指令做准备。下条指令的地址保存在PC中，如果没有跳转，则PC+1，由CU控制。 间址周期数据流 当前要执行的指令采用间接寻址方式，则指令需要的操作数的地址保存在指令的地址码部分。取指周期后，该指令存在于IR和MDR中。首先需要取出操作数的地址，即MDR或IR中指令的地址码部分。假设起始操作从MDR中读取地址码开始，MDR将地址码送给MAR，进行内存单元的访问。从存储器中读出来的数据，其实是一个地址，是这条指令需要的操作数所在的内存单元的地址，将这个地址送到MDR中，此时MDR地址码中就保存了我们真正需要的操作数的地址。 执行周期数据流 不同的指令差别非常大。 中断周期数据流 中断周期所做的工作其实有三部分。第一部分是保存断点，第二部分是形成中断程序的入口地址，第三是硬件关中断。首先保存断点在内存中，由CU给出保存在哪个地址。CU把地址给MAR，MAR将地址传送给存储器，CU传送写命令给存储器。断点是中断程序后，要执行的下一条指令地址，而这个地址保存在PC中，于是PC将自己保存的地址传送给MDR,由MDR送给存储器。之后形成中断程序的入口地址，CU给出该地址，直接写入PC中。 指令流水如何提高机器速度 提高访存速度 提高I/O和主机之间的传送速度 提高运算器速度 提高整机处理能力 改进系统结构，开发系统的并行性 系统的并行性 并行的概念 并发：两个或者两个以上事件在同一时间段发生 同时：两个或者两个以上事件在同一时刻发生 时间上相互重叠 并行性的等级 过程级（程序、进程） 粗粒度 软件实现–操作系统 指令级（指令之间）（指令内部） 细粒度 硬件实现 指令流水原理 指令的串行执行 由于指令的串行执行，导致取指令部件和执行指令部件总有一个是处于等待（空闲）状态，利用率不高，速度慢。 指令的二级流水 若取指和执行阶段时间上完全重叠，指令周期减半速度提高1倍,这是理想情况下，而流水线一直处于满负荷状态是很难的。 影响指令流水效率加倍的因素 执行时间＞取指时间 在取指令部件和执行指令部件之间加一个指令部件缓冲区，用于缓存更快的取指令部件取出的指令，执行指令部件空闲后可直接从缓冲区获得指令去执行。 条件转移指令 必须等上条指令执行结束，才能确定下条指令的地址，造成时间损失。可以用分支预测法解决。 指令的六级流水 影响指令流水线性能的因素 结构相关 不同指令争用同一功能部件产生资源冲突 解决办法： 停顿 指令存储器和数据存储器分开–哈弗结构 指令预取技术（缓存，适用于访存周期短的情况） 数据相关 不同指令因重叠操作，可能改变操作数的读/写访问顺序 写后读相关（RAW） 读后写相关（WAR） 写后写相关（WAW） 解决方法： 后推法 采用旁路技术 控制相关 由转移指令引起 指令3结束后才知道跳转到指令15执行，那么前面的指令4，5，6，7的执行均被浪费掉。 流水线性能 吞吐率： 单位时间内流水线所完成指令或者输出结果的数量 设m段的流水线各段时间为Δt。m为一条指令的总长度 最大吞吐率： 一条长度为m的指令完成需要Δt，则Tpmax = 1/Δt 实际吞吐率： 分析连续处理n条指令的吞吐率，注意到m段的指令完成后，每隔Δt，都有一条指令完成，由于还有（n-1）条指令，所以总时间为m·Δt+(n-1)·Δt，共有n条指令 加速比Sp: m段的流水线的速度与等功能的非流水线的速度之比 设流水线各段时间为Δt.完成n条指令在m段流水线上共需T=m·Δt+(n-1)·Δt.完成 n 条指令在等效的非流水线上共需T=mn·Δt. 效率: 流水线中各功能段的利用率 由于流水线有建立时间和排空时间因此各功能段的设备不可能一直处于工作状态. 流水线的多发技术 超标量技术 每个时钟周期内,并发多条独立指令,进入不同的流水线,需要配置多个流水线功能部件.但是不能调整指令的执行顺序,所以需要通过编译优化技术,把可以并行执行的指令搭配起来. 超流水线技术 在一个时钟周期内将一个流水线再次分段(3段),于是一个功能部件能使用多次(3次).一条流水线的结构仍是以前的结构,但是和流水线不同的是,把每个时钟周期分为三份,在每个时间点开始的时候,都可以有一条新的指令进入流水线.这种方式把流水线进一步细分.但是在普通流水线技术中,每个时钟周期或者说流水段之间都有一个锁存器,用来储存上一段的结果给下一个流水段使用,而在这种超流水技术中,流水段之间仍有锁存器,然而更细分的段之间没有锁存器.所以超流水线技术的一个关键技术在于,不同的指令在同一流水段中,如何保证数据互相不影响. 超流水技术一般也不在流水过程中调整指令的执行顺序,也是通过静态的方式即编译的方式来优化.若分成3段,则流水线速度是原来速度的3倍. 超长指令字技术 由编译程序挖掘出指令间潜在的并行性,这是由计算机的执行部件的数量和种类决定的。将多条能并行操作的指令组合成一条具有多个操作码字段的超长指令字（可达几百位）。即进行一次取指，取出一条超长指令，然后对该长指令进行分析，将其内含的多个操作码分别使用相应的功能部件执行，其实就相当于一次取出多条指令，然后同时执行。 流水线结构 指令流水线结构 若流水线不出现断流，则1个时钟周期出现1结果 每段之间必须加上锁存器 运算流水线 比如完成浮点加减运算可以分为对阶，尾数求和，规格化三段 分段原则是每段操作时间尽量一致。 中断系统","link":"/2020/04/15/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86%E4%B9%8BCPU/"},{"title":"运输层可靠数据传输原理","text":"可靠数据传输为上层实体提供的服务抽象是：数据可以通过一条可靠的信道进行传输。借助于可靠信道，传输数据比特就不会受到损坏 （由0变为1,或者相反）或丢失，而且所有数据都是按照其发送顺序进行交付。这恰好就是TCP向调用它的因特网应用所提供的服务模型。 可靠数据传输原理图示说明了我们学习可靠数据传输的框架。 实现这种服务抽象是可靠数据传输协议（reliable data transfer protocol）的责任。由于可靠数据传输协议的下层协议也许是不可靠的，因此这是一项困难的任务。例如，TCP是在不可靠的（IP）端到端网络层之上实现的可靠数据传输协议。就我们的目的而言，我们可将较低层直接视为不可靠的点对点信道。 构造可靠数据传输协议我们现在一步步地研究一系列协议，它们一个比一个更为复杂，最后得到一个完美、可靠的数据传输协议。 .经完全可靠信道的可靠数据传输：rdt1.0 在这个简单的协议中，一个单元数据与一个分组没差别。而且，所有分组是从发送方流向接收方；有了完全可靠的信道，接收端就不需要提供任何反馈信息给发送方，因为不必担心出现差错！注意到我们也已经假定了接收方接收数据的速率能够与发送方发送数据的速率一样快。因此，接收方没有必要请求发送方慢一点！ 经具有比特差错信道的可靠数据传输：rdt2.0 底层信道更为实际的模型是分组中的比特可能受损的模型。这种比特差错通常会出现在网络的物理部件中。还将继续假定所有发送的分组(虽然有些比特可能受损)将按其发送的顺序被接收。 肯定确认(positive knowledgment) 与否定确认(negative acknowledgmenl)。这些控制报文使得接收方可以让发送方知道哪些内容被正确接收，哪些内容接收有误并因此需要重复。在计算机网络环境中，基于这样重传机制的可靠数据传输协议称为自动重传请求 (Automatic Repeat reQuest, ARQ)协议。 重要的是，ARQ协议中还需要另外三种协议功能来处理存在比特差错的情况 差错检测 需要一种机制以使接收方检测到何时出了比特差错。这些技术使接收方可以检测并可能纠正分组中的比特差错。 接收方反馈 为了让发送方了解接收方情况，唯一的途径是接收方发送明确的反馈信息给发送方。理论上表示“肯定确认”(ACK)和否定确认(NAK)只需要一个比特长。 重传 发送方重传有差错的分组。 注意到当发送方处于等待ACK或NAC的状态时，它不能从上层获得更多的数据。即发送方将不会发送一块新数据，除非发送方确信接收方已正确接收当前分组。由于这种行为，rdt2.0这样的协议被称为停等 (stop-and-wait) 协议。 rdt2.0存在一个致命的缺陷：我们没有考虑到ACK或NAK分组受损的可能性。如果一个ACK或NAK分组受损，发送方无法知道接收方是否正确接收了上一块发送的数据。 解决这个新问题的一个简单方法（几乎所有现有的数据传输协议中，包括TCP,都采用了这种方法）是在数据分组中添加一新字段，让发送方对其数据分组编号，即将发送数据分组的序号（sequence number）放在该字段。于是，接收方只需要检查序号即可确定收到的分组是否一次重传。 2.1 协议rdt2.1 是rdt2.0协议的修订版。必须反映出目前（由发送方）正发送的分组或（在接收方）希望接收的分组的序号是0还是1。 协议rdt2. 1使用了从接收方到发送方的肯定确认和否定确认。当接收到失序的分组时，接收方对所接收的分组发送一个肯定确认。 如果收到受损的分组，则接收方将发送一个否定确认。如果不发送NAK,而是对上次正确接收的分组发送一个ACK,我们也能实现与NAK —样的效果。发送方接收到对同一个分组的两个ACK（即接收冗余ACK）后，就知道接收方没有正确接收到跟在被确认两次的分组后面的分组。 2 rdt2.2是在有比特差错信道上实现的一个无NAK的可靠数据传输协议。 rcit2. 1和rdt2.2之间的细微变化在于，接收方此时必须包括由一个ACK报文所确认的分组序号(这可以通过在接收方中，在ACK 0或 ACK1来实现)，发送方此时必须检查接收到的ACK报文中被确认的分组序号(这可通过在发送方，在isACK()中包括参数0或1来实现)。 *经具有比特差错的丢包信道的可靠数据传输:rdt3.0 现在假定除了比特受损外，底层信道还会丢包，这在今天的计算机网络（包括因特网）中并不罕见。协议现在必须处理另外两个关注的问题：怎样检测丢包以及发生丢包后该做些什么。在rdt2.2中已经研发的技术，如使用检验和、序号、ACK分组和重传等，可以解决丢包后如何做。为解决怎样检测丢包的问题，还需增加一种新的协议机制。 有很多可能的方法用于解决丢包问题。这里，我们让发送方负责检测和恢复丢包工作。假定发送方传输一个数据分组，该分组或者接收方对该分组的ACK发生了丢失。在这两种情况下，发送方都收不到应当到来的接收方的响应。如果发送方愿意等待足够长的时间以便确定分组已丢失，则它只需重传该数据分组即可。 但是发送方需要等待多久才能确定已丢失了某些东西呢？很明显发送方至少需要等待这样长的时间：即发送方与接收方之间的一个往返时延（可能会包括在中间路由器的缓冲时延）加上接收方处理一个分组所需的时间。在很多网络中，最坏情况下的最大时延是很难估算的，确定的因素非常少。此外，理想的协议应尽可能快地从丢包中恢复出来；因此实践中采取的方法是发送方明智地选择一个时间值，以判定可能发生了丢包（尽管不能确保）。如果在这个时间内没有收到ACK,则重传该分组。注意到如果一个分组经历了一个特别大的时延，发送方可能会重传该分组，即使该数据分组及其ACK都没有丢失。这就在发送方到接收方的信道中引入了冗余数据分组（duplicate data packet）的可能性。幸运的是，rdt2.2协议已经有足够的功能（即序号）来处理冗余分组情况。 从发送方的观点来看，重传是一种万能灵药。发送方不知道是一个数据分组丢失，还是一个ACK丢失，或者只是该分组或ACK过度延时。在所有这些情况下，动作是同样的：重传。为了实现基于时间的重传机制，需要一个倒计数定时器（countdown timer）,在一个给定的时间量过期后，可中断发送方。因此，发送方需要能做到：①每次发送一个分组（包括第一次分组和重传分组）时，便启动一个定时器。②响应定时器中断（采取适当的动作）。③终止定时器。 因为分组序号在0和1之间交替，因此rdt3.0有时被称为比特交替协议。 现在我们归纳一下数据传输协议的要点。在检验和、序号、定时器、肯定和否定确认分组这些技术中，每种机制都在协议的运行中起到了必不可少的作用。至此，我们得到了一个可靠数据传输协议！ 流水线可靠数据传输协议rdt3.0性能问题的核心在于它是一个停等协议。 停等协议有着非常低的发送方利用率。发送方只有万分之2. 7时间是忙的。这种特殊的性能问题的一个简单解决方法是：不以停等方式运行，允许发送方发送多个分组而无须等待确认。 如果发送方可以在等 待确认之前发送3个报文，其利用率也基本上提高3倍。因为许多从发送方向接收方输送的分组可以被看成是填充到一条流水线中，故这种技术被称为流水线。 流水线技术对可靠数据传输协议可带来如下影响： 必须增加序号范围，因为每个输送中的分组（不计算重传的）必须有一个唯一的序号，而且也许有多个在输送中的未确认报文。 协议的发送方和接收方两端也许不得不缓存多个分组。发送方最低限度应当能缓冲那些已发送但没有确认的分组。接收方也需要缓存那些已正确接收的分组。 所需序号范围和对缓冲的要求取决于数据传输协议如何处理丢失、损坏及延时过大的分组。解决流水线的差错恢复有两种基本方法是: 回退N步(Go- Back- N, GBN)和选择重传(Selective Repeat，SR) 回退N步在回退N步（GBN）协议中，允许发送方发送多个分组（当有多个分组可用时）而不需等待确认，但它也受限于在流水线中未确认的分组数不能超过某个最大允许数N。 那些已被发送但还未被确认的分组的许可序号范围可以被看成是一个在序号范围内长度为N的窗口。随着协议的运行，该窗口在序号空间向前滑动。因此，N常被称为窗口长度 , GBN协议也常被称为滑动窗口协议 （sliding-window protocol） 你也许想知道，我们为什么先要限制这些被发送的、未被确认 的分组的数目为N呢？为什么不允许这些分组为无限制的数目呢？流量控制是对发送方施加限制的原因之一。TCP拥塞控制也是另一个原因。 在实践中，一个分组的序号承载在分组首部的一个固定长度的字段中。如果分组序号字段的比特数是k，则该序号范围是［0, 2^k-1］。在一个有限的序号范围内，所有涉及序号的运算必须使用模2^k运算。（即序号空间可被看作是一个长度为2^k的环，其中序号 2^k-1紧接着序号0。）前面讲过，rdt3.0有一个1比特的序号，序号范围是［0, 1］。TCP 有一个32比特的序号字段，其中的TCP序号是按字节流中的字节进行计数的，而不是按分组计数 GBN发送方必须响应三种类型的事件: 上层的调用。当上层调用rdt_send()时，发送方首先检查发送窗口是否已满，即是否有N个已发送但未被确认的分组。如果窗口未满，则产生一个分组并将其发送, 并相应地更新变量。如果窗口已满，发送方只需将数据返回给上层，隐式地指示上层该窗口已满。然后上层可能会过一会儿再试。在实际实现中，发送方更可能缓存(并不立刻发送)这些数据，或者使用同步机制(如一个信号量或标志)允许上层在仅当窗口不满时才调用rdt_send()。 收到一个ACK。在GBN协议中，对序号为n的分组的确认采取累积确认的方式，表明接收方已正确接收到序号为n的以前且包括n在内的所有分组。稍后讨论GBN接收方一端时，我们将再次研究这个主题 超时事件。协议的名字“回退N步”来源于出现丢失和时延过长分组时发送方的 行为。就像在停等协议中那样，定时器将再次用于恢复数据或确认分组的丢失。 如果出现超时，发送方重传所有已发送但还未被确认过的分组。发送方仅使用一个定时器，它可被当作是最早的已发送但未被确认的分组所使用的定时器。如果收到一个ACK,但仍有已发送但未被确认的分组，则定时器被重新启 动。如果没有已发送但未被确认的分组，停止该定时器。 在GBN协议中，接收方丢弃所有失序分组。尽管丢弃一个正确接收（但失序）的分组有点愚蠢和浪费，但这样做是有理由的。前面讲过，接收方必须按序将数据交付给上层。假定现在期望接收分组n，而分组n+ 1却到了。因为数据必须按序交付，接收方可能缓存（保存）分组n + 1,然后，在它收到并交付分组n后，再n将该分组交付到上层。然而，如果分组n丢失，则该分组及分组n+ 1最终将在发送方根据GBN重传规则而被重传。因此，接收方只需丢弃分组n + 1即可。这种方法的优点是接收缓存简单，即接收方不需要缓存任何失序分组。因此，虽然发送方必须维护窗口的上下边界及nextseqnum在该窗口中的位置，但是接收方需要维护的唯一信息就是下一个按序接收的分组的序号。当然，丢弃一个正确接收的分组的缺点是随后对该分组的重传也许会丢失或出错，因此甚至需要更多的重传。 这里我们注意到，GBN协议中综合了我们将学习TCP可靠数据传输构件时遇到的所有技术。这些技术包括使用序号、累积确认、检验和以及超时/重传操作。 选择重传GBN协议潜在地允许发送方用多个分组“填充流水线”，因此避免了停等协议中所提到的信道利用率问题。然而，GBN本身也有一些情况存在着性能问题。尤其是当窗口长度和带宽时延积都很大时，在流水线中会有很多分组更是如此。单个分组的差错就能够引起GBN重传大量分组，许多分组根本没有必要重传。随着信道差错率的增加, 流水线可能会被这些不必要重传的分组所充斥。 顾名思义，选择重传（SR）协议通过让发送方仅重传那些它怀疑在接收方出错（即丢失或受损）的分组而避免了不必要的重传。这种个别的、按需的重传要求接收方*逐个*地确认正确接收的分组。 再次用窗口长度N来限制流水线中未完成、未被确认的分组数。然而，与GBN不同的是，发送方已经收到了对窗口中某些分组的ACK。 SR接收方将确认一个正确接收的分组而不管其是否按序。 失序的分组将被缓存直到所有丢失分组（即序号更小的分组）皆被收到为止，这时才可以将一批分组按序交付给上层。下图说明岀现丢包时SR的操作。在接收方初始时缓存了分组3、4、5,并在最终收到分组2时，才将它们一并交付给上层。 SR发送方的事件与动作 从上层收到数据。当从上层接收到数据后，SR发送方检査下一个可用于该分组的序号。如果序号位于发送方的窗口内，则将数据打包并发送；否则就像在GBN中一样，要么将数据缓存，要么将其返回给上层以便以后传输。 超时。定时器再次被用来防止丢失分组。然而，现在每个分组必须拥有其自己的逻辑定时器.因为超时发生后只能发送一个分组。 收到ACK。如果收到ACK,倘若该分组序号在窗口内，则SR发送方将那个被确认的分组标记为已接收。 如果该分组的序号等于窗口中序号最小值,则窗口基序号向前移动到具有最小序号的未确认分组处。如果窗口移动了并且有序号落在窗口内的未发送分组，则发送这些分组。 SR接收方的事件与动作 序号在窗口内的分组被正确接收。 情况下，一个选择ACK被回送给发送方。如果该分组以前没收到过，则缓存该分组。如果该分组的序号等于接收窗口的基序号.则该分组以及以前缓存的序号连续的分组交付给上层。 然后，接收窗口按向前移动分组的编号向上交付这些分组。 序号在上一个窗口长度N内分组被正确收到。在此情况下，必须产生一个ACK，即使该分组，是接收方以前已确认过的分组。 其他情况。忽略该分组 注意到第二步很重要，接收方重新确认（而不是忽略）已收到过的那些序号小于当前窗口基序号的分组。你应该理解这种重新确认确实是需要的。例如，如果分组send_base的ACK没有从接收方传播回发送方，则发送方最终将重传分组send.base,即使显然（对我们而不是对发送方来说!）接收方已经收到了该分组。如果接收方不确认该分组，则发送方窗口将永远不能向前滑动！这个例子说明了 SR协议（和很多其他协议一样）的一个重要方面。对于哪些分组已经被正确接收，哪些没有，发送方和接收方并不总是能看到相同的结果。对SR协议而言，这就意味着发送方和接收方的窗口并不总是一致。 下面考虑窗口长度N与序号之间的关系。当我们面对有限序号范围的现实时，发送方和接收方窗口间缺乏同步会产生严重的后果。 现在考虑一下图中接收方的观点，在发送方和接收方之间有一个假想的帘子， 因为接收方不能“看见”发送方采取的动作。接收方所能观察到的是它从信道中收到的以 及它向信道中发出报文序列。就其所关注的而言，图中的两种情况是等同的。没有办法区分是第1个分组的重传还是第5个分组的初次传输。显然，窗口长度比序号空间小 1时协议无法工作。但窗口必须多小呢？对于SR协议 而言，窗口长度必须小于或等于序号空间大小的一半。 至此我们结束了对可靠数据传输协议的讨论。我们已涵盖许多基础知识，并介绍了多种机制，这些机制可一起提供可靠数据传输。总结这些机制。既然我们已经学习了 所有这些运行中的机制，并能看到“全景”，建议再复习一遍本节内容，看看这些机制是怎样逐步被添加进来，以涵盖复杂性渐增的（现实的）连接发送方与接收方的各种信道模型的，或者如何改善协议性能的。 我们通过考虑在底层信道模型中的一个遗留假设来结束对可靠数据传输协议的讨论。前面讲过，我们曾假定分组在发送方与接收方之间的信道中不能被重新排序。这在发送方与接收方由单段物理线路相连的情况下，通常是一个合理的假设。然而，当连接两端的 “信道”是一个网络时，分组重新排序是可能会发生的。分组重新排序的一个表现就是, 一个具有序号或确认号x的分组的旧副x本可能会出现，即使发送方或接收方的窗口中都没有包含x。对于分组重新排序，信道可被看成基本上是在缓存分组，并在将来任意时刻自然地释放出这些分组。由于序号可以被重新使用，那么必须小心，以免出现这样的冗余分组。实际应用中采用的方法是，确保一个序号不被重新使用，直到发送方“确信”任何先前发送的序号为x的分组都不再在网络中为止。通过假定一个分组在网络中的“存活”时 间不会超过某个固定最大时间量来做到这一点。在高速网络的TCP扩展中，最长的分组寿命被假定为大约3分钟。［Sunshine 1978］描述了一种使用序号的方法，它能够完全避免重新排序问题。","link":"/2020/04/02/%E8%BF%90%E8%BE%93%E5%B1%82%E5%8F%AF%E9%9D%A0%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/"},{"title":"面向连接的运输--TCP","text":"既然我们已经学习了可靠数据传输的基本原理，我们就可以转而学习TCP 了。TCP是因特网运输层的面向连接的可靠的运输协议。我们将看到，为了提供可靠数据传输，TCP依赖于前一节所讨论的许多基本原理，其中包括差错检测、重传、累积确认、定时器以及用于序号和确认号的首部字段。 面向连接的运输：TCPTCP连接TCP被称为是面向连接的（connection-oriented）,这是因为在一个应用进程可以开始向另一个应用进程发送数据之前，这两个进程必须先相互“握手”，即它们必须相互发送某些预备报文段，以建立确保数据传输的参数。作为TCP连接建立的一部分，连接的双方都将初始化与TCP连接相关的许多TCP状态变量。 这种TCP “连接”不是一条像在电路交换网络中的端到端TDM或FDM电路。相反, 该“连接”是一条逻辑连接，其共同状态仅保留在两个通信端系统的TCP程序中。前面 讲过，由于TCP协议只在端系统中运行，而不在中间的网络元素（路由器和链路层交换 机）中运行，所以中间的网络元素不会维持TCP连接状态。事实上，中间路由器对TCP完全视而不见，它们看到的是数据报，而不是连接。 TCP是全双工的，应用层数据就可在从进程B流向进程A的同时，也从进程A流向进程B。TCP连接也总是点对点（point-to-point）的，即在单个发送方与单个接收方之间的连接。所谓“多播”，即在一次发送操作中，从一个发送方将数据传送给多个接收方，这种情况对TCP来说是不可能的。对于 TCP而言，两台主机是一对，而3台主机则太多了！ 我们现在来看看TCP连接是怎样建立的。假设运行在某台主机上的一个进程想与另一台主机上的一个进程建立一条连接。发起连接的这个进程被称为客户进程，而另一个进程被称为服务器进程。该客户应用进程首先要通知客户运输层，它想与服务器上的一个进程建立一条连接。客户上的TCP 开始与服务器上的TCP建立一条TCP连接。客户首先发送一个特殊的TCP报文段，服务器用另一个特殊的TCP报文段来响应，最后，客户再用第三个特殊报文段作为响应。前两个报文段不承载“有效载荷”，也就是不包含应用层数据；而第三个报文段可以承载有效载荷。 由于在这两台主机之间发送了 3个报文段，所以这种连接建立过程常被称为三次握手 (three- way handshake) 。 一旦建立起一条TCP连接，两个应用进程之间就可以相互发送数据了。我们考虑一下从客户进程向服务器进程发送数据的情况。 客户进程通过套接字（该进程之门）传递数据流。数据一旦通过该门，它就由客户中运行的TCP控制了。 TCP将这些数据引导到该连接的发送缓存里，发送缓存是发起三次握手期间设置的缓存之一。接下来TCP就会不时从发送缓存里取出一块数据，并将数据传递到网络层。“TCP应该在它方便的时候以报文段的形式发送数据”。TCP可从缓存中取出并放入报文段中的数据数量受限于最大报文段长度 (Maximum Segment Size, MSS）。MSS通常根据最初确定的由本地发送主机发送的最大链路层帧长度（即所谓的最大传输单元（Maximum Transmission Unit, MTU））来设置。设置该MSS要保证一个TCP 报文段（当封装在一个IP数据报中）加上TCP/IP首部长度（通常40字节）将适合单个链路层帧。以太网和PPP链路层协议都具有1500字节的MTU,因此MSS的典型值为1460 字节。已经提出了多种发现路径MTU的方法，并基于路径MTU值设置MSS （路径MTU 是指能在从源到目的地的所有链路上发送的最大链路层帧［RFC 1191］）。注意到MSS是 指在报文段里应用层数据的最大长度，而不是指包括首部的TCP报文段的最大长度。 TCP为每块客户数据配上一个TCP首部，从而形成多个TCP报文段（TCP segment）。 这些报文段被下传给网络层，网络层将其分别封装在网络层IP数据报中。然后这些IP数据报被发送到网络中。当TCP在另一端接收到一个报文段后，该报文段的数据就被放入该 TCP连接的接收缓存中。应用程序从此缓存中读取数据流。该连接的 每一端都有各自的发送缓存和接收缓存。 从以上讨论中我们可以看出，TCP连接的组成包括：一台主机上的缓存、变量和与进程连接的套接字，以及另一台主机上的另一组缓存、变量和与进程连接的套接字。如前面讲过的那样，在这两台主机之间的网络元素(路由器、交换机和中继器)中，没有为该连接分配任何缓存和变量。 TCP报文段结构简要地了解了 TCP连接后，我们研究一下TCP报文段结构。TCP报文段由首部字段和一个数据字段组成。数据字段包含一块应用数据。MSS限制了报文段数据字段的最大长度。当TCP发送一个大文件，例如某Web页面上的一个图像时，TCP通常是将该文件划分成长度为MSS的若干块(最后一块除外，它通常小于MSS)。然而，交互式应用通常传送长度小于MSS的数据块。与 UDP 一样，首部包括源端口号和目的端口号，它被用于多路复用/分解来自或送到上层应用的数据。另外，同UDP一样，TCP 首部也包括检验和字段(checksum field ) 。TCP报文段首部还包含下列字段： 32比特的序号字段(sequence number field )和32比特的确认号字段(acknowl・ edgment number field) 。这些字段被TCP发送方和接收方用来实现可靠数据传输服务。 16比特的接收窗口字段 (receive window field),该字段用于流量控制。该字段用于指示接收方愿意接受的字节数量。 4比特的首部长度字段(header length field),该字段指示了以32比特的字为单位的TCP首部长度。由于TCP选项字段的原因，TCP首部的长度是可变的。(通常, 选项字段为空，所以TCP首部的典型长度是20字节。) 可选与变长的选项字段(options field),该字段用于发送方与接收方协商最大报文 段长度(MSS)时，或在高速网络环境下用作窗口调节因子时使用。首部字段中 还定义了一个时间戳选项。 6比特的标志字段(flag field) 。ACK比特用于指示确认字段中的值是有效的，即 该报文段包括一个对已被成功接收报文段的确认。RST、SYN和FIN比特用于连 接建立和拆除。在明确拥塞通告中使用了 CWR和 ECE比特。当PSH比特被置位时，就指示接收方应立即将数据交给上层。最后，URG比特用来指示报文段里存在着被发送端的上层实体置为“紧急”的数据。紧急数据的最后一个字节由16比特的紧急数据指针字段 (urgent data pointer field)指出。当紧急数据存在并给出指向紧急数据尾指针的时候，TCP必须通知接收端的上层实体。(在实践中，PSH、URG和紧急数据指针并没有使用。为了完整性起见，我们才提到这些字段。) 序号和确认号 TCP报文段首部中两个最重要的字段是序号字段和确认号字段。这两个字段是TCP可靠传输服务的关键部分。但是在讨论这两个字段是如何用于提供可靠数据传输之前，我们首先来解释一下TCP在这两个字段中究竟放置了什么。 TCP把数据看成一个无结构的、有序的字节流。我们从TCP对序号的使用上可以看出这一点，因为序号是建立在传送的字节流之上，而不是建立在传送的报文段的序列之上。 一个报文段的序号(sequence number for a segment)因此是该报文段首字节的字节流编号。 举例来说，假设主机A上的一个进程想通过一条TCP连接向主机B上的一个进程发送一 个数据流。主机A中的TCP将隐式地对数据流中的每一个字节编号。假定数据流由一个 包含500 000字节的文件组成，其MSS为1000字节，数据流的首字节编号是0。该TCP将为该数据流构建500个报文段。给第一个报文段分配序号0,第二个报文段分配序号1000,第三个报文段分配序号2000,以此类推。每一个序号被填入到相应TCP 报文段首部的序号字段中。 现在我们考虑一下确认号。确认号要比序号难处理一些。前面讲过，TCP是全双工的, 因此主机A在向主机B发送数据的同时，也许也接收来自主机B的数据(都是同一条TCP 连接的一部分)。从主机A到达主机B的每个报文段中都有一个序号用于从B流向A的数据。主机 A填充进报文段的确认号是主机A期望从主机B收到的下一字节的序号。假设主机A已收到了来自主机B的编号为0 ~535的所有字节，同时假设它打算发送一个报文段给主机B。主机A等待主机B的数据流中字节536及之后的所有字节。所以主机A就会在它发往主机B的报文段的确认号字段中填上536。 假设主机A已收到一个来自主机B的包含字节0 ~535的报文段，以及另一个包含字节900-1000的报文段。由于某种原因，主机A还没有收到字节536 - 899的报 文段。在这个例子中，主机A为了重新构建主机B的数据流，仍在等待字节536 （和其后的字 节）。因此，A到B的下一个报文段将在确认号字段中包含536。因为TCP只确认该流中至第一个丢失字节为止的字节，所以TCP被称为提供累积确认（cumulalive acknowledgment）。 最后一个例子也会引发一个重要而微妙的问题。主机A在收到第二个报文段（字节 536 -899）之前收到第三个报文段（字节900 ~ 1000）。因此，第三个报文段失序到达。 该微妙的问题是：当主机在一条TCP连接中收到失序报文段时该怎么办？有两个基本的选择：①接收方立即丢弃失序报文段（如前所述，这可以简化接收方的设计）；②接收方保留失序的字节，并等待缺少的字节以填补该间隔。显然，后一种选择对网络带宽而言更为有效，是实践中采用的方法。 我们假设初始序号为0。事实上，一条TCP连接的双方均可随机地选择初始序号。这样做可以减少将那些仍在网络中存在的来自两台主机之间先前已终止的连接的报文段，误认为是后来这两台主机之间新建连接所产生的有效报文段的可能性。 Telnet:序号和确认号的一个学习案例 假设客户和服务器的起始序号分别是42和79，因此，客户发送的第一个报文段的序号为42,服务器发送的第一个报文段的序号为79。前面讲过，确认号就是主机正在等待的数据的下一个字节序 号。在TCP连接建立后但没有发送任何数据之前，该客户等待字节79,而该服务器等待字节42。 在客户最后一份报文发送时，即使没有数据，也有序号存在。 往返时间的估计与超时TCP如同前面3. 4节所讲的rdt协议一样，它采用超时重传机制来处理报文段的丢失问题。尽管这在概念上简单，但是当在如TCP这样的实际协议中实现超时/重传机制时还是会产生许多微妙的问题。也许最明显的一个问题就是超时间隔长度的设置。显然，超时间隔必须大于该连接的往返时间（RTT）,即从一个报文段发出到它被确认的时间。否则会造成不必要的重传。但是这个时间间隔到底应该是多大呢？刚开始时应如何估计往返时间呢？是否应该为所有未确认的报文段各设一个定时器？问题竟然如此之多！ 估计往返时间考虑一下TCP是如何估计发送方与接收方 之间往返时间的。报文段的样本RTT （表示为SampleRTT）就是从某报文段被发岀（即交给IP）到对该报文段的确认被收到之间的时间量。大多数TCP 的实现仅在某个时刻做一次SampleRTT测量，而不是为每个发送的报文段测量一个Samp- leRTT。这就是说，在任意时刻，仅为一个已发送的但目前尚未被确认的报文段估计Samp- leRTT,从而产生一个接近每个RTT的新SampleRTT值。另外，TCP决不为已被重传的报文段计算SampleRTT；它仅为传输一次的报文段测量SampleRTT 。 显然，由于路由器的拥塞和端系统负载的变化，这些报文段的SampleRTT值会随之波动。由于这种波动，任何给定的SampleRTT值也许都是非典型的。因此，为了估计一个典型的RTT,自然要采取某种对SampleRTT取平均的办法。TCP维持一个SampleRTT均值 （称为EstimatedRTT）。一旦获得一个新SampleRTT时，TCP就会根据下列公式来更新Esti- mated RTT: EstimatedRTT = （1 - a） • EstimatedRTT + a • SampleRTT 除 了估算RTT外，测量RTT的变化也是有价值的。定义了 RTT 偏差 DevRTT,用于估算SampleRTT 一般会偏离EstimatedRTT的程度： DevRTT = （1 -β • DevRTT +β • | SampleRTT - EstimatedRTT | 设置和管理重传超时间隔假设已经给出了 EstimatedRTT值和DevRTT值，那么TCP超时间隔应该用什么值呢? 很明显，超时间隔应该大于等于EstimatedRTT,否则，将造成不必要的重传。但是超时间隔也不应该比EstimatedRTT大太多,否则当报文段丢失时，TCP不能很快地重传该报文段，导致数据传输时延大。因此要求将超时间隔设为EstimatedRTT加上一定余量。当 SampleRTT值波动较大时，这个余量应该大些；当波动较小时，这个余量应该小些。因此，DevRTT值应该在这里发挥作用了。在TCP的确定重传超时间隔的方法中，所有这些因素都考虑到了： Timeoutlnterval = EstimatedRTT +4 • DevRTT 推荐的初始Timeoutinterval值为1秒。同时，当出现超时后，Timeoutlnt- erval值将加倍，以免即将被确认的后继报文段过早出现超时。然而，只要收到报文段并更新EstimatedRTT,就使用上述公式再次计算Timeoutinterval 。 TCP实践原则TCP通过使用肯定确认与定时器来提供可靠数据传输。TCP确认正确接收到的数据，而当认为报文段或其确认报文丢失或受损时， TCP会重传这些报文段。 有些版本的TCP还有一个隐式NAK机制（在TCP的快速重传机制下，收到对一个特定报文段的3个冗余ACK就可作为对后面报文段的一个隐式 NAK,从而在超时之前触发对该报文段的重传）。 TCP使用序号以使接收方能识别丢失或重复的报文段。像可靠数据传输协议rdt3.0的情况一样，TCP自己也无法明确地分辨一个报文段或其ACK是丢失了还是受损了，或是时延过长了。在发送方，TCP的响应是相同的：重传有疑问的报文段。 TCP也使用流水线，使得发送方在任意时刻都可以有多个已发出但还未被确认的报 文段存在。我们在前面已经看到，当报文段长度与往返时延之比很小时，流水线可显著地增加一个会话的吞吐量。一个发送方能够具有的未被确认报文段的具体数量是由TCP 的流量控制和拥塞控制机制决定的。 可靠数据传输前面讲过，因特网的网络层服务（IP服务）是不可靠的。1P不保证数据报的交付， 不保证数据报的按序交付，也不保证数据报中数据的完整性。对于IP服务，数据报能够溢出路由器缓存而永远不能到达目的地，数据报也可能是乱序到达，而且数据报中的比特可能损坏（由0变为1或者相反）。由于运输层报文段是被IP数据报携带着在网络中传输的，所以运输层的报文段也会遇到这些问题。 TCP在IP不可靠的尽力而为服务之上创建了一种可靠数据传输服务（reliable data transfer service）。 TCP的可靠数据传输服务确保一个进程从其接收缓存中读出的数据流是无损坏、无间隙、非冗余和按序的数据流；即该字节流与连接的另一方端系统发送出的字节流是完全相同。TCP提供可靠数据传输的方法涉及我们所学的许多原理。 在我们前面研发可靠数据传输技术时，曾假定每一个已发送但未被确认的报文段都与一个定时器相关联，这在概念上是最简单的。虽然这在理论上很好，但定时器的管理却需要相当大的开销。因此，推荐的定时器管理过程仅使用单一的重传定时器，即使有多个已发送但还未被确认的报文段。在本节中描述的TCP协议遵循了这种单一定时器的推荐。 我们将以两个递增的步骤来讨论TCP是如何提供可靠数据传输的。我们先给出一个TCP 发送方的高度简化的描述，该发送方只用超时来恢复报文段的丢失；然后再给出一个更全面的描述，该描述中除了使用超时机制外，还使用冗余确认技术。在接下来的讨论中，我们假定数据仅向一个方向发送，即从主机A到主机B,且主机A在发送一个大文件。 给出一个TCP发送方高度简化的描述。我们看到在TCP发送方有3个与发送和重传有关的主要事件：从上层应用程序接收数据；定时器超时和收到ACK。 一旦第一个主要事件发生，TCP从应用程序接收数据，将数据封装在一个报文段中，并把该报文段交给IP。注意到每一个报文段都包含一个序号，这个序号就是该报文段第一个数据字节的字节流编号。还要注意到如果定时器还没有为某些其他报文段而运行，则当报文段被传给IP时，TCP就启动该定时器。（将定时器想象为与最早的未被确认的报文段相关联是有帮助的。）该定时器的过期间隔是Timeoutinterval,它是由EstimatedRTT和DevRTT计算得出的。 第二个主要事件是超时。TCP通过重传引起超时的报文段来响应超时事件。然后TCP 重启定时器。 TCP发送方必须处理的第三个主要事件是，到达一个来自接收方的确认报文段（ACK） （更确切地说，是一个包含了有效ACK字段值的报文段）。当该事件发生时，TCP将ACK的值y与它的变量SendBase进行比较。TCP状态变量SendBase是最早未被确认的字节的序号。 （因此SendBase - 1是指接收方已正确按序接收到的数据的最后一个字节的序号。）如前面指出的那样，TCP采用累积确认，所以y确认了字节编号在y之前的所有字节都已经收到。如果y &gt; SendBase,则该ACK是在确认一个或多个先前未被确认的报文段。因此发送方更新它的SendBase变量；如果当前有未被确认的报文段，TCP还要重新启动定时器。 123456789101112131415161718192021222324252627/*假设发送方不受TCP流量和拥塞控制的限制，来自上层数据的长度小于MSS,且数据传送只在一个方向进行。*/NextSeqNum=InitialSeqNumber SendBase=InitialSeqNumberloop （永远） { switch （事件） 事件：从上面应用程序接收到数据e 生成具有序号NextSeqNum的TCP报文段 if （定时器当前没有运行） 启动定时器 向IP传递报文段 NextSeqNum=NextSeqNum4-length （data） break; 事件：定时器超时 重传具有最小序号但仍未应答的报文段 启动定时器 break; 事件：收到ACK,具有ACK字段值y if （y &gt; SendBase） { SendBase=y if （当前仍无任何应答报文段） 启动定时器 } break; }/*结束永远循环*/ 一些微妙的情况从以上的描述，我们得到了一个简化的TCP模型。这种高度简化的版本，仍然存在着许多微妙之处。为了较好地感受该协议的工作过程，我们来看几种简单情况。 第一种情况中，超时事件发生，主机A会重传相同的报文段。当然，当主机B收到该重传的报文段时，它将通过序号发现该报文段包含了早已收到的数据。因此，主机B中的TCP将丢弃该重传的报文段中的这些字节。 现在假设在超时之前这两个报文段中没有一个确认报文到达主机A。当超时事件发生时，主机A重传序号92的第一个报文段，并重启定时器。只要第二个报文段的ACK在新的超时发生以前到达，则第二个报文段将不会被重传。 第一个报文段的确认报文在网络丢失，但在超时事件发生之前主机A收到一个确认号为120的确认报文。主机A因而知道主机B已经收到了序号为119及之前的所有字节; 所以主机A不会重传这两个报文段中的任何一个。 超时间隔加倍我们现在讨论一下在大多数TCP实现中比简化版本所做的一些修改。下面我们考虑TCP对超时重传时间的选择。在这种修改中, 每当超时事件发生时，如前所述，TCP重传具有最小序号的还未被确认的报文段。只是每次TCP重传时都会将下一次的超时间隔设为先前值的两倍，而不是用从EstimatedRTT和DevRTT推算出的值。 这种修改提供了一个形式受限的拥塞控制。定时器过期很可能是由网络拥塞引起的，即太多的分组到达源与目的地之间路径上的一台（或多台）路由器的队列中，造成分组丢失或长时间的排队时延。在拥塞的时候，如果源持续重传分组，会使拥塞更加严重。相反，TCP使用更文雅的方式，每个发送方的重传都是经过越来越长的时间间隔后进行的。学习CSMA/CD时，将看到以太网采用了类似的思路。 快速重传下面考虑为什么引入冗余ACK机制。 超时触发重传存在的问题之一是超时周期可能相对较长。当一个报文段丢失时， 这种长超时周期迫使发送方延迟重传丢失的分组，因而增加了端到端时延。发送方通常可在超时事件发生之前通过注意所谓冗余ACK来较好地检测到丢包情况。再利用快速重传从而避免过长超时周期的等待。 冗余ACK 就是再次确认某个报文段的ACK,而发送方先前已经收到对该报文段的确认。要理解发送方对冗余ACK的响应，我们必须首先看一下接收方为什么会发送冗余ACK。 当TCP接收方收到一个具有这样序号的报文段时，即其序号大于下一个所期望的、按序的报文段，它检测到了数据流中的一个间隔，这就是说有报文段丢失。这个间隔可能是由于在网络中报文段丢失或重新排序造成的。因为TCP不使用否定确认，所以接收方不能向发送方发回一个显式的否定确认。相反，它只是对已经接收到的最后一个按序字节数据进行重复确认（即产生一个冗余ACK）即可。 因为发送方经常一个接一个地发送大量的报文段，如果一个报文段丢失，就很可能引起许多一个接一个的冗余ACK。如果TCP发送方接收到对相同数据的3个冗余ACK,它把这当作一种指示，说明跟在这个已被确认过3次的报文段之后的报文段已经丢失。（考虑为什么发送方等待3个冗余ACK,而不是仅仅等待一个冗余 ACK。）一旦收到3个冗余ACK, TCP就执行快速重传（fast retransmit）,即在该报文段的定时器过期之前重传丢失的报文段。对于采用快速重传的TCP,可用下列代码片段代替ACK收到事件。 12345678910111213事件：收到ACK,具有ACK字段值y if （y &gt; SendBase） { SendBase=y if （当前仍无任何应答报文段） 启动定时器 } else {/*对已经确认的报文段的一个冗余ACK*/ 对y收到的冗余ACK数加1 if （对y==3收到的冗余ACK数） /* TCP快速重传*/ 重新发送具有序号y的报文段 } break; 是回退N步还是选择重传考虑下面这个问题来结束有关TCP差错恢复机制的学习：TCP是一个GBN协议还是一个SR协议？前面讲过，TCP确认是累积式的，正确接收但失序的报文段是不会被接收方逐个确认的。因此， TCP发送方仅需维持已发送过但未被确认的字节的最小序号（SendBase ）和下一个要发送的字节的序号 （NextSeqNum）。在这种意义下，TCP看起来更像一个GBN风格的协议。但是TCP和GBN 协议之间有着一些显著的区别。许多TCP实现会将正确接收但失序的报文段缓存起来。 另外考虑一下，当发送方发送的一组报文段1 , 2,…，N,并且所有的报文段都按序无差错地到达接收方时会发生的情况。进一步假设对分组n&lt;N的确认报文丢失，但是其余N-1个确认报文在分别超时以前到达发送端，这时又会发生的情n况。n在该例中，GBN不仅会重传分组n，还会重传n所有后继的分组n，n，n + 1， n+2，…，N。 在另一方面,TCP将重传至多一个报文段，即报文段n。此外，如果对报文段n+ 1的确认报文在报文段n超时之前到达, TCP甚至不会重传报文段n。 除了累积确认，对TCP提岀的一种修改意见是所谓的选择确认(selective acknowledgment),它允许TCP接收方有选择地确认失序报文段，而不是累积地确认最后一个正确接收的有序报文段。当将该机制与选择重传机制结合起来使用时(即跳过重传那些已被接收方选择性地确认过的报文段)，TCP看起来就很像我们通常的SR协议。因此，TCP的差错恢复机制也许最好被分类为GBN协议与SR协议的混合体。 流量控制前面讲过，一条TCP连接的每一侧主机都为该连接设置了接收缓存。当该TCP 连接收到正确、按序的字节后，它就将数据放入接收缓存。相关联的应用进程会从该缓存中读取数据，但不必是数据刚一到达就立即读取。事实上，接收方应用也许正忙于其他任务，甚至要过很长时间后才去读取该数据。如果某应用程序读取数据时相对缓慢，而发送方发送得太多、太快，发送的数据就会很容易地使该连接的接收缓存溢出。 TCP为它的应用程序提供了流量控制服务(flowcontrol service)以消除发送方使接收 方缓存溢出的可能性。流量控制因此是一个速度匹配服务，即发送方的发送速率与接收方应用程序的读取速率相匹配。前面提到过，TCP发送方也可能因为IP网络的拥塞而被遏制；这种形式的发送方的控制被称为拥塞控制(congestion control)。即使流量控制和拥塞控制采取的动作非常相似(对发送方的遏制)，但是它们显然是针对完全不同的原因而采取的措施。现在我们来讨论TCP如何提供流量控制服务的。为了能从整体上看问题，我们在本节都假设TCP是这样实现的，即TCP 接收方丢弃失序的报文段（虽然实际情况并不是）。 TCP通过让发送方维护一个称为接收窗口( receive window)的变量来提供流量控制。 通俗地说，接收窗口用于给发送方一个指示——该接收方还有多少可用的缓存空间。因为TCP是全双工通信，在连接两端的发送方都各自维护一个接收窗口。我们在文件传输的情况下研究接收窗口。假设主机A通过一条TCP连接向主机B发送一个大文件。主机B为该连接分配了一个接收缓存，并用RcvBuffer来表示其大小。主机B上的应用进程不时地从该缓存中读取数据。我们定义以下变量： • LastByteRead：主机B上的应用进程从缓存读出的数据流的最后一个字节的编号。 • LastByteRcvd:从网络中到达的并且已放入主机B接收缓存中的数据流的最后一个 字节的编号。 由于TCP不允许已分配的缓存溢岀，下式必须成立： LastByteRcvd - LastByteRead≤RcvBuffer 接收窗口用rwnd表示，根据缓存可用空间的数量来设置: rwnd = RcvBuffer - [ LastByteRcvd - LastByteRead ] 由于该空间是随着时间变化的，所以rwnd是动态的。 连接是如何使用变量rwnd来提供流量控制服务的呢？主机B通过把当前的rwnd值放入它发给主机A的报文段接收窗口字段中，通知主机A它在该连接的缓存中还有多少可用空间。开始时，主机B设定rwnd = RevBuffer。 主机A轮流跟踪两个变量，LastByteSent和LastByteAcked,。 注意到这两个变量之间的差LastByteSent - LastByteAcked,就是主机A发送到连接中但未被确认的数据量。通过将未确认的数据量控制在值rwnd以内，就可以保证主机A不会使主机B的接收缓存溢出。因此，主机A在该连接的整个生命周期须保证: LastByteSent - LastByteAcked≤rwnd 对于这个方案还存在一个小小的技术问题。假设主机B的接收缓存已经存满，使得rwnd=0。在将rwnd= 0通告给主机A之后，还要假设主机B没有任何数据要发给主机A。此时，考虑会发生什么情况。因为主机B上的应用进程将缓存清空，TCP并不向主机A发送带有rwnd新值的新报文段。（事实上，TCP仅当在它有数据或有确认要发时才会发送报文段给主机A。)这样，主机A不可能知道主机B的接收缓存已经有新的空间了，即主机A被阻塞而不能再发送数据！为了解决这个问题，TCP规范中要求：当主机B的接收窗口为0时，主机A继续发送只有一个字节数据的报文段。这些报文段将会被接收方确认。最终缓存将开始清空，并且确认报文里将包含一个非0的rwnd值。 描述了 TCP的流量控制服务以后，在此要简要地提一下UDP并不提供流量控制, 报文段由于缓存溢出可能在接收方丢失。 TCP连接管理我们更为仔细地观察如何建立和拆除一条TCP连接。它很重要，因为TCP连接的建立会显著地增加人们感受到的时延 （如在Web上冲浪时）。此外，许多常见的网络攻击（包括极为流行的SYN洪泛攻击）利用了 TCP连接管理中的弱点。假设运行在一台主机（客户）上的一个进程想与另一台主机（服务器）上的一个进程建立一条连接。客户应用进程首先通知客户TCP,它想建立一个与服务器上某个进程之间的连接。客户中的TCP会用以下方式与服务器中的TCP建立一条TCP连接： 第一步：客户端的TCP首先向服务器端的TCP发送一个特殊的TCP报文段。该报文段中不包含应用层数据。但是在报文段的首部中的一个标志位 （即SYN比特）被置为1。因此，这个特殊报文段被称为SYN报文段。另外，客户会随机地选择一个初始序号（client_isn）,并将此编号放置于该起始的TCP SYN 报文段的序号字段中。该报文段会被封装在一个IP数据报中，并发送给服务器。 第二步：一旦包含TCP SYN报文段的IP数据报到达服务器主机（假定它的确到达了！）,服务器会从该数据报中提取出TCP SYN报文段，为该TCP连接分配TCP缓存和变量，并向该客户TCP发送允许连接的报文段。（在完成三次握手的第三步之前分配这些缓存和变量，使得TCP易于受到称为SYN洪泛的拒绝服务攻击。）这个允许连接的报文段也不包含应用层数据。但是，在报文段的首部却包含3个重要的信息。 首先，SYN比特被置为1。 其次，该TCP报文段 首部的确认号字段被置为client_isn + 1 。 最后，服务器选择自己的初始序号 （server_isn）,并将其放置到TCP报文段首部的序号字段中。 这个允许连接的报文段实际上表明了：“我收到了你发起建立连接的SYN分组，该分组带有初始序号 client_isn。我同意建立该连接。我自己的初始序号是server_isn。该允许连接的报文段被称为SYNACK报文段（SYNACK segment）。 第三步：在收到SYNACK报文段后，客户也要给该连接分配缓存和变量。客户主机则向服务器发送另外一个报文段；这最后一个报文段对服务器的允许连接的报文段进行了确认（该客户通过将值server_isn + 1放置到TCP报文段首部的确认字段中来完成此项工作）。因为连接已经建立了，所以该SYN比特被置为0。该三次握手的第三个阶段可以在报文段负载中携带客户到服务器的数据。一旦完成这3个步骤，客户和服务器主机就可以相互发送包括数据的报文段了。在以后每一个报文段中，SYN比特都将被置为0。注意到为了创建该连接，在两台主机之间发送了 3个分组，由于这个原因，这种连接创建过程通常被称为3 次握手（three-way handshake）。 天下没有不散的宴席，对于TCP连接也是如此。参与一条TCP连接的两个进程中的任何一个都能终止该连接。当连接结束后，主机中的“资源”（即缓存和变量）将被释放。假设某客户打算关闭连接，客户应用进程发出一个关闭连接命令。这会引起客户TCP向服务器进程发送一个特殊的TCP报文段。这个特殊的报文段让其首部中的一个标志位即FIN比特被设置为1。当服务器接收到该报文段后，就向发送方回送一个确认报文段。然后，服务器发送它自己的终止报文段，其FIN比特被置为1。最后，该客户对这个服务器的终止报文段进行确认。此时，在两台主机上用于该连接的所有资源都被释放了。 注意到为了释放该连接，在两台主机之间发送了4个分组，由于这个原因，这种连接创建过程通常被称为4次挥手。 下面是一个客户的TCP典型状态 假设客户应用程序决定要关闭该连接。（注意到服务器也能选择关闭该连接。）这引起客户TCP发送一个带有FIN比特被置为1的TCP报文段，并进入FIN_WAIT_1状态。当处在FIN_WAIT_1状态时，客户TCP等待一个来自服务器的带有确认的TCP报文段。当它收到该报文段时，客户TCP进入FIN_WAIT_2状态。当处在FIN_WAIT_2状态时，客户等待来自服务器的FIN比特被置为1的另一个报文段；当收到该报文段后，客户TCP对服务器的报文段进行确认，并进入TIME_WAIT状态。假定ACK丢失，TIME_WAIT状态使TCP 客户重传最后的确认报文。在TIME_WAIT状态中所消耗的时间是与具体实现有关的，而典型的值是30秒、1分钟或2分钟。经过等待后，连接就正式关闭，客户端所有资源（包 括端口号）将被释放。 我们上面的讨论假定了客户和服务器都准备通信，即服务器正在监听客户发送其SYN 报文段的端口。我们来考虑当一台主机接收到一个TCP报文段，其端口号或源IP地址与该主机上进行中的套接字都不匹配的情况。例如，假如一台主机接收了具有目的端口 80 的一个TCP SYN分组，但该主机在端口 80不接受连接（即它不在端口 80上运行Web服务器）。则该主机将向源发送一个特殊重置报文段。该TCP报文段将RST标志位置为1。因此，当主机发送一个重置报文段时，它告诉该源“我没有那个报文段的套接字。请不要再发送该报文段了”。当一台主机接收一个UDP分组，它的目的端口与进行中的UDP套接字不匹配，该主机发送一个特殊的ICMP数据报。 拥塞控制原理我们已经分析了面临分组丢失时用于提供可靠数据传输服务的基本原理及特定的TCP机制。在实践中，这种丢包一般是当网络变得拥塞时由于路由器缓存溢出引起的。分组重传因此作为网络拥塞的征兆（某个特定的运输层报文段的丢失）来对待，但是却无法处理导致网络拥塞的原因，因为有太多的源想以过高的速率发送数据。为了处理网络拥塞原因，需要一些机制以在面临网络拥塞时遏制发送方。 我们考虑一般情况下的拥塞控制问题，试图理解为什么网络拥塞是一件坏事情，网络拥塞是如何在上层应用得到的服务性能中明确地显露出来的？如何可用各种方法来避免网络拥塞或对它做出反应？这种对拥塞控制的更一般研究是恰当的，就像可靠数据传输一样。之后详细研究TCP的拥塞控制算法。 拥塞原因与代价我们通过分析3个复杂性越来越高的发生拥塞的情况，开始对拥塞控制的一般性研 究。在每种情况下，我们首先将看看出现拥塞的原因以及拥塞的代价（根据资源未被充分利用以及端系统得到的低劣服务性能来评价）。我们暂不关注如何对拥塞做出反应或避免拥塞，而是重点理解一个较为简单的问题，即随着主机增加其发送速率并使网络变得拥塞，这时会发生的情况。 情况1：两个发送方和一台具有无穷大缓存的路由器 假设有一段容量为R的共享式输出链路。链路上一个路由器有无限大的缓存空间。当主机A发送速率在0~R之间时，接收方的吞吐量等于发送方的发送速率，即发送方发送的所有数据经有限时延后到达接收方。然而当发送速率超过R时，它的吞吐量只能达到R。这个吞吐量上限是由两条连接之间共享链路容量造成的。看起来取得R的吞吐量可能是一件好事，因为在将分组交付到目的地的过程中链路被充分利用了。但是，以接近链路容量的速率运行时的后果，就是当发送速率接近R时，平均时延就会越来越大，当发送速率超过R时，路由器中的平均排队分组数就会无限增长。甚至在这种（极端）理想化的情况中，我们已经发现了拥塞网络的一种代价，即当分组的到达速率接近链路容量时，分组经历巨大的排队时延。 情况2：两个发送方和一台具有有限缓存的路由器 结论： 一种代价，即发送方必须执行重传以补偿因为缓存溢出而丢弃（丢失）的分组。 另一种代价，即发送方在遇到大时延时所进行的不必要重传会引起路由器利用其链路带宽来转发不必要的分组副本。 情况3：4个发送方和具有有限缓存的多台路由器及多跳路径 每当有一个分组在第二跳路由器上被丢弃时，第一跳路由器所做的将分组转发到第二跳路由器的工作就是“劳而无功”的。而第一跳路由器所使用的将分组转发到第二跳路由器的传输容量用来传送不同的分组可能更有效。例如，当选择一个分组发送时，路由器最好优先考虑那些已经历过一定数量的上游路由器的分组 于是代价很明显：当一个分组沿一条路径被丢弃时，每个上游路由器用于转发该分组到丢弃该分组而使用的传输容量最终被浪费掉了。 拥塞控制方法这里，我们指出在实践中所采用的两种主要拥塞控制方法，讨论特定的网络体系结构和具体使用这些方法的拥塞控制协议。 在最为宽泛的级别上，我们可根据网络层是否为运输层拥塞控制提供了显式帮助，来区分拥塞控制方法。 端到端拥塞控制。在端到端拥塞控制方法中，网络层没有为运输层拥塞控制提供显式支持。即使网络中存在拥塞，端系统也必须通过对网络行为的观察（如分组丢失与时延）来推断之。TCP采用端到端的方法解决拥塞控制，因为IP层不会向端系统提供有关网络拥塞的反馈信息。TCP报文段的丢失（通过超时或3次冗余确认而得知）被认为是网络拥塞的一个迹象，TCP 会相应地减小其窗口长度。 网络辅助的拥塞控制。在网络辅助的拥塞控制中，路由器向发送方提供关于网络中拥塞状态的显式反馈信息。这种反馈可以简单地用一个比特来指示链路中的拥塞情况。更复杂的网络反馈也是可能的。例如，在ATM可用比特率（Available Bite Rate, ABR）拥塞控制中，路由器显式地通知发送方它（路由器）能在输出链路上支持的最大主机发送速率。如上面所提到的，默认因特网版本的IP和TCP采用端到端拥塞控制方法。然而，最近IP和TCP也能够选择性地实现网络辅助拥塞控制。 TCP拥塞控制TCP为运行在不同主机上的 两个进程之间提供了可靠传输服务。TCP的另一个关键部分就是其拥塞控制机制。TCP必须使用端到端拥塞控制而不是使网络辅助的拥塞控制，因为IP层不向端系统提供显式的网络拥塞反馈。 TCP所采用的方法是让每一个发送方根据所感知到的网络拥塞程度来限制其能向 连接发送流量的速率。如果一个TCP发送方感知从它到目的地之间的路径上没什么拥 塞，则TCP发送方增加其发送速率；如果发送方感知沿着该路径有拥塞，则发送方就 会降低其发送速率。但是这种方法提出了三个问题。 第一，一个TCP发送方如何限制它向其连接发送流量的速率呢？ 第二，一个TCP发送方如何感知从它到目的地之间的路径上存在拥塞呢？ 第三，当发送方感知到端到端的拥塞时，采用何种算法来改变其发送速率呢? 运行在发送方的TCP拥塞控制机制跟踪一个额外的变量，即拥塞窗口 （congestion window） 。拥塞窗口表示为cwnd,它对一个TCP发送方能向网络中发送流量的速率进行了限制。通过调节cwnd的值，发送方因此能调整它向连接发送数据的速率。在一个发送方中未被确认的数据量不会超过cwnd与nvnd中的最小值，即 LastByteSent -LastByteAcked ≤min { cwnd, rwnd} 我们接下来考虑TCP发送方是如何感知在它与目的地之间的路径上出现了拥塞的。我们将一个TCP发送方的“丢包事件”定义为：要么出现超时，要么收到来自接收方的3 个冗余ACK）当出现过度的拥塞时，在沿着这条路径上的一台（或多台）路由器的缓存会溢岀，引起一个数据报（包含一个TCP报文段）被丢弃。丢弃的数据报接着会引起发送方的丢包事件（要么超时或收到3个冗余ACK），发送方就认为在发送方到接收方的路径上出现了拥塞的指示。 TCP使用确认来触发（或计时）增大它的拥塞窗口长度,TCP被说成是自计时的。 给定调节cwnd值以控制发送速率的机制，关键的问题依然存在：TCP发送方怎样确定它应当发送的速率呢？如果众多TCP发送方总体上发送太快，它们能够拥塞网络，导致我们看到的拥塞崩溃。如果TCP 发送方过于谨慎，发送太慢，它们不能充分利用网络的带宽；这就是说，TCP发送方能够以更高的速率发送而不会使网络拥塞。那么TCP发送方如何确定它们的发送速率，既使得网络不会拥塞，与此同时又能充分利用所有可用的带宽？ TCP发送方是显式地协作，或存在一种分布式方法使TCP发送方能够仅基于本地信息设置它们的发送速率？ TCP使用下列原则回答这些问题： 一个丢失的报文段表意味着拥塞，因此当丢失报文段时应当降低TCP发送方的 速率。一个超时事件或四个确认 （一个初始ACK和其后的三个冗余ACK）出现，TCP发送方应当减小它的拥塞窗口长度，即减小其发送速率，以应对这种推测的丢包事件。 一个确认报文段指示该网络正在向接收方交付发送方的报文段，因此，当对先前未确认报文段的确认到达时，能够增加发送方的速率。 带宽探测。TCP调节其传输速率的策略是增加其速率以响应到达的ACK,除非岀现丢包事件，此时才减小传输速率。因此，为探测拥塞开始出现的速率，TCP 发送方增加它的传输速率，从该速率后退，进而再次开始探测，看看拥塞开始的速率是否发生了变化。 TCP拥塞控制算法概述了 TCP拥塞控制后，现在是我们考虑广受赞誉的TCP拥塞控制算法细节的时候了，该算法包括3个主要部分：①慢启动；②拥塞避免; ③快速恢复。慢启动和拥塞避免是TCP的强制部分，两者的差异在于对收到的ACK 做出反应时增加cwnd长度的方式。我们很快将会看到慢启动比拥塞避免能更快地增加cdwnd的长度。快速恢复是推荐部分，对TCP发送方并非是必需的。 慢启动当一条TCP连接开始时，cwnd的值通常初始置为一个MSS的较小值, 这就使得初始发送速率大约为MSS/RTT。例如，如果MSS = 500字节且RIT = 200ms,则得到的初始发送速率大约只有20kbps。由于对TCP发送方而言，可用带宽可能比MSS/RTT大得多，TCP发送方希望迅速找到可用带宽的数量。因此，在慢启动（slow-start）状态，*cwnd的值以1个MSS开始并且每当传输的报文段首次被确认就增加1个MSS。* TCP向网络发送第一个报文段并等待一个确认。当该确认到达时，TCP发送方将拥塞窗口增加一个 MSS,并发送出两个最大长度的报文段。这两个报文段被确认，则发送方对每个确认报文段将拥塞窗口增加一个MSS,使得拥塞窗口变为4个MSS,并这样下去。这一过程每过一个RTT,发送速率就翻番。因此，TCP发送速率起始慢，但在慢启动阶段以指数增长。 但是，何时结束这种指数增长呢？ 第一种，如果存在一个由超时指示的丢包事件（即拥塞），TCP发送方将cwnd设置为1并重新开始慢启动过程。它还将第二个状态变量的值ssthresh （”慢启动阈值”的速记）设置为cwnd/2,即当检测到拥塞时将ssthresh置为拥塞窗口值的一半。 慢启动结束的第二种方式是直接与ssthresh的值相关联。因为当检测到拥塞时ssthresh设为cwnd的值一半，当到达或超过ssthresh的值时，继续使cwnd翻番可能有些鲁莽。因此，当cwnd的值等于ssthresh时，结束慢启动并且TCP转移到拥塞避免模式。我们将会看到，当进入拥塞避免模式时，TCP更为谨慎地增加cwnd。 最后一种结束慢启动的方式是,如果检测到3个冗余ACK,这时TCP执行一种快速重传并进入快速恢复状态。 拥塞避免一旦进入拥塞避免状态，cwnd的值大约是上次遇到拥塞时的值的一半，即距离拥塞可能并不遥远！因此，TCP无法每过一个RTT再将cwnd的值翻番，而是采用了一种较为保守的方法，每个*RTT*只将cwnd的值增加一个MSS。这能够以几种方式完成。 一种通用的方法是对于TCP发送方无论何时到达一个新的确认，就将cwnd增加一个 MSS （ MSS/cwnd）字节。例如，如果MSS是1460字节并且cwnd是14 600字节，则在一 个R1T内发送10个报文段。每个到达ACK （假定每个报文段一个ACK）增加1/10MSS 的拥塞窗口长度，因此在收到对所有10个报文段的确认后，拥塞窗口的值将增加了一个 MSS。 但是何时应当结束拥塞避免的线性增长（每RTT 1MSS）呢？ 当出现超时时，TCP的拥塞避免算法行为相同。与慢启动的情况一样，cwnd的值被设置为1个MSS,当丢包事件出现时，ssthresh的值被更新为cwnd值的一半。进入慢启动状态。 然而，前面讲过丢包事件也能由一个三个冗余ACK事件触发。在这种情况下，网络继续从发送方向接收方交付报文段（就像由收到冗余ACK所指示的那样）。因此TCP对这种丢包事件的行为，相比于超时指示的丢包,应当不那么剧烈：TCP将cwnd的值减半（为使测量结果更好，计及已收到的3个冗余的 ACK要加上3个MSS）,并且当收到3个冗余的ACK,将ssthresh的值记录为cwnd的值的一半。接下来进入快速恢复状态。 快速恢复慢启动和拥塞避免状态中，当且仅当接收3个冗余ACK时，才会进入快速恢复状态 在快速恢复中，对于引起TCP进入快速恢复状态的缺失报文段，对收到的每个冗余的ACK, cwnd的值增加一个MSS。最终，当对丢失报文段的一个ACK到达时，TCP在降低cwnd后进入拥塞避免状态。 如果出现超时事件，快速恢复在执行如同在慢启动和拥塞避免中相同的动作后，迁移到慢启动状态：当丢包事件出现时，cwnd的值被设置为1个 MSS,并且ssthresh的值设置为cwnd值的一半。 快速恢复是TCP推荐的而非必需的构件。一种称为TCP Tahoe的TCP早期版本，不管是发生超时指示的丢包事件，还是发生3个冗余ACK指示的丢包事件，都无条件地将其拥塞窗口减至1个MSS,并进入慢启动阶段。TCP的较新版本TCP Reno,则综合了快速恢复。 TCP拥塞控制常常被称为加性增、乘性减 (Additive-1ncrease, Multiplicative- Decrease, AIMD）拥塞控制方式。AIMD控制引发了锯齿行为。 公平性考虑K条TCP连接，每条都有不同的端到端路径，但是都经过一段传输速率为R bps 的瓶颈链路。如果每条连接的平均传输速率接近R/K,即每条连接都得到相同份额的链路带宽，则认为该拥塞控制机制是公平的。 TCP的AIMD算法公平吗？尤其是假定可在不同时间启动并因此在某个给定的时间点可能具有不同的窗口长度情况下，对这些不同的TCP连接还是公平的吗？TCP趋于在竞争的多条TCP连接之间提供对一段瓶颈链路带宽的平等分享 。 实践中，这些条件通常是得不到满足的，客户-服务器应用因此能获得非常不平等的链路带宽份额。已经表明当多条连接共享一个共同的瓶颈链路时，那些具有较小RTT的连接能够在链路空闲时更快地抢到可用带宽（即较快地打开其拥塞窗口），因而将比那些具有较大RTT的连接享用更高的吞吐量。 公平性和UDP 我们刚才已经看到，TCP拥塞控制是如何通过拥塞窗口机制来调节一个应用程序的传输速率的。许多多媒体应用如因特网电话和视频会议，经常就因为这种特定原因而不在TCP上运行，因为它们不想其传输速率被扼制，即使在网络非常拥塞的情况下。相反，这些应用宁可在UDP上运行，UDP是没有内置的拥塞控制的。当运行在UDP上时，这些应用能够以恒定的速率将其音频和视频数据注入网络之中并且偶尔会丢失分组，而不愿在拥塞时将其发送速率降至“公平”级别并且不丢失任何分组。从TCP的观点来看，运行在 UDP上的多媒体应用是不公平的，因为它们不与其他连接合作，也不适时地调整其传输速率。因为TCP拥塞控制在面临拥塞增加（丢包）时，将降低其传输速率，而UDP源则不 必这样做，UDP源有可能压制TCP流量。当今的一个主要研究领域就是开发一种因特网中的拥塞控制机制，用于阻止UDP流量不断压制直至中断因特网吞吐量的情况。 公平性和并行TCP连接 即使我们能够迫使UDP流量具有公平的行为，但公平性问题仍然没有完全解决。这是因为我们没有什么办法阻止基于TCP的应用使用多个并行连接。例如，Web浏览器通常使用多个并行TCP连接来传送一个Web页中的多个对象。（多条连接的确切数目可以在多数浏览器中进行配置。）当一个应用使用多条并行连接时，它占用了一条拥塞链路中较大比例的带宽。举例来说，考虑一段速率为尺且支持9个在线客户-服务器应用的链路，每个应用使用一条TCP连接。如果一个新的应用加入进来，也使用一条TCP连接，则每个应用得到差不多相同的传输速率R/10。但是如果这个新的应用这次使用了 11个并行TCP 连接，则这个新应用就不公平地分到超过R/2的带宽。Web流量在因特网中是非常普遍 的，所以多条并行连接并非不常见。 明确拥塞通告：网络辅助拥塞控制不做具体阐述。","link":"/2020/04/03/%E9%9D%A2%E5%90%91%E8%BF%9E%E6%8E%A5%E7%9A%84%E8%BF%90%E8%BE%93-TCP/"}],"tags":[{"name":"javaSE","slug":"javaSE","link":"/tags/javaSE/"},{"name":"随笔","slug":"随笔","link":"/tags/%E9%9A%8F%E7%AC%94/"},{"name":"SSM","slug":"SSM","link":"/tags/SSM/"},{"name":"ssm","slug":"ssm","link":"/tags/ssm/"},{"name":"maven","slug":"maven","link":"/tags/maven/"},{"name":"计算机网络","slug":"计算机网络","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"408","slug":"408","link":"/tags/408/"},{"name":"springMVC","slug":"springMVC","link":"/tags/springMVC/"},{"name":"算法设计与分析","slug":"算法设计与分析","link":"/tags/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%86%E6%9E%90/"},{"name":"网络层","slug":"网络层","link":"/tags/%E7%BD%91%E7%BB%9C%E5%B1%82/"},{"name":"计算机组成原理","slug":"计算机组成原理","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"}],"categories":[{"name":"java","slug":"java","link":"/categories/java/"},{"name":"随笔","slug":"随笔","link":"/categories/%E9%9A%8F%E7%AC%94/"},{"name":"SSM","slug":"SSM","link":"/categories/SSM/"},{"name":"框架学习","slug":"框架学习","link":"/categories/%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/"},{"name":"408","slug":"408","link":"/categories/408/"},{"name":"springMVC","slug":"springMVC","link":"/categories/springMVC/"},{"name":"ssm","slug":"ssm","link":"/categories/ssm/"},{"name":"算法","slug":"算法","link":"/categories/%E7%AE%97%E6%B3%95/"}]}